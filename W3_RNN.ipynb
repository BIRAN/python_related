{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W3_RNN",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BIRAN/python_related/blob/master/W3_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9wLFstaIkZT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "0d564c4b-f74a-4066-be0f-b2439be5d027"
      },
      "source": [
        "!pip install tf-nightly-2.0-preview"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly-2.0-preview in /usr/local/lib/python3.6/dist-packages (2.0.0.dev20190803)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.16.4)\n",
            "Requirement already satisfied: tensorflow-estimator-2.0-preview in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.14.0.dev2019080300)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (2.3.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.33.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.11.2)\n",
            "Requirement already satisfied: tb-nightly<1.16.0a0,>=1.15.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.15.0a20190802)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.7.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly-2.0-preview) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly-2.0-preview) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly-2.0-preview) (0.15.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tf-nightly-2.0-preview) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Vw6l07K7an",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7877845-3aa7-4cb7-c4c5-3f563910294e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-dev20190803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFbguvDmK9Ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "    plt.plot(time[start:end], series[start:end], format)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.grid(True)\n",
        "\n",
        "def trend(time, slope=0):\n",
        "    return slope * time\n",
        "\n",
        "def seasonal_pattern(season_time):\n",
        "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n",
        "    return np.where(season_time < 0.4,\n",
        "                    np.cos(season_time * 2 * np.pi),\n",
        "                    1 / np.exp(3 * season_time))\n",
        "\n",
        "def seasonality(time, period, amplitude=1, phase=0):\n",
        "    \"\"\"Repeats the same pattern at each period\"\"\"\n",
        "    season_time = ((time + phase) % period) / period\n",
        "    return amplitude * seasonal_pattern(season_time)\n",
        "\n",
        "def noise(time, noise_level=1, seed=None):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    return rnd.randn(len(time)) * noise_level\n",
        "  \n",
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
        "  dataset = dataset.batch(batch_size).prefetch(1)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8amL5ESLN78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time = np.arange(4 * 365 + 1, dtype=\"float32\")\n",
        "baseline = 10\n",
        "series = trend(time, 0.1)  \n",
        "baseline = 10\n",
        "amplitude = 40\n",
        "slope = 0.05\n",
        "noise_level = 5\n",
        "\n",
        "# Create the series\n",
        "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n",
        "# Update with noise\n",
        "series += noise(time, noise_level, seed=42)\n",
        "\n",
        "split_time = 1000\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]\n",
        "\n",
        "window_size = 20\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb2Egn2wLr5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e72dd4da-c0db-49ff-a49f-2f9a1377d0b8"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "\n",
        "train_set = windowed_dataset(x_train, window_size, batch_size=128, shuffle_buffer=shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "  tf.keras.layers.SimpleRNN(40, return_sequences=True),\n",
        "  tf.keras.layers.SimpleRNN(40),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
        "optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0804 01:18:10.191322 139850187470720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0804 01:18:11.134660 139850187470720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:468: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Apply a constraint manually following the optimizer update step.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 2s 262ms/step - loss: 195.6164 - mae: 196.0720\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 194.5489 - mae: 195.2834\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 193.0079 - mae: 194.0106\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 192.1724 - mae: 192.4087\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 190.2399 - mae: 190.5219\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 187.3783 - mae: 188.3526\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 185.5602 - mae: 185.8774\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 182.9401 - mae: 183.0458\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 179.8463 - mae: 179.8092\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 175.3591 - mae: 176.0968\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 171.4483 - mae: 171.8191\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 166.5275 - mae: 166.8562\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 161.0708 - mae: 161.0344\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 153.6406 - mae: 154.1573\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 145.5144 - mae: 145.8014\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 135.2997 - mae: 135.5340\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 122.6167 - mae: 122.5148\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 106.1422 - mae: 105.8232\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 84.8292 - mae: 84.5497\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 58.1743 - mae: 57.8901\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 32.5309 - mae: 32.4902\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 24.0240 - mae: 24.4906\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 23.0907 - mae: 23.6417\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 21.0732 - mae: 21.4012\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 16.7517 - mae: 17.2673\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 13.7967 - mae: 14.2181\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 10.8228 - mae: 11.2559\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 8.6563 - mae: 9.1753\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 8.1088 - mae: 8.4686\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 7.8638 - mae: 8.3768\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.9747 - mae: 8.3434\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.6494 - mae: 8.2072\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.6088 - mae: 8.1244\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 7.6491 - mae: 8.1203\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.5776 - mae: 8.0143\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 7.3892 - mae: 7.9604\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.4214 - mae: 7.8328\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 7.1884 - mae: 7.7662\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 7.2013 - mae: 7.7087\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.0946 - mae: 7.6695\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 7.0964 - mae: 7.6554\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.2272 - mae: 7.6855\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 7.5938 - mae: 7.9560\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.2416 - mae: 7.6074\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.1088 - mae: 7.5198\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.8654 - mae: 7.3602\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.1020 - mae: 7.4739\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 7.0206 - mae: 7.4515\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 7.9478 - mae: 8.4849\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.6144 - mae: 7.9709\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.8342 - mae: 7.3529\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.7181 - mae: 7.3265\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 8.2463 - mae: 8.6690\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.1740 - mae: 7.7811\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 7.6705 - mae: 8.0675\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 8.8307 - mae: 9.3075\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 7.3002 - mae: 7.7392\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 7.5071 - mae: 7.9515\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 7.3360 - mae: 7.8543\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.4223 - mae: 6.8936\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.6475 - mae: 7.2845\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 8.0408 - mae: 8.7272\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.2053 - mae: 7.7210\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.2072 - mae: 7.6970\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 8.1754 - mae: 8.8217\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 10.7630 - mae: 11.6141\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 11.8531 - mae: 12.4574\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 11.7152 - mae: 12.2951\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 12.4412 - mae: 12.8412\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 9.3557 - mae: 9.7434\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.1622 - mae: 6.5753\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.9744 - mae: 8.5372\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.7500 - mae: 8.1352\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 9.2630 - mae: 9.6310\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.9968 - mae: 7.3136\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 11.2382 - mae: 12.8363\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 17.6521 - mae: 18.0977\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 11.5709 - mae: 11.9709\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 10.5359 - mae: 10.6923\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 18.5954 - mae: 18.6825\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 18.8887 - mae: 19.2736\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 20.8260 - mae: 21.9483\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 21.1544 - mae: 22.3906\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 19.5956 - mae: 19.5685\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 17.6546 - mae: 17.6291\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 15.2290 - mae: 15.1185\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 18.5161 - mae: 20.0996\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 21.7256 - mae: 21.3924\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 26.0818 - mae: 28.0953\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 39.5972 - mae: 41.1607\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 35.5262 - mae: 34.4550\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 47.9264 - mae: 50.6405\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 45.6445 - mae: 45.3153\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 45.3104 - mae: 47.1302\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 52.5934 - mae: 52.1973\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 65.4894 - mae: 67.5183\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 54.4904 - mae: 52.3677\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 67.6395 - mae: 65.3131\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 104.1244 - mae: 104.7710\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 98.5310 - mae: 97.2816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1OyUjh1Ludu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "9b7eaccb-6c2d-4c5e-fabc-45c3dae8a347"
      },
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-8, 1e-4, 0, 30])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1e-08, 0.0001, 0, 30]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIgp9EZEs8v8B+6Jt67S8hxIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkssfserLzOa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8bf4e504-496c-40d5-fad2-e893c9935b6b"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "\n",
        "dataset = windowed_dataset(x_train, window_size, batch_size=128, shuffle_buffer=shuffle_buffer_size)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "  tf.keras.layers.SimpleRNN(40, return_sequences=True),\n",
        "  tf.keras.layers.SimpleRNN(40),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 100.0)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(lr=5e-5, momentum=0.9)\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(dataset,epochs=400)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "8/8 [==============================] - 2s 235ms/step - loss: 80.8704 - mae: 83.5782\n",
            "Epoch 2/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 24.4569 - mae: 24.3853\n",
            "Epoch 3/400\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 18.2022 - mae: 18.7075\n",
            "Epoch 4/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 14.2618 - mae: 14.6785\n",
            "Epoch 5/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 10.8892 - mae: 11.2668\n",
            "Epoch 6/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 11.3937 - mae: 12.5401\n",
            "Epoch 7/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 12.7681 - mae: 13.1479\n",
            "Epoch 8/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 12.2807 - mae: 12.5482\n",
            "Epoch 9/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 13.6768 - mae: 13.6776\n",
            "Epoch 10/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 15.0722 - mae: 15.1427\n",
            "Epoch 11/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 12.1674 - mae: 12.4071\n",
            "Epoch 12/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 12.7979 - mae: 13.2284\n",
            "Epoch 13/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 10.7223 - mae: 11.0952\n",
            "Epoch 14/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.8107 - mae: 8.1667\n",
            "Epoch 15/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.7977 - mae: 7.4179\n",
            "Epoch 16/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.8862 - mae: 7.4136\n",
            "Epoch 17/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 7.0739 - mae: 7.5828\n",
            "Epoch 18/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.7999 - mae: 7.1940\n",
            "Epoch 19/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.9964 - mae: 7.3939\n",
            "Epoch 20/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 10.1996 - mae: 10.8532\n",
            "Epoch 21/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 9.9150 - mae: 10.2265\n",
            "Epoch 22/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 9.6696 - mae: 10.2477\n",
            "Epoch 23/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 8.0833 - mae: 8.4482\n",
            "Epoch 24/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 10.1085 - mae: 10.5807\n",
            "Epoch 25/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 8.4903 - mae: 9.1409\n",
            "Epoch 26/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 9.4681 - mae: 9.8834\n",
            "Epoch 27/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 8.4356 - mae: 8.9004\n",
            "Epoch 28/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 7.7679 - mae: 8.7038\n",
            "Epoch 29/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 9.1131 - mae: 9.4590\n",
            "Epoch 30/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.5368 - mae: 8.1826\n",
            "Epoch 31/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 9.3322 - mae: 9.6500\n",
            "Epoch 32/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.1030 - mae: 7.6114\n",
            "Epoch 33/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.4257 - mae: 8.1208\n",
            "Epoch 34/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 10.3024 - mae: 10.6096\n",
            "Epoch 35/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 9.3304 - mae: 9.8295\n",
            "Epoch 36/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 6.0158 - mae: 6.4234\n",
            "Epoch 37/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.9087 - mae: 6.3753\n",
            "Epoch 38/400\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 5.1456 - mae: 5.5928\n",
            "Epoch 39/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 5.5039 - mae: 5.9486\n",
            "Epoch 40/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 5.7136 - mae: 6.1697\n",
            "Epoch 41/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.8081 - mae: 6.2545\n",
            "Epoch 42/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.8719 - mae: 6.2746\n",
            "Epoch 43/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 6.7652 - mae: 7.3862\n",
            "Epoch 44/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 6.4634 - mae: 6.9546\n",
            "Epoch 45/400\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 5.7664 - mae: 6.5878\n",
            "Epoch 46/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 7.3731 - mae: 7.6084\n",
            "Epoch 47/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.8799 - mae: 7.4312\n",
            "Epoch 48/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.4334 - mae: 5.8477\n",
            "Epoch 49/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.7598 - mae: 7.3676\n",
            "Epoch 50/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 6.6380 - mae: 7.0033\n",
            "Epoch 51/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.1945 - mae: 6.7110\n",
            "Epoch 52/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.6080 - mae: 6.0066\n",
            "Epoch 53/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.0470 - mae: 5.5382\n",
            "Epoch 54/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.6555 - mae: 7.0791\n",
            "Epoch 55/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.8066 - mae: 6.1649\n",
            "Epoch 56/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.7551 - mae: 5.1612\n",
            "Epoch 57/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.7860 - mae: 5.2634\n",
            "Epoch 58/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.0253 - mae: 5.7481\n",
            "Epoch 59/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.7582 - mae: 6.2090\n",
            "Epoch 60/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.8265 - mae: 6.3596\n",
            "Epoch 61/400\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 5.4735 - mae: 5.9734\n",
            "Epoch 62/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.8497 - mae: 5.2974\n",
            "Epoch 63/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 6.6528 - mae: 7.0121\n",
            "Epoch 64/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 9.0213 - mae: 9.9112\n",
            "Epoch 65/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 9.5956 - mae: 9.7212\n",
            "Epoch 66/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.8028 - mae: 8.4403\n",
            "Epoch 67/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.5044 - mae: 6.8912\n",
            "Epoch 68/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.8704 - mae: 5.3505\n",
            "Epoch 69/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.2191 - mae: 5.7589\n",
            "Epoch 70/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.2102 - mae: 5.6123\n",
            "Epoch 71/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.7648 - mae: 6.1708\n",
            "Epoch 72/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.5581 - mae: 5.9727\n",
            "Epoch 73/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.0213 - mae: 5.4667\n",
            "Epoch 74/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.0061 - mae: 5.5135\n",
            "Epoch 75/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.9399 - mae: 6.2620\n",
            "Epoch 76/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.0541 - mae: 5.4747\n",
            "Epoch 77/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.3090 - mae: 4.7812\n",
            "Epoch 78/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.7057 - mae: 6.2427\n",
            "Epoch 79/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.0714 - mae: 5.4742\n",
            "Epoch 80/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.8664 - mae: 5.2720\n",
            "Epoch 81/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.2690 - mae: 5.6346\n",
            "Epoch 82/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.4107 - mae: 4.8314\n",
            "Epoch 83/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.3738 - mae: 4.8579\n",
            "Epoch 84/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.8291 - mae: 5.2946\n",
            "Epoch 85/400\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 5.7478 - mae: 6.1373\n",
            "Epoch 86/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 7.7646 - mae: 8.3955\n",
            "Epoch 87/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.7332 - mae: 8.1169\n",
            "Epoch 88/400\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 7.4055 - mae: 7.8289\n",
            "Epoch 89/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 6.4815 - mae: 6.9316\n",
            "Epoch 90/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.7332 - mae: 5.2168\n",
            "Epoch 91/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.5763 - mae: 5.0797\n",
            "Epoch 92/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.2786 - mae: 5.7424\n",
            "Epoch 93/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.4428 - mae: 5.8523\n",
            "Epoch 94/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 6.3238 - mae: 6.9390\n",
            "Epoch 95/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.0753 - mae: 5.6286\n",
            "Epoch 96/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.0349 - mae: 6.4284\n",
            "Epoch 97/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.2800 - mae: 6.9777\n",
            "Epoch 98/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 8.2867 - mae: 8.5897\n",
            "Epoch 99/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 8.4533 - mae: 8.9199\n",
            "Epoch 100/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 6.3575 - mae: 6.9283\n",
            "Epoch 101/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.6535 - mae: 5.1116\n",
            "Epoch 102/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.3653 - mae: 4.8579\n",
            "Epoch 103/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.1186 - mae: 5.5515\n",
            "Epoch 104/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 6.5479 - mae: 7.2412\n",
            "Epoch 105/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 7.5644 - mae: 8.0656\n",
            "Epoch 106/400\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 7.6966 - mae: 8.1735\n",
            "Epoch 107/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.1396 - mae: 6.6417\n",
            "Epoch 108/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.1054 - mae: 6.5083\n",
            "Epoch 109/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 7.9821 - mae: 8.3172\n",
            "Epoch 110/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 6.4429 - mae: 6.8056\n",
            "Epoch 111/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 7.7788 - mae: 8.2693\n",
            "Epoch 112/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.6025 - mae: 6.1643\n",
            "Epoch 113/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.0500 - mae: 5.4987\n",
            "Epoch 114/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.3070 - mae: 4.7901\n",
            "Epoch 115/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.8377 - mae: 5.2565\n",
            "Epoch 116/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.0467 - mae: 6.4338\n",
            "Epoch 117/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.8463 - mae: 5.3405\n",
            "Epoch 118/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.7997 - mae: 6.2783\n",
            "Epoch 119/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.3830 - mae: 5.8344\n",
            "Epoch 120/400\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 4.9053 - mae: 5.3775\n",
            "Epoch 121/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.7458 - mae: 5.2375\n",
            "Epoch 122/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.4094 - mae: 4.8556\n",
            "Epoch 123/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.1285 - mae: 5.5960\n",
            "Epoch 124/400\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.5415 - mae: 5.0245\n",
            "Epoch 125/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.9855 - mae: 5.4360\n",
            "Epoch 126/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.3076 - mae: 4.8571\n",
            "Epoch 127/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.3337 - mae: 4.8342\n",
            "Epoch 128/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.9249 - mae: 5.3648\n",
            "Epoch 129/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.7448 - mae: 5.2115\n",
            "Epoch 130/400\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.8267 - mae: 5.2866\n",
            "Epoch 131/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.8302 - mae: 6.2458\n",
            "Epoch 132/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.1117 - mae: 5.6156\n",
            "Epoch 133/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 8.9582 - mae: 9.4205\n",
            "Epoch 134/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 6.5062 - mae: 7.0753\n",
            "Epoch 135/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.2030 - mae: 5.6531\n",
            "Epoch 136/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.2898 - mae: 5.8158\n",
            "Epoch 137/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 7.1402 - mae: 7.7907\n",
            "Epoch 138/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 7.3151 - mae: 7.6190\n",
            "Epoch 139/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 7.6520 - mae: 8.0941\n",
            "Epoch 140/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.5928 - mae: 6.1743\n",
            "Epoch 141/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.3957 - mae: 5.9864\n",
            "Epoch 142/400\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 5.1319 - mae: 5.4971\n",
            "Epoch 143/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.8876 - mae: 5.2848\n",
            "Epoch 144/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.7487 - mae: 5.3234\n",
            "Epoch 145/400\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 4.7991 - mae: 5.3048\n",
            "Epoch 146/400\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 4.3469 - mae: 4.8093\n",
            "Epoch 147/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.5341 - mae: 5.0872\n",
            "Epoch 148/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.3274 - mae: 4.8205\n",
            "Epoch 149/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.7933 - mae: 5.2506\n",
            "Epoch 150/400\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.8466 - mae: 5.3825\n",
            "Epoch 151/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.7473 - mae: 5.1733\n",
            "Epoch 152/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.3645 - mae: 4.8419\n",
            "Epoch 153/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.6829 - mae: 5.2326\n",
            "Epoch 154/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.2667 - mae: 6.6418\n",
            "Epoch 155/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 8.2765 - mae: 8.7850\n",
            "Epoch 156/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.5472 - mae: 7.7625\n",
            "Epoch 157/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 6.7726 - mae: 7.1498\n",
            "Epoch 158/400\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 5.4603 - mae: 6.1141\n",
            "Epoch 159/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.0345 - mae: 5.5611\n",
            "Epoch 160/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.9908 - mae: 5.4065\n",
            "Epoch 161/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.0996 - mae: 5.4816\n",
            "Epoch 162/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.6084 - mae: 5.2147\n",
            "Epoch 163/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.6579 - mae: 5.1339\n",
            "Epoch 164/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.4601 - mae: 4.9299\n",
            "Epoch 165/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.7620 - mae: 5.2732\n",
            "Epoch 166/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.5294 - mae: 4.9982\n",
            "Epoch 167/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.4831 - mae: 5.1024\n",
            "Epoch 168/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.5393 - mae: 5.0485\n",
            "Epoch 169/400\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 5.8217 - mae: 6.3708\n",
            "Epoch 170/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.7997 - mae: 5.2584\n",
            "Epoch 171/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.8781 - mae: 5.3920\n",
            "Epoch 172/400\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 5.1428 - mae: 5.5509\n",
            "Epoch 173/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 5.2894 - mae: 5.7382\n",
            "Epoch 174/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 5.2528 - mae: 5.7795\n",
            "Epoch 175/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 6.3818 - mae: 7.0291\n",
            "Epoch 176/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 7.3831 - mae: 7.6466\n",
            "Epoch 177/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.9049 - mae: 7.3578\n",
            "Epoch 178/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.3312 - mae: 5.8191\n",
            "Epoch 179/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.9881 - mae: 5.4826\n",
            "Epoch 180/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.1216 - mae: 5.5471\n",
            "Epoch 181/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 7.6557 - mae: 8.3255\n",
            "Epoch 182/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 7.4583 - mae: 7.8507\n",
            "Epoch 183/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.3666 - mae: 6.9795\n",
            "Epoch 184/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.7913 - mae: 6.2169\n",
            "Epoch 185/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.6437 - mae: 5.0962\n",
            "Epoch 186/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.1921 - mae: 5.5746\n",
            "Epoch 187/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.0860 - mae: 5.4855\n",
            "Epoch 188/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.6291 - mae: 5.0873\n",
            "Epoch 189/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.0980 - mae: 5.4984\n",
            "Epoch 190/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.8422 - mae: 5.3574\n",
            "Epoch 191/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.0187 - mae: 5.4947\n",
            "Epoch 192/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.7378 - mae: 5.2259\n",
            "Epoch 193/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.7561 - mae: 5.2349\n",
            "Epoch 194/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.9469 - mae: 5.5738\n",
            "Epoch 195/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.3316 - mae: 5.9226\n",
            "Epoch 196/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 6.5106 - mae: 7.1662\n",
            "Epoch 197/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 6.2920 - mae: 6.6264\n",
            "Epoch 198/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.7610 - mae: 5.2630\n",
            "Epoch 199/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.7349 - mae: 5.2015\n",
            "Epoch 200/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.1920 - mae: 4.6961\n",
            "Epoch 201/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.5766 - mae: 5.0070\n",
            "Epoch 202/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.3772 - mae: 4.9607\n",
            "Epoch 203/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.8138 - mae: 5.2454\n",
            "Epoch 204/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.7296 - mae: 5.1588\n",
            "Epoch 205/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.7501 - mae: 5.1541\n",
            "Epoch 206/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.3860 - mae: 4.8588\n",
            "Epoch 207/400\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 5.0488 - mae: 5.5096\n",
            "Epoch 208/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.5338 - mae: 5.0405\n",
            "Epoch 209/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.9779 - mae: 5.4001\n",
            "Epoch 210/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.3702 - mae: 4.8372\n",
            "Epoch 211/400\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 4.4719 - mae: 4.9995\n",
            "Epoch 212/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.1849 - mae: 4.6945\n",
            "Epoch 213/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.3985 - mae: 5.8916\n",
            "Epoch 214/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.5024 - mae: 4.9605\n",
            "Epoch 215/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.7051 - mae: 5.1313\n",
            "Epoch 216/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.7809 - mae: 5.2516\n",
            "Epoch 217/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.7957 - mae: 5.2053\n",
            "Epoch 218/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.5635 - mae: 8.1956\n",
            "Epoch 219/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 6.4067 - mae: 6.9063\n",
            "Epoch 220/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.6725 - mae: 6.1244\n",
            "Epoch 221/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.4360 - mae: 4.9805\n",
            "Epoch 222/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.8752 - mae: 5.4004\n",
            "Epoch 223/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.6858 - mae: 5.1967\n",
            "Epoch 224/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.6565 - mae: 5.1528\n",
            "Epoch 225/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.4209 - mae: 4.9935\n",
            "Epoch 226/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.7038 - mae: 5.1446\n",
            "Epoch 227/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.1510 - mae: 5.6982\n",
            "Epoch 228/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 6.4553 - mae: 6.9734\n",
            "Epoch 229/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.8036 - mae: 6.2722\n",
            "Epoch 230/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.3352 - mae: 5.8966\n",
            "Epoch 231/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 6.5255 - mae: 6.8505\n",
            "Epoch 232/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.4858 - mae: 4.9331\n",
            "Epoch 233/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.4219 - mae: 5.8946\n",
            "Epoch 234/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.6886 - mae: 6.0198\n",
            "Epoch 235/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 6.6056 - mae: 7.0932\n",
            "Epoch 236/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.8504 - mae: 5.2888\n",
            "Epoch 237/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.6597 - mae: 5.0988\n",
            "Epoch 238/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.6377 - mae: 5.0484\n",
            "Epoch 239/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.2252 - mae: 4.8047\n",
            "Epoch 240/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.7989 - mae: 6.2070\n",
            "Epoch 241/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 6.4013 - mae: 6.8613\n",
            "Epoch 242/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.7271 - mae: 5.1685\n",
            "Epoch 243/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.0291 - mae: 5.4895\n",
            "Epoch 244/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.1926 - mae: 5.8710\n",
            "Epoch 245/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.8481 - mae: 7.2351\n",
            "Epoch 246/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.6930 - mae: 6.0759\n",
            "Epoch 247/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.9541 - mae: 5.4593\n",
            "Epoch 248/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.6156 - mae: 5.1336\n",
            "Epoch 249/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.2808 - mae: 5.9063\n",
            "Epoch 250/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.7108 - mae: 6.0872\n",
            "Epoch 251/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.1167 - mae: 5.5718\n",
            "Epoch 252/400\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.3657 - mae: 4.8121\n",
            "Epoch 253/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.5124 - mae: 4.9576\n",
            "Epoch 254/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.6387 - mae: 5.0876\n",
            "Epoch 255/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.0640 - mae: 4.5785\n",
            "Epoch 256/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.2399 - mae: 4.7033\n",
            "Epoch 257/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.1126 - mae: 4.5988\n",
            "Epoch 258/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.0675 - mae: 4.5639\n",
            "Epoch 259/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.0620 - mae: 4.5262\n",
            "Epoch 260/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.0122 - mae: 4.4976\n",
            "Epoch 261/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.6457 - mae: 5.1355\n",
            "Epoch 262/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.4511 - mae: 5.9413\n",
            "Epoch 263/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.7062 - mae: 6.1902\n",
            "Epoch 264/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 6.4069 - mae: 6.9421\n",
            "Epoch 265/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.5861 - mae: 6.1616\n",
            "Epoch 266/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.0950 - mae: 6.6929\n",
            "Epoch 267/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 6.6088 - mae: 7.1224\n",
            "Epoch 268/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 7.0978 - mae: 7.5206\n",
            "Epoch 269/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.8814 - mae: 6.2660\n",
            "Epoch 270/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.3490 - mae: 6.8493\n",
            "Epoch 271/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.1284 - mae: 6.5303\n",
            "Epoch 272/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 7.0756 - mae: 7.5693\n",
            "Epoch 273/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.4954 - mae: 5.9066\n",
            "Epoch 274/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.8934 - mae: 5.4107\n",
            "Epoch 275/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.1998 - mae: 4.6785\n",
            "Epoch 276/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.4810 - mae: 4.9020\n",
            "Epoch 277/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.3677 - mae: 4.9499\n",
            "Epoch 278/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.3340 - mae: 5.8334\n",
            "Epoch 279/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.3878 - mae: 4.8670\n",
            "Epoch 280/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.4315 - mae: 4.8379\n",
            "Epoch 281/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.3348 - mae: 4.8210\n",
            "Epoch 282/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.1957 - mae: 4.6106\n",
            "Epoch 283/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.2441 - mae: 4.7543\n",
            "Epoch 284/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.3703 - mae: 4.8444\n",
            "Epoch 285/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.3004 - mae: 4.8661\n",
            "Epoch 286/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.9043 - mae: 5.3893\n",
            "Epoch 287/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.7900 - mae: 7.2167\n",
            "Epoch 288/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.1324 - mae: 5.7420\n",
            "Epoch 289/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.0264 - mae: 6.3854\n",
            "Epoch 290/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.9984 - mae: 5.4822\n",
            "Epoch 291/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.3364 - mae: 4.8141\n",
            "Epoch 292/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.1485 - mae: 4.6520\n",
            "Epoch 293/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.2395 - mae: 4.7565\n",
            "Epoch 294/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.7139 - mae: 5.2156\n",
            "Epoch 295/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.7044 - mae: 5.2072\n",
            "Epoch 296/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.5246 - mae: 6.9506\n",
            "Epoch 297/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.7432 - mae: 5.1877\n",
            "Epoch 298/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.1378 - mae: 4.6828\n",
            "Epoch 299/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.8339 - mae: 5.3047\n",
            "Epoch 300/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.4169 - mae: 4.8514\n",
            "Epoch 301/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.7966 - mae: 5.2710\n",
            "Epoch 302/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.8464 - mae: 5.3306\n",
            "Epoch 303/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.0976 - mae: 5.5166\n",
            "Epoch 304/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.0305 - mae: 5.4657\n",
            "Epoch 305/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.0359 - mae: 5.4732\n",
            "Epoch 306/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.6267 - mae: 6.0456\n",
            "Epoch 307/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.0835 - mae: 5.4979\n",
            "Epoch 308/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.5065 - mae: 4.8944\n",
            "Epoch 309/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 5.2614 - mae: 5.6607\n",
            "Epoch 310/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.5283 - mae: 4.9370\n",
            "Epoch 311/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.1800 - mae: 4.6224\n",
            "Epoch 312/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.2260 - mae: 4.6791\n",
            "Epoch 313/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.5305 - mae: 4.9887\n",
            "Epoch 314/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.5822 - mae: 5.1954\n",
            "Epoch 315/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.1538 - mae: 6.4354\n",
            "Epoch 316/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.5742 - mae: 6.1731\n",
            "Epoch 317/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.2172 - mae: 5.7571\n",
            "Epoch 318/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.1555 - mae: 5.5980\n",
            "Epoch 319/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.2739 - mae: 4.7562\n",
            "Epoch 320/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.4762 - mae: 4.9189\n",
            "Epoch 321/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.2860 - mae: 4.7774\n",
            "Epoch 322/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.4572 - mae: 5.0294\n",
            "Epoch 323/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.6202 - mae: 5.1760\n",
            "Epoch 324/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.8680 - mae: 5.3849\n",
            "Epoch 325/400\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.8657 - mae: 5.4693\n",
            "Epoch 326/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.6789 - mae: 6.1026\n",
            "Epoch 327/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.8100 - mae: 5.2341\n",
            "Epoch 328/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.1340 - mae: 4.6578\n",
            "Epoch 329/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.6150 - mae: 5.2520\n",
            "Epoch 330/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.4243 - mae: 4.9120\n",
            "Epoch 331/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.3967 - mae: 4.9199\n",
            "Epoch 332/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.4826 - mae: 4.9555\n",
            "Epoch 333/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.3768 - mae: 4.8538\n",
            "Epoch 334/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.5600 - mae: 4.9945\n",
            "Epoch 335/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.3466 - mae: 4.8405\n",
            "Epoch 336/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.2256 - mae: 4.7144\n",
            "Epoch 337/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.1605 - mae: 4.6189\n",
            "Epoch 338/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.1258 - mae: 4.6100\n",
            "Epoch 339/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 5.1623 - mae: 5.6822\n",
            "Epoch 340/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.5367 - mae: 5.9913\n",
            "Epoch 341/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 6.1669 - mae: 6.7757\n",
            "Epoch 342/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 6.4618 - mae: 6.7667\n",
            "Epoch 343/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.4952 - mae: 4.9499\n",
            "Epoch 344/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.8454 - mae: 5.3102\n",
            "Epoch 345/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.5097 - mae: 5.0741\n",
            "Epoch 346/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.9953 - mae: 5.5128\n",
            "Epoch 347/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.2826 - mae: 4.9310\n",
            "Epoch 348/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.9428 - mae: 5.5194\n",
            "Epoch 349/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.2796 - mae: 5.7454\n",
            "Epoch 350/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.2887 - mae: 4.7286\n",
            "Epoch 351/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.2194 - mae: 4.7277\n",
            "Epoch 352/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.5378 - mae: 5.0216\n",
            "Epoch 353/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.2132 - mae: 4.6727\n",
            "Epoch 354/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.0582 - mae: 4.5775\n",
            "Epoch 355/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.7171 - mae: 5.1514\n",
            "Epoch 356/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.9526 - mae: 5.4078\n",
            "Epoch 357/400\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 4.1338 - mae: 4.6026\n",
            "Epoch 358/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.3483 - mae: 4.8134\n",
            "Epoch 359/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.2555 - mae: 4.7023\n",
            "Epoch 360/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.4142 - mae: 4.8851\n",
            "Epoch 361/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.7862 - mae: 5.2587\n",
            "Epoch 362/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.3480 - mae: 4.8531\n",
            "Epoch 363/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.8290 - mae: 5.3244\n",
            "Epoch 364/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.7993 - mae: 5.2650\n",
            "Epoch 365/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.6313 - mae: 5.1845\n",
            "Epoch 366/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.4478 - mae: 4.9392\n",
            "Epoch 367/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.2999 - mae: 4.7353\n",
            "Epoch 368/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 5.1360 - mae: 5.6322\n",
            "Epoch 369/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.4841 - mae: 4.9417\n",
            "Epoch 370/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.2684 - mae: 4.7728\n",
            "Epoch 371/400\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.2172 - mae: 4.6744\n",
            "Epoch 372/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.4291 - mae: 4.8377\n",
            "Epoch 373/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.2818 - mae: 4.7491\n",
            "Epoch 374/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.3331 - mae: 4.7725\n",
            "Epoch 375/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.1110 - mae: 4.5250\n",
            "Epoch 376/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.6387 - mae: 5.1355\n",
            "Epoch 377/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.1088 - mae: 4.5657\n",
            "Epoch 378/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.4929 - mae: 4.9143\n",
            "Epoch 379/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.4494 - mae: 4.9086\n",
            "Epoch 380/400\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.5211 - mae: 5.0251\n",
            "Epoch 381/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.4019 - mae: 4.8379\n",
            "Epoch 382/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.1295 - mae: 4.5939\n",
            "Epoch 383/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.0290 - mae: 4.5302\n",
            "Epoch 384/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.1439 - mae: 4.7613\n",
            "Epoch 385/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.6851 - mae: 6.1761\n",
            "Epoch 386/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.8423 - mae: 6.3045\n",
            "Epoch 387/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.1316 - mae: 5.6824\n",
            "Epoch 388/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.3059 - mae: 5.7371\n",
            "Epoch 389/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.6552 - mae: 5.1202\n",
            "Epoch 390/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.1871 - mae: 4.6328\n",
            "Epoch 391/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.0315 - mae: 4.5173\n",
            "Epoch 392/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.3527 - mae: 4.9138\n",
            "Epoch 393/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.9800 - mae: 5.3745\n",
            "Epoch 394/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.4892 - mae: 4.8803\n",
            "Epoch 395/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.1500 - mae: 4.6488\n",
            "Epoch 396/400\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.0663 - mae: 4.5549\n",
            "Epoch 397/400\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 4.2694 - mae: 4.6842\n",
            "Epoch 398/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.3121 - mae: 4.8300\n",
            "Epoch 399/400\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.2260 - mae: 4.7357\n",
            "Epoch 400/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.3882 - mae: 4.8681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpJnSn8JL7R9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "005e44d6-a965-487e-82aa-57667bbddb0f"
      },
      "source": [
        "forecast=[]\n",
        "for time in range(len(series) - window_size):\n",
        "  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n",
        "\n",
        "forecast = forecast[split_time-window_size:]\n",
        "results = np.array(forecast)[:, 0, 0]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plot_series(time_valid, x_valid)\n",
        "plot_series(time_valid, results)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0804 01:20:06.584640 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.847636 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.863845 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.876924 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.888723 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.902344 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.914324 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.926254 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.938125 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.949871 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.962784 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.974585 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.986170 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:06.999307 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.011994 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.024711 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.039090 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.051712 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.062988 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.076081 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.089275 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.103384 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.118675 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.145458 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.160926 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.171346 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.181940 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.193272 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.204944 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.217031 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.230051 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.241517 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.254158 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.265670 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.276063 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.285915 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.296306 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.306517 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.317456 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.330529 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.341696 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.352167 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.364854 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.376340 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.388659 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.402239 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.416256 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.431199 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.443834 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.455980 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.468821 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.481110 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.493473 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.504729 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.517152 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.529064 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.542663 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.556186 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.567795 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.578042 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.588307 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.598256 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.608829 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.619822 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.630867 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.640836 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.652031 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.663688 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.674064 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.689196 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.702270 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.714066 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.729861 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.742825 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.756760 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.768750 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.781822 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.795258 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.807200 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.818180 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.831961 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.844276 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.855987 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.867395 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.879183 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.890646 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.903822 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.914653 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.928160 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.938689 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.948913 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.959133 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.970811 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.980989 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:07.991112 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.000803 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.011599 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.021973 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.033480 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.044264 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.054697 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.064657 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.077562 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.086987 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.098756 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.109930 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.120567 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.133026 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.144955 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.155592 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.166072 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.177768 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.192399 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.206046 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.217082 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.231516 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.244282 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.258392 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.270464 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.281811 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.292886 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.305078 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.316010 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.329917 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.339658 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.351813 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.362438 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.376590 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.386027 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.399852 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.411999 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.423409 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.433838 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.447071 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.459794 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.470890 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.482661 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.496479 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.509603 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.524314 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.538717 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.552029 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.565645 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.577276 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.589164 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.602746 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.615898 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.631333 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.644647 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.656701 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.669474 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.682002 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.693481 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.705503 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.717209 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.733389 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.745185 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.755468 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.769171 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.781058 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.792206 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.802685 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.816273 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.831270 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.842089 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.852679 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.862630 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.873058 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.882882 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.892791 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.902809 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.915818 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.930478 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.942194 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.953282 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.965476 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.976959 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.988208 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:08.998553 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.011466 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.024044 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.035952 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.045857 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.056920 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.067323 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.077198 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.086502 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.096967 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.108129 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.121417 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.134870 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.147669 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.159451 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.170713 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.181188 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.192667 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.205469 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.216941 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.229851 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.242510 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.253539 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.265093 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.276259 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.289254 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.302059 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.315317 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.327224 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.339121 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.351146 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.362406 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.372390 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.383512 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.394151 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.405532 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.417773 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.437118 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.448542 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.460376 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.471412 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.483282 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.494249 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.505330 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.515883 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.531687 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.543345 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.553781 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.563987 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.575752 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.587049 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.598022 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.609223 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.623522 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.640524 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.651930 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.663981 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.677575 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.690445 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.701715 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.711849 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.723427 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.733729 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.747655 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.757695 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.769295 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.780269 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.790836 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.800586 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.810923 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.821645 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.831899 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.841454 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.855344 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.865224 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.874745 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.883934 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.894400 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.905092 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.914792 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.924179 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.935783 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.945419 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.955171 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.968731 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.979825 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:09.989789 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.000478 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.009863 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.020589 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.030480 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.040701 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.050340 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.061129 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.075300 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.088648 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.098952 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.109161 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.119153 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.130495 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.141009 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.151627 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.160928 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.171519 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.182332 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.196950 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.206909 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.217498 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.229914 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.240607 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.249771 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.260212 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.269898 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.280064 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.290218 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.301638 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.314504 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.328829 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.339600 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.351666 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.365078 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.376761 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.387858 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.398190 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.411656 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.423764 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.436779 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.447533 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.461039 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.472283 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.483719 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.494581 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.507711 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.519010 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.532513 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.543626 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.556659 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.567688 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.579086 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.590103 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.602005 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.613049 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.624105 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.634984 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.646556 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.657481 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.668223 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.678331 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.691065 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.702619 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.713617 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.724526 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.735043 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.745151 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.754939 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.764327 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.775971 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.787117 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.797055 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.810364 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.823691 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.836686 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.848546 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.859306 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.871378 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.882635 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.894203 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.905166 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.918783 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.935214 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.948575 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.960421 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.971842 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.982976 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:10.993841 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.004106 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.016507 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.030958 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.045461 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.057067 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.068162 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.078382 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.089450 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.099811 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.112558 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.123445 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.134751 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.145488 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.155630 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.165578 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.176306 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.186633 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.197110 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.208261 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.220159 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.233636 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.244961 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.254955 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.266228 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.276845 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.288002 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.298192 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.312275 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.324830 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.338263 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.349234 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.361385 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.374210 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.386810 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.399133 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.413465 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.426719 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.440496 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.451942 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.465251 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.477015 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.491059 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.503430 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.516033 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.530424 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.545285 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.557615 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.570002 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.581912 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.594431 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.607182 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.621803 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.637492 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.650611 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.662864 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.674268 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.684523 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.696789 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.708693 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.721559 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.733073 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.745515 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.759943 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.772160 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.786800 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.797587 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.811400 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.825011 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.839993 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.852536 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.866067 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.878164 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.889275 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.899789 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.911808 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.923564 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.936164 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.952306 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.965958 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.977944 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:11.989800 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.001186 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.013326 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.024800 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.036264 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.050959 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.063530 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.075373 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.087841 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.098469 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.110212 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.121549 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.132685 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.142988 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.157102 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.170400 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.182151 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.192519 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.204500 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.215467 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.226717 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.236494 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.247285 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.260114 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.273026 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.283502 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.294695 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.305893 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.317863 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.330685 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.343466 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.357116 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.370446 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.386961 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.397706 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.408790 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.419300 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.433574 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.445085 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.456312 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.467808 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.481493 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.496034 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.507478 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.517942 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.536463 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.549303 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.561309 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.572094 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.588014 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.601740 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.614977 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.629292 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.643512 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.655725 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.668684 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.681316 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.694321 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.709205 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.722459 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.736537 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.752315 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.764334 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.776673 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.789259 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.801755 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.816518 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.832468 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.844419 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.855299 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.867556 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.880317 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.893556 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.905722 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.920701 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.935213 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.947575 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.958884 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.970523 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.982344 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:12.993587 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.004746 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.020005 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.035693 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.048625 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.061149 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.074247 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.086116 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.097663 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.108438 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.123047 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.136013 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.146892 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.157020 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.168867 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.180033 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.191114 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.201795 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.213533 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.225843 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.236265 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.248657 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.264081 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.275600 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.287235 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.298588 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.311381 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.325136 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.341067 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.352506 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.364819 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.377637 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.389147 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.399462 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.412576 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.425896 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.441124 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.453102 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.464668 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.475889 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.491032 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.503564 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.516308 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.527883 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.541096 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.558155 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.570314 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.581833 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.591862 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.602671 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.613905 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.625204 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.635252 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.647870 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.662539 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.675452 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.686204 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.698419 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.710136 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.723611 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.736289 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.748859 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.760805 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.774475 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.785936 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.797471 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.808651 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.820541 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.830874 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.842559 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.853345 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.864952 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.875835 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.892635 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.905158 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.916558 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.930428 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.943307 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.955109 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.966394 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.976830 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:13.989106 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.001312 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.011331 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.021274 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.034070 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.046398 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.058458 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.069439 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.080513 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.090955 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.103109 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.112834 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.124598 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.138221 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.148687 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.157915 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.168318 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.177806 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.187446 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.196807 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.208189 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.219227 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.232307 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.242893 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.254420 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.266221 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.278620 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.289007 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.300693 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.311951 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.322503 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.333041 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.344475 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.355040 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.366563 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.377204 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.387882 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.399611 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.410446 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.423257 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.434508 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.446871 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.458640 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.470560 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.483495 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.494481 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.504868 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.515121 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.526117 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.538063 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.549941 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.561312 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.571943 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.582761 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.593968 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.606048 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.616770 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.629729 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.640202 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.650209 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.659869 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.670895 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.684252 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.699664 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.715047 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.730013 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.740900 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.753113 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.764787 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.777942 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.790051 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.802338 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.814569 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.828427 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.841497 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.853169 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.865835 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.880766 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.892527 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.904701 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.914585 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.926895 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.938321 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.949006 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.958883 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.970032 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.981589 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:14.992408 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.003367 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.015160 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.028286 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.039551 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.049560 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.060244 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.070126 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.079849 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.089572 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.101462 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.112443 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.124124 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.135233 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.147822 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.158101 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.171277 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.182864 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.194073 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.205029 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.216219 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.227084 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.237835 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.248187 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.258532 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.267949 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.280267 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.295603 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.307925 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.319805 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.333980 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.345999 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.357703 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.369218 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.380744 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.393606 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.406102 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.417056 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.430614 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.443099 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.453963 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.464674 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.474545 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.485777 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.499716 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.512720 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.528988 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.545855 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.559214 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.570930 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.581420 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.595073 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.608045 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.619444 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.631912 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.645999 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.659298 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.674504 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.685816 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.700577 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.711802 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.724319 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.736248 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.748202 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.759962 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.771263 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.783507 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.794452 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.804588 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.815708 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.829117 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.839199 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.850093 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.859884 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.870522 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.881022 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.890819 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.900959 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.912819 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.925094 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.937678 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.948598 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.959594 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.971207 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.981779 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:15.992001 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.002267 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.013219 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.024248 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.037899 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.049326 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.061753 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.072452 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.082487 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.093015 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.104457 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.115136 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.127037 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.138472 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.152892 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.164876 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.177043 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.188173 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.199587 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.210623 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.221865 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.231876 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.243132 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.256033 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.268449 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.278394 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.289720 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.300876 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.311902 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.324404 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.336301 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.348819 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.362045 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.375611 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.389017 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.400868 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.412453 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.424434 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.436964 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.447243 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.457070 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.471292 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.485635 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.497160 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.508476 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.519555 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.532788 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.544822 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.557102 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.567605 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.579310 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.590319 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.603397 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.616572 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.630698 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.642913 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.656385 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.668205 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.680490 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.691728 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.704129 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.717763 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.733266 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.746429 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.760319 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.772819 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.784338 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.795186 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.809982 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.826653 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.841636 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.853566 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.867067 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.878294 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.889520 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.899991 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.912246 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.923074 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.932972 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.944609 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.954767 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.966122 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.976278 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.987678 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:16.998102 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.009223 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.019002 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.032494 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.042646 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.053725 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.065035 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.076043 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.085818 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.096582 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.109110 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.122966 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.134645 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.146294 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.157182 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.169071 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.180395 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.191975 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.202140 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.213224 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.225765 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.238003 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.248484 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.260447 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.272403 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.284099 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.297088 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.308739 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.320151 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.332760 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.348135 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.372884 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.383946 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.395835 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.406579 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.419132 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.432084 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.446330 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.457748 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.468630 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.479204 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.490801 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.501173 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.513203 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.525702 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.540109 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.551857 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.567836 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.579510 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.592282 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.603799 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.617114 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.630313 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.642318 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.654644 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.668953 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.683377 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.698546 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.709924 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.722322 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.734049 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.746827 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.759558 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.772372 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.784770 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.798771 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.813318 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.829910 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.841388 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.853834 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.864598 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.874964 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.884554 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.896486 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.906628 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.917737 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.930114 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.940522 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.950294 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.961207 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.971893 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.983788 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:17.993809 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.004765 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.014319 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.024792 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.035058 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.045221 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.056858 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.068180 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.078946 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.091156 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.101644 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.112518 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.125268 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.138108 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.148607 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.159935 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.170608 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.181244 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.191171 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.202220 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.212443 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.225549 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.239606 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.251798 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.263572 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.274184 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.284382 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.295747 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.306936 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.318210 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.330083 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.341796 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.353270 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.365885 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.376624 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.387979 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.399188 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.410741 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.422404 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.436554 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.447691 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.458106 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.468822 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.481180 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.492765 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.506026 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.516678 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.530620 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.544682 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.555373 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.566080 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.578214 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.589673 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.601133 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.613628 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.624979 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.638128 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.650119 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.660934 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.671590 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.687144 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.698976 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.710255 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.720904 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.732413 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.743711 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.755851 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.768227 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.781152 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.794823 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.808259 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.820594 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.837473 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.850483 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.863147 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.875168 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.886769 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.899931 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.911890 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.924934 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.938009 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.950315 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.961294 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.972806 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.985266 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:18.996815 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.007221 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.017118 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.027927 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.038596 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.048913 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.058472 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.071438 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.083641 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.094771 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.105287 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.116465 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.127022 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.137129 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.146774 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.157265 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.167099 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.176625 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.189485 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.201122 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.211121 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.222512 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.233060 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.246259 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.257081 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.270334 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.283015 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.296051 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.307615 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.319246 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.330869 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.343515 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.355038 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.366630 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.377055 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.389200 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.400302 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.412060 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.425294 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.438149 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.449839 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.460712 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.470792 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.486141 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.497025 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.508427 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.521871 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.535702 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.548069 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.560529 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.570692 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.581794 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.592821 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.605334 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.615061 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.628180 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.639968 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.651095 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.661566 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.673216 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.684597 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.695914 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.711323 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.724678 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.739510 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.751167 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.761593 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.773005 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.783752 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.794613 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.804681 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.816263 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.828281 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.841296 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.852261 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.863122 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.872986 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.884925 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.897401 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.908068 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.918046 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.928244 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.938642 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.948506 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.959033 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.968380 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.979061 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:19.988911 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.002386 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.011887 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.022881 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.034451 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.044335 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.054865 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.065422 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.075340 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.084932 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.093839 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.103732 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.119761 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.132287 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.141966 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.151960 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.162503 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.173311 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.182679 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.192804 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.202414 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.211781 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.221077 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.231101 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.240995 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.250894 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.260172 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.270390 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.280398 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.292329 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.302565 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.313643 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.324326 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.334977 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.344451 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.355091 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.366972 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.378964 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.389092 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.400901 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.412295 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.423722 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.434323 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.446156 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.456325 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.467616 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.479382 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.491148 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.502299 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.515465 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.526910 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.540512 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.553187 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.564502 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.577403 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.589008 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.600045 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.611738 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.622912 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.634506 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.647485 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.657988 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.668151 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.683028 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.697457 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.708036 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.721280 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.732483 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.743906 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.754462 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.767649 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.778121 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.793460 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.804257 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.815770 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.828154 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.839857 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.850612 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.860485 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.869987 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.883540 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.893791 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.906101 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.915896 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.930079 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.941071 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.951786 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.961393 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.972877 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.982959 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:20.992789 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.002110 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.012453 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.022790 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.033559 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.043934 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.054977 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.069342 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.080327 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.090292 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.100288 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.109687 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.119133 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.129724 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.140848 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.151736 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.162084 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.174575 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.187244 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.200419 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.211407 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.222171 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.235331 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.245144 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.255877 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.266973 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.279372 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.292520 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.305676 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.316930 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.332571 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.345827 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.358023 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.369877 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.382952 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.395805 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.408843 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.420941 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.437023 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.448028 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.458416 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.469919 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.481853 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.494690 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.506458 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.519947 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.536954 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.548586 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.559571 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.569796 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.580821 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.592515 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.604424 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.614675 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.629015 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.640088 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.651107 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.662378 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.675028 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.687745 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.699227 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.709592 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.721729 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.733559 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.745007 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.755662 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.768714 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.781402 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.795393 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.807089 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.818078 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.828561 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.839722 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.850169 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.862016 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.873930 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.887116 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.900186 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.912709 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.924642 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.937412 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.948219 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.959245 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.968994 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.981666 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:21.993447 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.005291 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.015860 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.029107 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.040953 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.051765 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.062128 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.073084 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.084027 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.094750 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.107086 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.117330 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.131096 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.141633 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.151934 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.161821 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.172509 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.182620 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.192772 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.202434 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.214158 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.224665 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.235017 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.245090 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.255767 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.266196 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.276597 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.289246 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.301308 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.313204 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.326713 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.337255 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.348877 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.360026 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.374246 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.386188 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.402534 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.417968 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.433592 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.445600 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.458023 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.472630 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.485197 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.496894 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.509138 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.522049 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.538319 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.550196 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.560600 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.573830 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.585247 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.596086 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.605860 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.617882 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.628816 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.639546 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.649556 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.661037 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.671540 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.683271 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.693316 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.703450 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.714598 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.726322 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.736105 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.746500 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.756509 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.766503 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.776183 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.787658 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.799696 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.811404 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.824267 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.839194 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.850893 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.861823 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.872016 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.883009 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.897707 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.911541 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.923779 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.936633 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.948434 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.958727 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.968810 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.978406 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.988546 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:22.999321 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.010605 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.021090 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.035118 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.046627 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.057464 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.067774 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.077993 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.087828 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.097830 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.109912 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.120174 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.132617 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.143097 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.153106 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.162945 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.176249 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.186863 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.196505 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.207263 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.216546 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.230322 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.241591 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.253250 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.263147 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.273001 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.282286 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.292215 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.304167 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.314580 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.325301 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.337886 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.348201 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.358443 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.368891 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.380025 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.391313 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.403245 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.414624 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.429489 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.440642 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.451805 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.462261 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.472497 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.482508 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.494652 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.505081 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.517876 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.531818 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.544471 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.555663 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.566305 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.576390 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.587609 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.598580 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.609832 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.621431 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.634933 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.646590 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.657942 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.668142 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.679712 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.690442 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.701661 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.712681 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.726661 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.740226 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.751536 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.761776 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.773275 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.784139 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.796978 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.807667 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.818287 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
            "W0804 01:20:23.831993 139850187470720 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAF3CAYAAADgjOwXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXd4HIWZ/z8zs1Vdsi1XwNjGFEMo\noQUCMSUhoYT0SwGSHJeE9OSSSy6XXDpppF0KSUj5AQkhtBAg9OYYMM1gbGMj4y7LsiSrrrZP+/0x\nZWdXK1mWJXllv5/n8aP17Ozu7M7uzHe+b1Ns20YQBEEQBEGoDNT9vQGCIAiCIAhCARFngiAIgiAI\nFYSIM0EQBEEQhApCxJkgCIIgCEIFIeJMEARBEAShghBxJgiCIAiCUEGIOBMEQRAEQaggRJwJgiAI\ngiBUECLOBEEQBEEQKggRZ4IgCIIgCBVEaH9vwL4wffp0e/78+RP+OqlUiurq6gl/HWF8kf02NZH9\nNjWR/TZ1kX03ebzwwgvdtm3P2NN6U1qczZ8/n5UrV0746yxbtoylS5dO+OsI44vst6mJ7Lepiey3\nqYvsu8lDUZTto1lPwpqCIAiCIAgVhIgzQRAEQRCECkLEmSAIgiAIQgUh4kwQBEEQBKGCEHEmCIIg\nCIJQQYg4EwRBEARBqCBEnAmCIAiCIFQQIs4EQRAEQRAqCBFngiAIgiAIFYSIM0EQBEEQhApCxJkg\nCIIgCEIFIeJMEARBEISDmic3dvNq5+D+3gwfEWeCIAiCIBzUfOZvq7jx6W37ezN8RJwJgiAIgnBQ\nY9k2mqLs783wEXEmCIIgCMJBjWXZKCLOBEEQBEEQKgPLBlXEmSAIgiAIQmVg2TZaBSmiCdsURVH+\npChKl6IoLweWXaMoSouiKGsURblTUZSGwH1fURRlk6IoGxRFuWCitksQBEEQBCGIadkHjXN2PfDm\nkmUPA8fatv0a4FXgKwCKohwDvBdY4j7mWkVRtAncNkEQBEEQBABsG1T1IBBntm0vB3pLlj1k27bh\n/vcZYJ57+1Lgb7Zt52zb3gpsAk6dqG0TBEEQBEHwsGybCtJmhPbja/87cIt7ey6OWPNoc5cNQVGU\njwIfBZg5cybLli2bwE10SCaTk/I6wvgi+21qIvttaiL7beoi+84Ja7a2trJsWcf+3hRgP4kzRVG+\nChjATXv7WNu2rwOuAzj55JPtpUuXju/GlWHZsmVMxusI44vst6mJ7Lepiey3qcvBvu9s28Z+4D4W\nzJ/P0qWL9/fmAPtBnCmK8iHgYuA827Ztd/FO4JDAavPcZYIgCIIgCBOG5SqRg6UgYAiKorwZ+BLw\nVtu204G77gbeqyhKVFGUw4EjgOcmc9sEQRAEQTj4sFyf6KDIOVMU5WZgKTBdUZQ24Bs41ZlR4GG3\nE+8ztm1fZdv2OkVRbgXW44Q7P2nbtjlR2yYIgiAIggABcVZB6mzCxJlt2+8rs/iPI6x/NXD1RG2P\nIAiCIAhCKZbl/D1ow5qCIAiCIAiVhOecHRQTAgRBEARBECqdQs6ZOGeCIAiCIAj7HS+sqYg4EwRB\nEARB2P/4Yc3K0WYizgRBEARBOHgxK7BaU8SZIAiCIAgHLZJzJgiCIAiCUEHYB/uEAEEQBEEQhErC\ntCpvQoCIM0EQBEEQDloqcUKAiDNBEARBEA5aZEKAIEwyt67cwR+e2DKmxw5kdL50+2qSOWOct0oQ\nBEGoFGRCgCBMMveu2cUdL+4c02NfbO3j1pVtvLxzYJy3ShAEQagUpFpTECYZy7bJG+aYHpvTHa87\nb1jjuUmCIAhCBeGJM5kQIAiThGnZ5MYornKuqNNNEWeCIAgHKm6xJpqIM0GYHAzLHrPz5Yk6cc4E\nQRAOXKSVhiBMMpZlkx/B+Xr3b1dw9+r2svf54kycM0EQhAMWaaUhCJOMaQ/vnFmWzfPb+ljXXj7h\nP6c7YU1xzgRBEA5cZEKAIEwy1gg5Z54j5iX+l+I9Tjftidk4QRAEYb8jYU1BmGQMy8Z0/5Xii7Nh\nxFvBORtbtacgCIJQ+UhYUxAmGU+UlQtN6ntI+BfnTBAE4cBH+pwJwiTj/ejKCbCCc1beGZOCAEEQ\nhAMfaaUhCJOM55yVE2C64d03nHMmBQGCIAgHOpbknAnC5FIQZ8M7Z8OGNXVxzgRBEA50TJkQIAiT\ni/ejKyewPFG2p7CmLs6ZIAjCAYvXSkOrIOtMxJlwQGO5uqpsQcCeqjW9sKY4Z4IgCAcs0kpDECYZ\nwxpegO0xrOlXa4o4EwRBOFCRVhqCMMmYIzlnxsjOWdbtczbWwemCIAhC5SMTAgRhkvGuiHb2p3ms\npbPovtyonTPpcyYIgnCgImFNQZhkvB/d/3tqGx+58QW/ZBqCztkwBQFetaZMCBAEQThgqcQmtKH9\nvQGCMBEs+p/7OOcQzQ9r7h7MYVo2edMipmrAKMY3uaJMnDNBEIQDl0oUZ+KcCQcMtm1z3fLN7B7M\nYVg2D283fOesJ5UHioec66MMa47UhPblnQN86fbVRY6cIAiCMHXwDt9qBSmiCtoUQdg3Xu1M8r37\nWrj8j8/6y8yS8U05sxCizO+hIGA045ue2tTNrSvbGMwa+7bxgiAIwn7Bc85kfJMgTABhzflhtXQM\nAhDVCjlnHkHnLO+GK03LxigjwHL6nsc3+e6btNsQBEGYknjnCZkQIAgTgFEixGojyhBxFhRRQdFV\nTlyNps+ZJ/C8fmqCIAjC1EImBAjCBFIqomrCQ39o5XLOvOWv7ErwzJYeAAzT8sXeaJwzb4i6IAiC\nMLUoFATs5w0JIOJMOGAoraqsCg9dJ9g2Iyi6cobFjx/cwBdvW+3/v/C8zu2sbrJ6Rz//fccablix\nzblvFHlpgiAIQuVS6HNWOepMWmkIBwyjGbOU0U0eWd/JeUc3F62fNyx2DWRp68uQzhtF4swTcRf8\nfDnbe9IAzG2I88Ez5hecMxFngiAIUxJ/QkAFWWfinAkHDKUCqVw08rFXuviPG1eyrj1R5HblDJPO\nRBaAzV0p32HTVIW8aZMzTLb3pHnHSXN50zEzyXjFAq5bJ+JMEARhamJKWFMQJo7SsKZeRi91J3MA\nDGaNorBmMmf4vdA27R70c9NqoiHyhklfSgfg5MOaOHZuPb2pPFndDDhnknMmCIIwFZFWGoIwgZS2\nwygnmPozjsgKCiuAtr6Mf3tjZ9IPa9bGQuimTa8r3Jqqw8yqiwHQlciNKqy5vj3BQ+s6xvKWBEEQ\nhAnGK+qXVhqCMAGUCqRyztmAK84yulnknLX2pv3bm7qSflizJhoib1r0pR1x1lgVYWa9I846EtlR\nibPrlm/mf+96eQzvSBAEQZhoLBl8LggTh5f/9YbFM6iPh8vmnA2kg85ZwVlr63PE2aFNVa44cx5c\nFwtjWrYfDp1WE/Gds45Elryx55yzRNYgKRMEBEEQKhI/rFlB6kzEmXDA4IU1v33pEl57WOOYnLMz\nF01nW0+KwayzXk3MKWjuGHCKBRqrIsxynbPOgeyocs6SWYNU3pT5m4IgCBWITAgQhAnEE0phTUVT\nFfQyYsjLOcvkTfKmRURzfgKtvWlCqsKphzdi2fDKLmcEVK0rzjoTORQF6uNh6mIh4mFt1GHNhCv0\n0ro57DqCIAjC/kEmBAjCBOK5V2FNJaQqZcOa3hVSzrDIG5bvjO3ozdBcG2XxzFoA1rUPAE7OGUBn\nIkt9PExIU1EUhVn1sVGLs2TOCWmmchLaFARBqDRkQoAgTABr2vp5+7VP+RWVYU1BG0aceWTyTrWm\nJ74AmutiLJxRg6LA6h2OOKuLO2MGOhNZmqoi/roz66J0DGQLfc5GGN806OabDUremSAIQsVR6HNW\nOepMJgQIU54P/uk5+tK6n6jvOWcjZXh5OWdBcTa3MU4srHFIYxWtvWlm1kVZML0acJL/vecHmFEb\nY01bP9UR5/H6MIPPbdsW50wQBKGC8ScEVJA4E+dMmNKkcgZ9bgWmV2EZ0hRCWuGr7f3eqiOav8zr\nc+aFNQEWNzshzSOaawB46/FziIWdx3QmsjRWF5yzeFgtbkI7jE2X0U0/lCriTBAEofIwpZWGIIwv\nj7Z0+bc9hyqsOs6ZRzysEQurxCMFIZbRTXKGRW3AOVs80xFli9y/l54wl7Ar8nTTLgprxsIaOcPa\nY7VmsIVGUsSZIAhCxVGJrTQkrClMaXrc/mPgOFOaqqCqStGPrDYWwrbxhRYUnDPPGQM4whVll512\nGHMb4iyZU0fXYNa/P+icxcKa8xyu4MsPUxCQCIizVF7EmSAIQqUhEwIEYZwxA+0ykjmDsOb8uILO\n2SeWLuKX7zuRaCgoziynlUZg2WHTnPyyQ5qquOJ181EUhYhWEG/TguIspJLVLT+UOly1ZtAtk0a0\ngiAIlYdl2RUV0gQRZ8IUxw5EE1M5w3fHNLXw1Z4/vZrTFkwrEmKZvIlu2L6Yg2JnrbCscP9r5zf6\nt6Ou4+blkRnDhDW9ZrYAyZz0ORMEQag0LNuuqJAmiDgTpjhmQJ0NZgviLBQQVZprVRc5Z4YT1gwK\ntnIE7z9+XoN/23uujNtYdljnLBjWdIXcK7sSnPzdR9iyOzniawuCIAgTj2nbFRXSBMk5E6Y4VkCc\n5QyLhqqhYU3PRIuGCiHKTN5ppRHWVO78xBk0B9pkBPGupmqioaIrq2CuGgyfczZYpiDgK39fS3cy\nxwvb+1gwo2aP71EQBEGYOGy7cBFfKYg4E6Y0dkk0MeQqsaA485ZFQsUFAV7O2YmHNjIc02qiAHz5\nLUcVLS8VZ8M5Z4OuIKuKaKRyBgNpnZd29LvL5OcnCIKwv5GcM0EYZ8yS+ZmeAAvmnGm+cxbIOdOL\nZ2sOx9yGOOu+dQGXn35Y0fJYuPhxAxmDr9/1clGOGRRyzmbVxUjmDJ7e0u3flzclB00QBGF/Y9p2\nRTWgBRFnwhTHKrHOPMcsmHPm/eiCzlkqZw5przEc1dGhDlcsVOycPb+1lxuf3s7KbX1Fy5NZg6qI\nRm08TDJnkMgUwpylI59+s2wz3/nn+j1ujyAIgjB+2DaoFWadSVxFmNJYlo2iQERTybk5ZFDcTNC7\n7Tln8bDm53/tqSBgOErDmv0ZZ67nYEmj2cGsQW0sRG00RCpnFN2fKwmFrtjcTcdAFkEQBGHyMCsw\nrCniTJjSWLbjjEVCrjgLDc0588SZJ8SaqiPs7M8Ao3POyhEtCWtmdUdoeWHMT9+8ihMOaSCZM6iJ\nhqiOauwezBWFPUtHPmXypl/9KQiCIEwOVgWGNUWcCVMay7bRFIVoSGMQg7A6tFqz4Jw5bldDVdgX\nZ1URjbFQGtb0SGYN+tN57lndzj2r26mJhlgyp47qaIhkzihqrVFa4ZnOm2RFnAmCIEwqVgWGNScs\n50xRlD8pitKlKMrLgWVNiqI8rCjKRvdvo7tcURTlF4qibFIUZY2iKCdN1HYJBxZOf5pCyNIPawYc\nsdI+Z02BTv/z3akAe0tpQYDHYNZgfXvCf72T5zfynbcdS000RCpvMJg1/EkDpc5ZVjfJ5EWcCYIg\nTCYHW7Xm9cCbS5b9N/CobdtHAI+6/wd4C3CE+++jwG8mcLuEAwjbDWt6YcZQmfFNpWHNhsAA84XN\nYxVnwzhnOYOX2wcAePor53H9h09l8cxaaqIhklmDwZxOfVUYRRnqnGV0J6xpl/YHEQRBECYMLwJT\nSUyYOLNteznQW7L4UuAG9/YNwNsCy2+0HZ4BGhRFmT1R2yYcOJiWM3bDC1lGRiwIcNZprAr7981w\n+5jtLaU5Zx6JrM7LOxPMqY8VOXSNVREMy6a9P0ttLExEU8uKM8sevqGtIAiCMP5YdmUNPYfJb6Ux\n07btXe7tDmCme3susCOwXpu7TBBGxCoJa5ZzzkpbaTS6zllIVcb8gxzWOcs6ztmSufVFy6fVOK/Z\n2pumNhpyxJkxNOcMIJsvL85e2ZUgUdJHTRAEQdg3LNtGrbDGYvutIMC2bVtRlL2O3yiK8lGc0Ccz\nZ85k2bJl471pQ0gmk5PyOsLes2NHDss0yCSdPK++nm6WLVvGq+2FxPvnnn2GzXGVHdscYdPdvh2A\nxihj3q9GoPltWAW3WJMt7bvZ2m9xXF2+6Lnbdjvb05vKkx3sA9tkW2sby5btpidjURNWfLH22PIn\naIwNPVJ8/JEUb54f5tJFkSH3HUjI721qIvtt6nKw77tdHVnyWauiPoPJFmediqLMtm17lxu27HKX\n7wQOCaw3z102BNu2rwOuAzj55JPtpUuXTuDmOixbtozJeB1h73m0/2WiPbtonl7Hhr5u5s2exdKl\nJ5BeuwvWvAjAWWc6szM7n2/lry1rOf6Yo7jplTUsnN3I0qWvG9Pr2raN+vB9WDbUxML0pR3h15VV\nsbF4/YlHs/Tkwld6WtsAP33hSQAOnzebtkw305un8+uWFM9v6+Oy0w8FWgE44eTTOHx69ZDXyzxw\nH9NmzWPp0mPGtM1TBfm9TU1kv01dDvZ9d3v7i3TpiYr6DCbbyLsb+KB7+4PAXYHlV7hVm6cDA4Hw\npyAMi9OfppBP5oU1taLB587tC4+bza/ffxJHzqoF4IIls8b8uopSyHMLzshMuK0yZpYMUm+qKbhd\ntbEwkZBKKm/wvDtRYFNX0r+/XMWmbtruX8lHEwRBGE8OqgkBiqLcDCwFpiuK0gZ8A/gBcKuiKFcC\n24H3uKvfB1wIbALSwIcnaruEAwuveaCXoO+10iiq1nTzympjYS56jVNn8sh/voGFM8ZWqekRC6tk\ndJPq6ND8s1JxNi1QHFATCxHWlKJRTl2DOf92uUa0niiTYgFBEITxxbvIryQmTJzZtv2+Ye46r8y6\nNvDJidoW4cDFstxWGqV9zoLiTBv6q1vUXLPPr+0UBehFzpnHzLrokHWrIhrpvOkUBIS0ouT+3YmC\nOCvXiNYXZ8ae0zRfbO3jqFm1ZbdLEARBKMYZ31RZ6qzC6hMEYe+w7OJWGmG/WnNoE9rxxqvYLJ0y\nEAmp1MfDQ9b3WmvUxkJENIVEpiDOgjM3Rwpr7sk5S+cN3vPbp7ltZdso34UgCMLBjTcGsJIQcSZM\naUonBIRG6HM23nivWepQzayLlm3R4YU2a2IhIiGVQTc/rTZa/Pj0CM5Z6VSBUrK6hWHZ9KXzo3wX\ngiAIBz6GaQ1pX+RRia00KmxzBGHvKJ0Q4IU1w9rQPmfjjeeceTlnnjM2szZWdv2CcxYmrKl+WHNG\nbXEINFvGOTNGWRDg3Z+WMVCCIAg+1zy0gff9/pmy9x1UEwIEYTLwJwS4oixSplozNEHOmTdf0wtr\nNrsiq7QYwKOp2rm/Juo4Z16oslSclSsIyI+yIMC7MkznjRHXEwRBOJho68vQ1pcue59MCBCEccaf\nEBD2Wml41ZqFr/ZElUiXttLwRFlzXfmRUN6UgLpYyHf4YHTizLC8goCh4iyrmzy4rgMIOGc5cc4E\nQRA88oZFbriw5kE2+FwQJhzbdhL+h6vWnKh8Myg4Z9WuczbLFWfDO2fFOWceQ8RZuYIAY/iCgB8+\n0MLH/vwCz2/r9ScXpMQ5EwRB8MkbFjl9+JyziTxXjAWptRemNF4JdEGcudWaXnhzAq1qv1rTTeg/\nfEY1EU3liGHadFywZBa7B3PMrI35A9oBmkty1Mq20nCds3I5Z91JJ/l/Z1+GuLtNwZyzTN4kb1pl\nK0gFQRAOBhznzMS27SEhTNMaumx/I86ZMKUpDD73WmkUN6GdUOcspKEoEHOF4aFNVTz9lXM596jm\nsusfPr2a/734GFRVKRJnQeesNhoq34TW8Ko1h/Y5q4874jCR1csWBPzwgRau+NNze/v2BEEQDhjy\npoVlF89F9vAiMJWEiDNhSuP3OQsXizIv52yiw5phTSUcKhQGTKsp30ajlGBY0yskiGgqNbFQ2bCm\nd0ApF9asizmO2EBa94sMUoG+ad3JHN2BCQSCIAgHG16+brm8s0pspSFhTWFK4zUP9JwoT/R4UwEm\nMo3gtAXT6E7lfbeuOjr6n1OwIMArIIiFVeJhbeRqzTIHlpqY87oDGR3DXS/4HKZlY5a5WhQEQThY\n8KIKOd2kpuRYbdoyIUAQxhXniifonJU4aNrEfcW9QepenpuX7zUags7ZNLfFRjyiEY9oZXPOjBEm\nBNiu7kpkdf/+VK5YnJWz8gVBEA4WRnbOZEKAIIwrplsCXTq+yQtnTsYP7ri59Zx0aAOHTasa9WO8\nfmyxsEqdmzNWFQkRD2ukcuaQ0KY/IaCMOPMOOgOZQlgzE6jWdMSZDEwX9p6cYXL9U1vFeRWmPLmR\nxJm00hCE8cWbEBB321n4/c78goCJ34ZFzbX8/RNnUhsbfTWk55zFwhrRkEYkpBILO87Z01t6OPOH\njxWFMEca3+Td15vKFwoCdBPLPaGato1pFk6u6bzBN+56uWjwuiCUY8XmHr55z3pWt/Xv700RhH3C\niyrkjKGRiUpspSHiTJjSmJYzduP4eQ18923H8roF04DAjM0Ks6o9vJwzLxRaFwsRD6u+A9ibytPa\nm/LXH2nwuRey7EkWxJltQ9Y9CJWGNV9q7eeGp7fz/Nbe8X5bQoWxbEMXL+0Yu7DyRokN1x9KOHhZ\n355gXfvA/t6MUeOHNct8l2VCgCCMM14rDU1VuOz0w3xHynfOtMr6wXkEnTNw5m3GIxrbewqCbGNn\n0r9dCGva2HZxiMk76HQnc76Ig0I7jdKwZspdnsxJo9oDnavvfYVrH9805sd7IaA9jQ0TDj6+e+96\nvvPP9Xv9uA0dg3z65lV+8dJkMWLOmYQ1BWF8sYdJ5PQnBFTY1ZCH55x5zXOPnFnLwhk1RaHGjV0F\ncRY8kJWeKD3hlsgaRTM1vRFORolz5rXZEHF24JM1TLLDjKwZDXlj+HC6cHCTzBlkxuCoPru1h3tW\nt/vNsyeLqRbWlFYawpTGtG0iZRrUeKJsouZq7iuec+blyv328tcC8N5TDmVj1yDXPLiBTQFxlg84\nYrppE6wENwL3dQxk/dveCCfLsrFt9+pQVfzlyayIswOdvGGVrf4dLd6JTJyzyuGzf1vFuUc1c+kJ\nc/frdmR1s2iG8WjxjlflipsmimA7oXJhTbPM1ID9jThnwpTGC2uWoqoKCoXwZqXh9WWLhYrbbxwz\np45LT5jLEc013L26neO/9RDt/Zli58wo75wBdCQK4swPa7phUH/upjhnBw25EYY9j/bxMLknUmFk\nHlnfyfPbRpcvapiWXxg03mR0c0xV4J5Imqz2Pjv7M3QNFo6L5X4PlTghQJwzYUpjWcPb0ZpSeb1r\nPAo5Z+Wvj2bVO/M2BzI6W7tTRSfH0hNl0NUIhgq8EGfhYGgRQfV7oA2Kc3bA4wx73hfnbPg8HWH/\noJt2kVs+Em+/dgXnHz2Tz55/xLhvR1a3xuacecejSRL8V/35BeY0FOYXDxfWrLTreHHOhCnNSM0D\nNXVixzftC361ZqR849rXL5rh307ljKJE/5Gcs8FAzponwkqvVD3nLCXO2QGPOGcHFrZtkzetUYeZ\nd/Sl2R6o+h5Psnmz7MSSPWFak1tk0p3MsWtgZOfM6ZdZWecKEWfClMYcocpGVSpXnPnOWai8OLvw\nuFnc86nXA07umD5CQYBh2n74NphHltGLnTOv15lUax4cGKaFadn76Jy5OWfinFUE3gWWPkrnTN9H\ncT4SWcMck2gvOGejD2sGC532llTOoC9diCiU+z3YduXlJ4s4E6Y01ggz0bQKFmfeJIPoMCOfFEVh\nZr0z1imZNYryM8qFNWvd+ZrBUGWpc6Zb3mgnyTk7GPBE/L5Ua3rJ0+KcVQYjNaMuv/6+ifPhMEwL\n3bTH9L0IplmMhnXtAxz3zYfY2j02BzCdN+lPFyIKwztnY3r6CUPEmTClGa6VBjjLKy3J08NroTHS\nPM7aqDNxIJkrDh+UC2t60wkGs7pfIJHJF4sz7693FSo5Z5XDs1t62DbGk89wFJpujv3k7Ak8cc72\nH7sGMiy95nF29KYLrU1GIYq8EGh2AhoIe4J/b9wvj711/9r6MpiWTWtveq9fK29YGJZddKwrP1tT\nwpqCMK6YI/Sn0ZTKs6o9IpojyoYrCPDuUxVI5vSiq8zSA7Nh2tS4vTVSeZOaiHfbDWvaxWGEpDhn\nFccXblvNr/ahWWw5vJPQeDhn+TGchIXxYcvuFNt60mzoGCyI5VGIM08ElUuA31e8C7+x5I2ZexnW\n9FrBjKX1T7lwaPmCgMo7V4g4E6Y0w7XSACfnrFJbaYRDznaN5JwpikJNNEQqZ6IbwYKA4oOaHghr\nghMqjYc1v5WGdxAsOGdjP9gJE0NWN0lkxnfWqeeymJY95so4yTmbeO5e3U5PMjfs/d5nnwwUBo3G\nOfPWmRDnzBVMpdvRnczxzt+soL0/M+xj/T5nowxrehcZg2OYBezl1xY9X+DzSOUM3vzz5XQncxLW\nFITxxBqhyiZUwdWafp+zEcQZOGOdBrMjFwTkTbtInEU0haqI5l81WnZxjkdSqjUrDt20fadzvAg6\nBGN1z6Rac2IZyOh85uZV/OOl9mHX8X7vg1ndzzUbTUjQu6DblybEWd3k0Vc6yy4Hx3EyA/mwr+xK\n8ML2PtbuHH7mpletOVrnzAvLjyUNI1PWOSt8l9v6MrR0DAKV1+dMxJkwpbHs4QWYWsF9zsLayH3O\nPKqjmtNKI1gQYJSGNS0iIdWvAA2HVKqiWtH4puBfb3kyb0xYg0ph79BNi2RufMNPwZPQWPPOPNdG\nnLOJwQsPjhR69D77wVzhIq1ULD/W0smbf768ODfVH1c09n338PpOrrxhJTtK8r2CblxwW7wLvpFc\n4ELO2ei2y3utwVFeTCayOm/91ZOsb0/4RVFBgp91f6CKUyYECMI4MlJYs5KrNWfWxTj3qGZOnt80\n4no10ZATzihz0PXQTYuwphILDH2vCoeKxjdB4UrVO4DaNqQnoJJL2Ht00xp3J7NInI3ZOSsfvhLG\nB8+BGslF8sOaWWPYAo0rb1hJS8dgUSf8Qlhz7L/x4YqHMoHnLBZnzvLECC6XudfizHPORhfW3NSV\nZE3bAGt39pd1o4O/hf6AiKy0C3kRZ8KUxrLsYe3oWdUqh0+vnuQtGh2RkMqfPnQKR8+uG3G9alec\nGZbl56eVHtR003bEmXt/WHNsCLMpAAAgAElEQVSds/xQ58y2nfDZ9JoIIHlnlYBt205Yc5zFWfAE\nPtYTdE6cswkl51c9On9f2tHPSzv6i9bxfu/BnLPS0Udu5kKR8BgPceYVgmQNE9u2+fGDG9i8O1n0\nnMEQqyeGRnLO/Pcw2rBmQJx6XP7HZ/m/RzaWXb8r4eTvDWYN35n0UJTinLOBQIsNrcLUUIVtjiDs\nHSNNCPjUiTH+9+JjJnmLxpfamCPO8qZNddQRX+VaaYQ1xRdnkZBKdSTkizPLb6XhlNVbNjTXOuNM\nkrnxTUIX9h7vRDve1bPj4pz51ZqVL87WtQ8w/7/vZX17AoCWjgQD41xkMd74ifXud+AH97/CD+5/\npWgd77NPZo2yrTS6A8UEQTHii7N9ENaeY5/VnV5hv3p8E/eu2TWsc+Z9hxMjuFx+ztkoCwKyJTln\nlmXz7NZeXm4vn9e223UPUzlzSEFATTRUFNYcEOdMECYG07YZw3i3KUN1JEQqZ2CYFlVui4xhw5pu\n/lpYU4lHyjhngaTzmXVOg1vpdbb/SGR15v/3vfzt+R2AE2627fHLARwP52wq9Tlb/mo3ALc83wrA\nu3/7NH98Ysv+3KQ94hdc+CLI8n+3HmVzzgL74/mthSHoQdHkVXXnDWvM3ytPQOV0y3/u3lS+6PsU\n/G4Ucs6GP67sbZ+zrCumBt0Lye5UjrxhDevO7R50xGoyp5MuueCpjYZKwpqFnDMqS5uJOBOmNnYF\nNg8cT2piIZJutWaVO4eztCCgNKwZUhWqA9WaXp8z0yqEzrzB6tLrbP+xZbfTdNYTEJa9920Pugaz\nPBc4OQcJOgSVmHNmWjY/eqCFzkR2zyuPAq9ieXtvGtNtPNobSPiuRPycs0DX/NJQXJFz5vc5Kwib\noIOULuOcwdD9b5gWd720s0i0Pd7SRUtHomg9T0BlddMXZz0l4qx8zpkjnDoGskPC9YU+Z6NspaEX\nhzXb+pw2HcO5ol2+ODOHCN3aWLhYnAXCmuPdymZfEXEmTGlGCmseCNREQyTzXlhzD85ZqBDWjEdC\nZcY32f4yL6wp7TT2H95nHw4ku+xtO40v376G9/zu6SF9pf7+YltRR/Ux55xNYFhzY9cg1y7bzEPr\nOsbl+TxB0Nqb9t9vuWq9SqK0X5hh2kXuF5T0OSsT1gwKjGDriOA6pfv/qc09fPZvL7GmrSDs/uv2\nNfzi0eI8rkJo1PRFY28qV3QREcx/S5ZUa7792qeGNFfee+fMayXiPPdOV5wN5/oXxJkxpAltbaw4\nrBksCPAct0pBxJkwpTGt4ScEHAjUREPYNgxm9IJzVnJQ83LOooGwZnVEI5N3wmRmIOfMO/l7ztlI\nVVXCxOKdyLwWKLD3Ytn7Jvz12VZ/WSZv8p+3ruamZwrLxu6ceWG08W+5sqvfccz60uPjWHhOSmtP\n2j/pVsLFRyKrD+tQl/aR08uMW9pTE9pE1vAbqAadovwIzpkX7vM+H9Oy6Unl2NZd3DLDe51gWLMn\nmS8Jn5YJa2YNBrM6uwayfoK+R+ms3z3hCcvEKJ0zT2SlckYZ5yxETrfIGxaPtXQykNb9OcddIs4E\nYfwYqZXGgYDnlvWl8744Cx5oTcvGsimp1nSb0OpmUYNIw7T9k8SchjhQeVb+wYT32UcD4mxvw8wz\napzcwZufa/VPpJ4A3x1IFB9zzpk3n3MCnLNdA544G5/Qo1d5Z1g2q1r7AIacnIdjY+fghBUPfPbm\nVfzP39eWva+0lYZu2kP2VT7gHJXrc5bI6Myqcy62MsNUUZY+Z2G0lyt88ja27biOrT1pv6jCCIY1\n8+XDmhnd9D97LwE/kdH9/ZvRi7/TwRzYIKZl87t/beaBl3eV/Yy84qW2vrT7f6NsaNRrJ5IsK86c\nsOb1K7by79ev5MlN3X5FvzhngjCOjDQh4EDAy6PpS+uENZWwphQdmL3bYU31W204rTQcxy0Y1jEs\n2z/ANtdGUZXikIgwuXiffVFYcy/DcN5JtieV98M9/tzDfazWtG27kHM2AQUBuwac7e1LjZM4C4ir\nVzuTwOjDxG/82XIu+sUT47IdpXQmcsOOM/JCdnogDyvjCzaL7mQu0EpD990w3bT9fLGBjE6zJ86C\nOWdFBSHl3TgvbN2fK1QMn33N41zofhZ5P6xZ2K6+VL7odX67bDMX/Hw5EHTOdHa677lUIBUmBBRv\n0xdvW83372/hmgc3FC33haRu0TGQZUdf4bMsvZgxLZvupPN9SmYNUjnDH+Gnqc5Fa84wiz6PI2bW\nAvCOk+ZSSYg4E6Y0I00IOBCojgTHMqmENbXooFsQZ0pRtWa167IFS9oNq3CyjYU16uLhim81cKCx\nezDHb/+1Gdu2fccoeHGxt2G4YP7MDtdRKM1Zctbbe3FluK4sjE/OWcdAlic27vb/X3DOxuc72J/W\nmes6wr0pxwVJj0Lses5MW19mXKtlPXLG0JYO/n0BIQaOSDMtG920+MdL7bzhR4/74bysbhVVH3rO\nWCJbcM6GLwgodc6c/3vOmSfOSinnnBmWXRQC3NaToiORJaub/vc3mTP88GPpPijM1iy8pm3b3LfW\nccwaqiJlPyOA07//KMtfLXyHSo9ffem8Hy1I5Q3Susk0t6djRFOJhlRyhkVzbdR/zIyaKBuvfgtf\nfNORZT+D/YWIM2FKc6CHNWsCMzNDmkIkpBadKL0DdGlYM+6KuuCVpWlZfu5QWFNoEHE26Xz8Ly/w\ng/tb2Lw75YuzYNLy3oY1s7rFDPdEs6O3vFMBw49venpzz5DqQP8xZS4C9oX/t2IrV16/0j95+s7Z\neIU1Mzqz3VzKXteNG41z1hNw7rb3pEdYc2zkTWtIYrpHuZwzcAR2x0CGVN4s2r7edPBiy1k3kTFo\nrI4Q0dTiXDBzeOcs6EYBDAwjzoLD04PPvTPgXnnisS+d97+/tg0b3MrPtD7U3YJi52x3MudvU+kF\nSrkKZu87X9qyw8tvm1YdIZk1SOcMplU760ZCKtGwRlY3i4oY6uNhwpoq45sEYTyx7OEnBBwI1EQL\n4izsOWfDhDWDEwI85yxY0WSYtn/AjoRU6uPhomolYeLZ4A5ZDqkKfaniPB0Ym3N2aFMVYU3xqzOD\nQsAzlcs5Zy+29vG+3z/DLx8r32m9aE7jKJy3jpTFcd94kG3dqbL396ecsFyP62qNe85ZRme265z1\nJD3hu2fnrCeQm/fkpu5x2ZYgOd0aNlyd86s1i/OwsvlC64pgXmgwBOxdaCWyOnXxELGwWtKEdhQ5\nZ3qxc1Z6KNXLOGeAH7IMbl9/WieVM/wcypZdznd9iHNWplrTE3u1sdAQ5zdrmH7KBsD1Hz6Fb16y\nBBjqnHmi/NBpVSRzBqm8SW0sRDTkHDsjmkresIq+zw1VYSoREWfClKZsK41MH6y9nZkdy2BwfMr0\n9xde4j4URJd3UoeCOAtpij9b02tCC8UHdsOy/YNSRFMlrLkf8IY3G5ZVcM5yY3fOcobT/25uQ9wP\nawZPxNXREIpSviDgCbdp63AhTy/0FVKVIc7Z1+96mavvXV+0rDNtMZgz2DqMOPOaiHYO5LBtu1Ct\nmRq/as3pNRFH+Lqf7Wg+z6AztXKb0zPuzlVtvPu3K8Zlu0ZyzrycM88FCzpnnmMU/A0H+7blTYus\nbpI3LOpiYaoioaLXGanPWb6Mc9ZYFWa2Gx71UkX8ak3DLHbO+jO+kPOeuy+dJ5Uz/WNWi3shMjTn\nbGjFqRcCXTyzdsj6Od1ieq0TmqyNhlh6ZDOLmmucz6ZkEoE3f3NOfZyc26i2KqJRFdGIhlQiIRXL\nLg79V6o4C+15FUGoXEzLpijlzMjDb14PiTaOBmi7GT5wK6hh6FgL2X7ob4VEO6gahKLQvwPySVBU\nsC3nOSzDuV9RQQ25tzVnuZkDI+esW90M814Lpg7TFkG4ynkMwMAOSHWDkYXcoPMvVg/Tj3Bu51Nw\n0hUw50ToWONsoxZxHjd9MdTNobEqTF0sRCJrENYUTjy0keWv7sa2bbZ0p3jQ7REV0RzLHpyQpVfl\nOZgrFmd6wDlrqIr4B0Vhcskbtl8QUOyc7WVBgG4xrVrjkKYq2nznrPAc0ZCGYdrDOmcATdWRIfd5\nzw1OaD2rW3z9rpe54nWHsai5lue29vrfMf89uS87OIwg8lzcjkSWQ5uqyOgm9e4FQt6wilqK7C26\naZHMGTTEI8Qjmu+g5A3L7wM4HJ7LVh3R/H3xyq5BVm7vw7btfQ53eW0oLMtGLcmPzZY6Z5bnVBXC\niAPDOGerWvv8Vir18TDxiEZGH+qqB1/HIx8QXeA4Z821cU5b0MSNT2/3896KwpqllY/RUFErnt2D\nOfKmxez6GFu7U74wLhWm5ao1vePQEc01tOwqboSbNUwaqhzReMaiaQDUxUNDPhsofMe8VkG7B3Ms\nbK6hKhIi4oozKHaovbBnpSHiTJiyeMm7RQe8zpch0QZvuYYXO0xO2nAN/O7s4geGYlA3x0mMMLJQ\nOxuqmhyxheIINlUDywLbBMt0RJltgloFWtRZR1GhdzM8fa3znHqpY6BArM5ZP1rjCLPdG+Dl2531\nFQ1eugmidZAuE06J1KLMOJJrotP4ZvZiQtpCzlg4jTtX7WRD5yB/fbaVG5/eDgwNa1ZFNDRMkplC\nyMY0C3Z+WFOpj4for/AO6gcSwWRz3bR8FyR4otjbJrRZwyQaVmmui3K/m1BdLM5UDEsdcnI2TIsX\ntzvibLh8NO8EXhMN0daX4cantzOrPsai5loGswalufNe1/rkML3zvBN5ZyJLu5tvtmROHSs299Cf\nzvsVh2PBc5caqsJUR0J+OwVwPo/6+PDizCsemFUfK5pdaduOaIqEigWVF7oLjXJSdj7ghpUKWk8A\n66aFZRV6EjrOWaHbfkhVMCzbF50AH/3zC/7tuniYeFgrakI70vgu73WDztnc5ijfvvRYDmms4ur7\nXiGjm0MmBES0Qs5rbSxcJM68UOfs+njwpYat1gz2OdvZn6ahKsyM2ihp3SwSxVnd5IyF03nLsbP5\n0BnzAUeMgrPf71zVxn1rO/j9FSf7FwZe7mFPKk91RCMe0dAUhYi7zzzh+PsrTubMRdOpREScCVMW\nL6ezKKzZ/qLzd/EFJDJb4aPLYPPjjtiadwrEm6B6+tDkin3BO0sNdoCZd0SebUHtLIhUD13fyDkO\nWaYPHr/aEYiHnO6IP1N3XLOejY6Q293C0vy/uCXyIg8Yf+LMmXOZQR8rNvUUhWzCmkKVavDl0M1o\nxlVM37meZ6OfpXv1WcAHnJcNOGchVaE+7hxcx8MdEPaMV+IPzsnYE8bB5GRPqG3eneSBlzv4xNKF\nAMPun5xuEQ2pHNJYRV/aaXYaPBFHQyqmpfknY49XO5P+iaxcdaf33FCc99jrvody/fG8c3AyVz5M\n6YWcOhNZf1j34pm1rNjcQ19a3ydx5jko9fEwVRGNwEdKOm/4J/Ny9CTzREIqTdURX9B4rk7eLHb0\nLMtmyTce5O0nzuVn/3bCHrfLMK2i6sFSceZVSxqmXSRWMnmzyFWbURtl92CuSJwFqYuFnN6Gw+Wc\nlYY1TbdaM5BzdoKbZB9zUyKyuhlwzhxxVhcPE1IVOhJZqqMaKhYaFjoh3/1a2Owc82pjId5y7Cxu\nXdlW5IwO55zNa4xTFXFaAGV1i3hEw7ZtsrpFdVTjs+cf4a8fD2uEVIWBjE5rb5rHWrqwbdv/js0M\nfJeqIiGq3e9EjZXgnepyDumeTyQ0nzceM7PwoSS7oHrG+J4b9gERZ8KUxTvoFbXS2LkKqqZBw6HA\nVufvaz84sRvi/ZjrZo9u/ZBro1c1wUU/Kb/Ogjf4N2+94++8fc3HuaTlv5m9to3nYwM8/8w5rGz+\nH3+dsKayoPsxTgvdQ/urrTS/uI5BwhzZeR8LlaVstuc6OWemTSTkVCbVx8OYltOYtjZWmXkXBxJe\nThg4ydPlxtd44uzOF3fyq8c3cdi0Kj7111Xc+5nXs2RO/ZD1c4ZFLKwxp8E5Ge3qzxSdoCMhFdO2\nfRHgUdygduScs9pAxXBvymlVMJgzhoTo8u7TDOecJQPOmdc+Y+GMav959wWvsKW+KuznW3rsKVTc\nncwzvTpCJKT6gtQTEHnDgkDUa+1OZ9zRXS/tHJU4C1ZMpnMm1BbfH3TOjCIxVdyLa1p1hN2DuWGL\nJ+riYZbYG/mPjmug9x5oOrw452wY58zbx4mc7Tc0joVUZtCH3fochuWEvL2wZjyi8qULjuLTN69i\nU1eSn4avZaHSziX57/lJ/Yc2VfHc/5zHtJoo16/YxuvVteR2ziNy2PFAoFozIEbb+jIsnFHtN9pO\n5w3iEc3//GKBggCMPMpz13Fr5C/Yrx7O32d8CtOySedNklmDqohWJMYXzajmvJav02h0c8hzCd4T\n2QI74M/a7wvPaZnw+/Ng0Xlwyc/LfsaTjRQECFMWyy5TYdT+Isw5qWKufsaD0CEn813jMmYn14Gq\ncX/N2zkl+Thv7/qVv05YUzl85z8BmJNYjR2t523576CrUT6q3Qs4B8W8YfnWfkM8wkJlJ+o/roI1\nt03+GzvI2BGYdVluVEwsrJJ0hYQ3DPznjziVlC/t6C/7nDndJBpS/X546bw5JKy5SGnn7e0/g0e/\n7bu8wXD2cNMDvDy1oHPWncr7IiuVM4pCtTlXXOw55yzn504dPq2ay7SHCW9+2EkjGCNB5yzYGxCG\n5jyV0pvK0VQTIaypLMyuhfZVfpuH0irVxzd0AXDyYU0jPucL23vJ6maRY1kuZO07ZwFXG9xqzcB+\n9PICL7BXMIOh34W6WJh3Df6FQ8wdsOwHwB4KAgK5ZLppYdiF/RzXLP5f5Bpm3Plu0HP+dmbyTtXk\nxa+ZzafOWcTv3qDzNm0Fx6nbOETp9Dv3N1q9NF93PNqvXsvFL/4Hf4l8n9g/rvT3b3AaAjjh/p19\nGeY2VNFg93ND+AfE/345D67r4JJfPgm4UzR2PAc/fw388DB46KvUqDlO6H2Ay1u/Bjjfr8GsQW0s\nRHU0xOvUdbxOXcd5/bdyVvoRlhjrqEnv5PfGhQAcqvUUPpBXH4SBVliwdMhnu78QcSZMWTxx5oc1\n8ynY3QJzT9qPWzX+zG2I8zfzHG6qvRI+cDt/b/4UD0bO5+zkA0RxTnLxfDfTu57iRuON7Go8GfuS\nn7PFnsPG+AksUbcBbugkEKaZQR93R75GdcvtcOfHYO3tDEkkEsaNYPuB7uRQcdZYFWFasgW2PkGn\nK942dTmd7hviwyTtGxbRkJNT825tGUfeciZViS3+/RFN4X8zP+SsxD3wxE/glbuBQmL5tLjKJW0/\nhu1PA44o9ESkJ0xqAq7qkb2Pk295AA3TbWocTEB3/pZzzvRA5/uuRJZUwqmKXNL5D74b/n+cvOJj\ncO/ny39wo8AbH1QfD1Mdho9p97BE2cYPQ9fR/MTXnJDVMPSk8kyrjvLWwVv44cCX4Ob3FTtnAR7f\n4DRAHal4Yfdgjnf99mluW7mj2Dkr09YjOPg86KRmdLPI7ayPhzlW3cavIr/kqtA9LFVXcYJSGCg+\nvWM5x2Weo0uZhr3mFt73/T+zfGO365JDLp8Hs7Bfgs6Zt188x3HJhl9zrLoN1ciyILfO3U5n/8Uj\nIZRXH+SLr76fNz7zQRJ2FQBL1dV09iU4QdnE/G23Q7IDmo8mrvfzlLmEcN9G2PI4MLRacyCjk9FN\n5jTEOOuFz/EGbQ1VWx5k46on/EkP0/NtcMMlTp7viZfBB+7gv5p+yYO172BhZi0apj/DtCYaYsbA\nGm6OXM3NkauZ/ezVcOgZKJ9bw1Pn3ck/zNcDMFd1xZllwbO/gbq5cNTFw+7XyUbEmTBl8fJK/D5n\nvVucXK/mY/bfRk0Ax82tBxS0sz4H815LTTTEo8ppRMlxiuqMOjnk5d+gYHO9eQGPnPYntGPeSiys\n0kctjYpT0m5YXuWa83kdufUGouisfstdMOs4uONKuP5ip5JVGDeWv7qb+9fuKuo554Uvg/2bGuNh\nPt77I7j9w3QNZACbZvo4UdnImY+8FdpfKnpey3L61kVDKjO6nuSa8HXEkm3M6y20gDjC3s58czt/\nrrsKZr0G7vsSZPrpS+soCrw7vpKzB+6GlX8C4Dv/XM9n/7YKGBrWbCTBV5LfZ8bdl/H90B94p7oc\n8/Ef+K/lFwS47+2SXz7JjU9vc5a5711V4HUD9/KxZ87nk7EHaFj+DZ40l/DSnPfCC9c7+aEl5AyT\nax5sGdI2IYjnStVEQ7wr9Ve+Er6ZeyJf5d9Cy2h+9Wa47cPDPrYnmeeY0E7e1vsn942kCuLMDIw/\nMy3WtPUXvV452vrS2LYjrPXBHv8CqlwPu1wgxy0Y5suU9BWLhFQujywD4Bx1Fb8M/4qfhH8D2HxM\nu4eGv7+PvvAsPqV+DQWb45JPsbatn6imEgupXLL+i464cQk6Z9l8YWoIz17H4S2/4y7zDGxFY0nO\n+c7lvJyzkA63XgGKhnnu13l7/ltss2byAe1R7lG/yD+iX2fOml/BwnPhvTfx7Fvu48P6l9Bj0+H5\nPzrvtSTnzOt3d4TSTlPvKn5uvAMzVM1rdt7MIUonn9Xu4IQt1zkXjh++Dy68Bo44n+poiE3KfMLo\nzFc6SGR0Elmd2miImc/9gN12HVfkvwwfvh+u+AfUzUFvWkS77biec5QeJ//3hoth63I47SrQKifT\nS8SZMGUZEtbscyoXaTxs/2zQBNFYHWHr9y/kvaceCkB1VONJ/WjyhLhQfYbLtYeY0fJnuhe/jy32\nHCKu+KqKhOi262jCE2dOWDOsqZAdYNarN3G3dQY7q46E/3gELv4ZtK+C6y8qusoW9o3rlm/h/x7d\n6LsVhyidvP/lj9BIgupoiPdqj7FQ2ckp4S3MN7dDajdVic18WHuA52Kf5PbIN2lIvAprbil63mA+\nzqxXb2a3XU8+XE9z0hHsS9WXePfgjRhoPKieCW/9BaS64JFv0J/K0RSFy3J/c56s1XHOBjK6nw/m\nCYdaN9x1proOFZv+Wa/jXdpyvhf+A9UrfgTbnoIt/+JjfT+iljRJN9y5rn3Ab7rrCdPXNJl8xvoL\nGib/xY0okWq+G/4Mf5/2EaibB8/8Zsjnt3JbH79+fDOPt3TxmRuW03rz5+CWy6DlXn8dLz8rntrJ\nW3r/wv3mKTxnH8V39MvYcORVsP0pGOwsu396Ulne2XMdOTXObdpFkEs4RToUhwNzhuUbyyONhfJC\n0jt39zHrr+fytdBfnMeUdc6c5z9JfxG7f2fRcue1bWbSS7WS4yKeJG1HWaB2UKtkWKju4s3q83wm\ndCcccQG/OfZm1htzyTYcwZnqOiwbwiGVi0LPccTAU9C6Alb/DVb8sjC+SS+EweMh4F8/JDH7TP5T\n/ziDTcdyXH6Nv14mb7LE2ui0Enrjt1HP+k+2MJdHrJM4St1Blgh3WmejWLojdHDak+QJ0z3/Ytj8\nKOiZQrWm+/3tcD+vxV33YSsqNxnn07no3zg78yh3Rr7B58N3MH/nPXD8e50qe5eqiMar9iEAHKXs\nYDBrkMwZHKttJ9q2gmuNS9lSfzocdoaf5xsJOResWSLMpscRZdufgjddDWd8eth9uj8QcSZMWazS\ngoD+Vudvw4ElzqC4Wq86GqI7H2K1cjTvDz3Od8LXk2taTPcpXwAKg7SrIhrdZg1xJU+crJNz5oU1\n21aiGhnuMM9iIKNz9QMbuT53Drz9t44DueHecpshjAbbhrs+5YgWnFYIOcPyw1Tnqi9xWHotS9Tt\nNEfz/CD8Bz6sPcCb8g+juzVa5+j/4guh21hlLeIO82x21x4Dmx4tehkvJFZnDVDb+ij/MM+kt+l4\n5mY20BjO87vwTzkx8zRbm87i2U6Fnrpj4PRPwAvXc8WGq/i19mPmmW2sipzs9Nbr30HOKPSz8sRk\ntS/OXiZhV/HEcd8nQwSdEHr1LLjzKrjlMk7Kr+QC7Xku6fkT1i1XcBTb/BO/53p9XruVWtJ8I/yf\ntISOhn/7C6HGubQmLKdfYO/mIR9na2+aajIs+dfH+NaW9zFvww2w6bEiIed9FrHdq1Gx+LVxKVdY\n3+CP5oVsnX4OYJf9TifbW/iYdTuLBlbwaPOHeIX5znvOOeHL4aYkBJ2zh9Z18IE/POPn33W4TtBx\nXXcTSnVwuvoKYFO/7QFY8aui1IGcbhIlz0/N71H9/C+K3k8mb/ImdSVPRz/Ne3b9mBrSfM94PwBd\ndgMJO84vwr8kquThgu8RiVWTzhv0zTydU9QNXK49xAJ1F5+1b6YzephTIX7nx+ChrxHL9xZex/3s\n5g6ugXQ3/Ue/HxON7hmnc5S5gSh553uhmywx3MbDh5yKoiiEVZWfGO/m/NyPeEv+B9yz4OvwxY2w\n+AKgECrtmnm2I3i3Pek7Zp6D1jGQ5b3aY8xsuYHk3LPYTQMvHvlZHjRPppos1+jvIdG4BM78bNG+\ni0dCvGrNwURlsbqDwXSKdCbLafpzgMKxF/wHt191RtFjnHxbhQ57GrPoho0PQygOp/xHxeUpizgT\npixDWmn0t0KkBuKN+2+jJoGaSIi8YfEb42JuMZZyUe5qdv7bwzQ1z0VTFX/uXCys0WU6nbSbGER3\n+5xFNBV2OeGKtdbhPLy+k98/sZXfLd+CfeSFToXrM7/db+9vyqOnYdWf4foLae1JY6V7uTh7D8ft\nvgeAoxXH4Z1BP4tDTi7UYrWNJennedg6GaNmDp8O/QMNi8/on+RLxsd4ZfqboHsDqS3POO1WKLg6\ni3oeR7F07jDPprv2aGbnt3NhVQtRxeCmWV8mf+nvsGx4tKULzv8WXPhjavReTjdf5I6Gf+dP8Suc\n7W59mrxRyA0L9jmLkeMsbS0rrCVsSFbxcf1zfET/AhvP/Cm52DQS4ekklFq+Evor70n/DbXlHj6g\nPcq8gZXQuZ7BrMESZStnJ/7JjeabuGHwZH449xdw6GnMqY/T3p+BpgWO+13i2m7vSXOldj+L+p7g\nMetEvtH0Q1h4jtPg2aPOD/AAACAASURBVCWnmygKhHs2YKOwyZ7LNDeJvj1yODQeDuvvLt5PGx+m\n5rrT+Hz4DjrmnM/zs97LTssJedXrzn4pEmfu56GpSpEL9tzWXp7a1OPnjO1KZGkiwXtytwOwUGnn\nm6EbOPOFz8FDX4XHvlPYbsNisdJGGJNwzwZ/ecYd33Sa2oKq2JzQ/zAbQ4u5yTyPrfZsbjbP5YfG\n+9jQcBYvnvozmL6IuNsuoq3xVKqUHN8JX8/v9a9yCLu4f9oH6Zt/of/8M7Pb/Nf3xVnHo6BF0Bec\nB0BPzWI0LA5XOlD1FJel/syJqSectJEq53MKawoZYmyy5wEK5xw5A2qa/depcoszdjac5IigjQ8F\nwprO59nfvYsfhP8AM4+l5w3fB+CVriwf0z/PKblr+bX5Nl56y10wbWHR7qsKawzoKm3KHD4bupOL\n7z6J2wYv5/WD98Pc1/LOs0/wm9F6eLmCO60mmu0e2PQwHH4WhMfexmWiEHEmTFm8xFK/or+/1REW\nFXYFNN54TsZj+nF82fgo6+zDCWsaM+tiPPXlc3m921Qxoql0mU6rgiZl0O/6HQmpTviyaQFvOH4x\nj7U4J6JdA1lautJw8pVOCKRnqIshjIJc0r/53N9/zs3pj/IF4w+8a9dPaYzBMaojzqYrAyxQnPy+\n45StNOidrDIX0Nt8Kpat8PPaL7LDdvowvRhxilyqb7wA/vVD52VcZ2t6sgUr1kCLfQid1UehYnGZ\ndQ85O8T6pnM55tCZzKmP8fD6Tien5tSPcGXd7/j83Jt5bMblbLAOcRohtz5TLM5cYdKkJPlX9PPM\nU7q5zzyNrT0pllvH87S1hAeSizhy+3/xmu7v8qx6ItOUQTYrh5KZfx5v0FbziV3/C/d8hsGszidD\nd6FH6vm58U7AKYAAZ0RZe3/WEVCW7jSRDtC7excfCd3LQ/apfEH/OPcNHO70KkwXqu2yhpN7p+xu\nYSA2hyxRv8IxrVtOSGzL47BrtfuABNzzOQZrF/K+/Ffpv+g6wqEQO03nwq7BE2fmUOessSrM+fnH\nfLHnVYp6zuju/iR/ivyIRgZ5efEnURWbD4UeYvP0c5xk9id+Al2vOI/RTf/7EOkvJPhn3Sa0x6ub\nSdnOxdbDDe/GRuVd2v/xM+Od3GSez7Zzf8OpF34IKOQvboifyHPWkfzTPI1GEvQoTTwbO5OrtY9z\nmfI9AObq26giy2cSP0XtdJL+Z7Q/Boe/gWi107KlL+ZEIBYrbfyIn/Eh8zbmZTfCoa/ztzPsFRe5\nF4RnHTGjaN95rTGSZshpD7ThASyreCpCdcfzAKhv+g6RGQsAWNeeABSSOAUHRa00XOJuX7eEu872\npjNJ2nEa9U5Y/OYh60NBnO1iGkcZLU6UYNEby667vxFxJkxZhkwI8MTZAU51dOiBKux2MZ9VH/ND\noJGQyi7ddc6UQbdc33bCnu0vwewT+O6lx3JEcw2Xne58bo+1dMFx7wYUp3pT2HvyBXH2tp0/YYN1\nKNda7yRs65wYaedIxREfM5QB5uN09Y8rTtL4WnsBTxz6CT6g/w8seav/PKszs/hf/UP0xQ518mQo\nJOw3JjdhzzgaUNhRfSx5whytr2M1i1EjNSiKwtmLZ/DC9j5yhsnLOwfoSxsodXOIhlVSOjDzWOha\nT951V81Aa4fZ6Q3MVPr5Qv4q7rbOYOvuwiSMPzy51b/9mOn0/fqz9WYGZp/BPKWbuJ2GtucJ7XqR\nN6ovkD7mvWQ05zvZWO2Js5gzpLrG/e32Fp4T4IiOe6lVMvwk/w7Aqa7MhhsdcWYVmqTGwhrsbmGg\nxnFYaqLOyJ5U3nByoGIN8PDXQc/Ao9+CxE7uX/BVnraWcNiMBsIhlR2uOKvXy4Q13c+joSrCj7Rr\n4dbLoXO9L85SOYNHX+mkunsNJ6hb+LrxIR6sLuzD52b+G5z/bWc6yLO/dfehxTHKNgBCmW4a3PzQ\n6GArb7aWc6yylZvNc7nh+L+yvtFxtOLRMOD8xoPHAk8ItWfCvCf/DT6tf5pHwku5pfZD9KRttics\nntcPh1g98/TtnKJu4ALjMU649yLOVlcTG9wOi873hdDuyFwA/j10H+eoL/F/5rtYPf0iOPnf/df0\nUii+dtHRPPi5s5k/vbjptrdNmbwJx74TBlo5yXZCo14BxMy+leSIwuwT/PXXtxePcIqFh0oVr+nu\n73k7txlnc+uCq/lk/tP0xg6FY98xZH3AH8q+03bGQKGG4Ji3ll13fyPiTJiyFIU1bRv6tx+Q+Wal\nlHYZB8rODoyEVDo954wEpukUBDQx4OQYzTmR+qowD33+bL77tuM4dm4dT2zcDfVz4bAzYe1t0lpj\nFFiW7bdyAJyEcpcQBl/Rr+QOw3EbLuJJooqz7nRlgHlWsUu0zprP2kQNT1tLuPL1h3P3p85kTn2M\nzsE8fzbfxKsNr3eEtZF3k8ltahMbUWc6Fcq9SgPfjn8ZE43okot476lOwvRh06rpTeW5YcU2LvnV\nk+zsz9BQFSEW1hyR13y0I870QqK4J0zqdSeRfkPsNQBs6ymIs2B47478qVyV/xx/zp/N7umnA5BQ\nnK6rp6z8AmHFxD7pg8x1B2M3ugOnvUHZuzQ32bu30AoE2+YN6Qd5yVrABrtw4dVt1zgTNXID/vbW\naBb0bCJZ53SSj0c0aqIhJ3k/3gDnfg22LMP62bHw/B/YtOAyVuQWMKc+RjyiEdFUBswodqyeJnP4\nnLPZscC+fuirfgPc21a2ceUNK6nreAaAh83XsqZHZbM1m23WTDZEjoPqafCa98DqW2D3BrK6yRJ1\nO3nbESWLlJ2AzTu3f4v/i1xLTNFZbS1koG4xtW5j1WAft6rAbT+/y23DYqPyf3X/xaa5l9LWl6a9\nP0vOsLFnHMN8cztHKa3+Y38Wvta5cfhZvjhL2lHamc4J6haydphf65fw6JHfhFnH+o/zeyZWRThy\nVkmHXQrHqlTegKMuxo7W8S5tGVBwzhakVrMldgyEIv776RrMMb0myiy30380NPSCtCqiYVo29+ZO\n4L+Mq9iRMFllH8HfzxwaAi1sr/M8KdsNYx59iTPJpQIRcSZMWUw7ENbM9jsnxYPCOSsjztShP+Vo\nSKXXrgMc50y3LPKmxQLbPSjPOg4oFBssbq5lR6/bi+u4dzkjpLwwkDAs1z2xheO//ZBfpRcMaz5p\nv4aN9jy2WLPIKHHO1x8DIEE10xlgpt7GassJ5aRq5jNIFZt3JwlrCjNqorxmXgPxiObPitwWX+JU\ny3WsJbLjCT6kPUhYH0RpPppoSCWnmzxuv5ZvLb6T49/1P/5UgXmNjgB69JUuX283VjnzGLO65Yiz\n7AD1hpPHlQmM7qlKt2PaCtGmeYAjyDxhBc48S4C8pfKAdSqmrdIaOoxXrEO5KfQOmHcqtdl2bjLO\no3rOUcxrrHIfVwhrArTqdY6r1FdwzpJbnmMxrdzFOQB+G5hdedehSTmhzaxusSjUCZZBpsERZ7GQ\nRlVE80f6cOpH4PI7aW08nT8ab+GS9edw9+p23+3xQl523VwaDUec5cqIs6NCHc56Wgz6tvujrDwn\n8wx1HZ3xRSS1erb1pPiifhWf0j9N2msEd9YXIFqLff3FLLE3crTSyr8sp3v+IrWd16svs+D/s3fe\nYZJc1dn/3arq3DM9eXZmcw5Ku4oraSWtBJYQQhJBBmFyENhg4w8w2TbR2OaziTZ8tsGAjE02UYBE\n0AohlNAqbM55Zmd2cufqqrrfH7equnqmJ+zujDS72+/z6NFsdYXbVdV133rPOe8pbCct1Xl5Wi4l\nbGi+SWw8oJYFiZr3t38fuudrXlOc7pGCv9xqWckieYTV2iG6ZTP7FtxBs0hjR5ugdTVR9zwUSg4H\npCLMTzgrMAlVWL8Er8fo5R4irs9a3rQhHEeueQkv1B5Dw0GWimz/n/ezxD7A8YZ1/jUw3EjI4pY4\nC5rVvWJVMSj2iJyX3tLl+gjWT9DtxLvGP3OuYHN8A7zwn8Zd97nGpORMCNEuhPiKEOLn7r/XCCHe\nNPNDq6GGieH4OWciUKk5/zkc0bODZBVyputj8+zCusYIcUpS503Gz/jw7pfyycF3M9d2fcxGWY60\np6L0jBTUeV1zO2ghpZ7VMCEeO6Aq35487Dq3u2HND5TexDuLylJAorFbLCYlR9jiLOIJVtMmhmgp\nHmWzs5xjtJJtU3ll+3oztNWVw9PxsOH35dwbXg1A6Z73sOLeV/OR0N3qmG1riIV15Y9VspHxZggQ\ndo+cbT486C9rSISJhjSVY+Z6Ay60DwJqMvVafenpo/TQSGNd3Fcy2uujfmrnqiqKyfERk5vNf+A/\nuY3CHd/g02u+x8e4i7Ch+WPxcsI63UbZXcOmyjsLhDWtBz/DiIxxZN4tgPL80zXBoYLbXDvnkTOb\n5W642GxaCSglqSMVpWu4TFZYegP/u+jDfMJ+DXNamnEkLPbImasCOclOmqspZy5ZXSqU5UV+ziVQ\nGPLDmpmCRZgSl2i76Wm+nLpoiL50kSflcnaKpWSLtiISjYvg9fcgEfwo8rdEhcnX7Zuw9SjLxDFe\nod/PgGjgVvMTfKj0Rg7LNsK6RjJSRTkLEDUvTBzsRBHSNeY3xpCyXB1ZaFxJigzXaFvYKRewq+N2\nda4XbABNNXQP6YKCZbPfUS3pHnHUfRcbFV70mr+PR86EECTChq+w2h1riQmTTtHHX+U+zZrdX+I3\nzjoOLH6lv42nAC5qTvCFV67jL25Yxuo59WP2HR/VpqtrSF3nZHR8rzKPnB2VbXx57sdU7uIsxVSU\ns68B9wKewchu4P/M1IBqqGGqqOgQkFUPU5LtE2xxdiD4cP7obefx17esrkrYIiFVNj5IHZ1igJTV\nzxprB2uKTwFC+UoFMKc+iuVI+rOmqsZa9nzY+r+n1VbnXIDXH3LfCVcxc5WzR53VnKDBX+8ZZzEA\nf2+/huN2iiWii4iTY5/s5M/0j9J/9UcA6Bou0F5fbugY7BV5nCa6RTt692Z6Ft7KsOvQTttqoobu\n+lZZY/pLempV0IW+MR4iaqjQUKlZEZpFtkpO98KaYV2jrnicY7KFtfMbuPkCFQLSNeHfh6sCE6d3\nH3qhtbxp8+6fHePzm01fhZrf5Clnimy01kUwNKE6KLSuUGrt0BH4zd+ROvgL7rZvZN1y9SKxoClO\nW12EI0X3e+eU0lewHJZyFISGbHaVs5DG/KZ4BVkB1X+0rS7Ca9arfS4epZxZ8TYaHEVii1UKAhY4\nRylJnUzzBZAfYihncpHYy6t3vo1LtN1ERYkTzZdSFzXIuqSkMRHmni3dXPFJ1w6ldQXDr/gBm+yL\n+EDkQ/zOuYB0cjHLxTGWad1sZykHZQf/bT8fEIQMzScdQVISfBZ41aleA3LvO3nX3sPI4pspSZ1m\nkWa7M5+D0dV8yboV6XqTgVId86bNbpecPeqRs/Bo5UyrujwIlbivKnCt1CIAXq/fy4v0R/iH0p28\nS38/6y9YNeY7LWpJ0F4f5d03rhzTx7XaMT2/tLopkDMok/HZiqmMrkVK+R3AAZBSWsDEnWRrqOFZ\ngN8hQBOQd1WL2MQ9784GBInYqjl1vPmaJVXX8x4+Jdwk25hSZlbln1R5FkZlS6B2VxXxwyLnvQTS\nXXD8mWkd/9kG77yVyZnKOcu4YSkPXyzezFc7P8Jm7Tx6ZYqwUI/RPzgrOWHMIZZqGbNPqJyM86bN\nn2p/yzvbv8bmSz/F35Zez8jSWyHeRCyskzVVw+zRSkZLMuwnQ3tIhA1/giuEUpCcw1I35J0zbb+y\nt77QzZJlq3nbxmXcdpF6R9/WNeLfh0HlzKva87y+cqbFEwcV0bnlQjXRe2TWU+F0TdCUCKuWUkuu\nV/mQ3341/PZT9Ibn88PIbVy1VCVwdzbEiIZ0hnAJYbYPnvxvPn30lSy390LjIqJxtf9oSGd+Y5zj\nIwU/5AiqKrkjFeOOS+dx45p2Nq5U1g8+OYvUk5TqWgaVs3DvFkJYdJiHOSDnkDMaQNropQxXa9tY\nnn+aF2kq32zDVddUkAQv9NaXKfqKf75+Ca8vvY/tySsAGIovZpl2jEXiOHvsdv/cAER0zTcDDqY1\nBJWzpqT6PXsKGbjKWVPlfZgONXOPo46501nAUN7iH61XEl5c9gSLhnWyRYsf2Vfx5cRd/EEq8p4a\n1UbMM7yeiJx5ifsApXpFiF+oP4ojBV+zb+Knf7GBNZ31FetDmTSPv9/qJKzai2p5vOXfQLU83dmE\nqYwuK4RoBiSAEGI9MDyjo6qhhimgokNAToWWznaPMxhdoTX5W+JcoUI/v657MQBJexhSY8O/nieQ\nN7H6ib9VjEFrKMPL4drnVTG6Yc0MlZNit2xiV/PzCOkaJ6TKBSuGUuyS8wjpWkU4JkjOgupIoWSz\n22xhV7GJomXzI2cD/Tf/G6Dye7yG5qNDPkIIP5y4fol6geloiBJxSVyh5CBbV7IIFfK2Ro7Tkt5J\nRHNg5BjNnUvQNMHa+UoJfNnF8/z7cHl7nR/ibE265Mwl+I5U+UIvvXgu//on6uXgxjVz+MHbrmJJ\na7L8HSOuyrTctTXofgp52V28SH6G1cuWsqApjqEJlrYmiRga/dLdNtcP+zfR4vSxtvgHaF3t/yZi\nIZ0FTXGkhGMBNalrOE9nQ5T6aIh/f+2lLGtT+/ImayuUIopJmFKZnPVs47L7Xszt+kO0FA6wV84l\npylSmiJLu1DPnxv1x5FaiEjLEuoi5dyngWy50XzGVZE841yPTPTFFjFX9BOjyD6XnDW4RQDhgHIW\ntJWIB/6uixh+DpiHkC6YUx/187gARvIWX7JuYxeLecRZzUDWJKRRoU5FQxrpgsUISX7TcAcOGqlY\niBtWtY3a/8RhTVA5YENuwUwp0YEpdTrFAAdlOwUiY/rGBsOaEyF4jwerOetj4+ecBc/PRP1RZwOm\nMrp3AT8GlgohHgLuBmZXn4MazklU5Jzl3Vyac4KcVX9zHg3v4ZNxK5OejF7OEO6kViU3z1MyvImV\nxkXq/6OsDWqohPeSsK+3HNaUCHJExqwbMTTCAXLW33wJEpXjE1Ra2sYJa2aKFvmSzUDW9H3OvIkp\nFtYZyJbGbOPBCye+/+bVPPah57FqTn0g+dvGaVrKEtHFDdpmLvnuFfzlvjcxX+sDx/LJvBCC3Z+4\nmX/64wt9UjGvMearOp5yFkxK78uYFROwpgnWLaj8nSYiOrmiBal50KpCaIcX3cGJdJGrlzbTnIzw\ny3ddx+1rO4kYGhknDKE4u/Yf4OiuPwCg40DbKn/SjoZ0/zsfccmZlJLuoYKf5xaE93sxw0rFqSdX\nJmfbfggoz69E7hgH5BwyHjkTWeYI9fxpFSOIpiWgGxVk+3N3rmVFu/rteZW9Xq6al3vXG13kr79f\nKpXRyyML6eWCAO8eioY0P+fLuzbevjyEdLVOR0OZ7A/lTHbJBby9/nOcoJGhnMnox0jU0EkX1fjW\nL2nmz69fxv1/tXEMoQl2IxkP8xpjfmjZRuOoVF5oO+UCNDE2DFkOa1aGY0cjeI+3uC8FK9qTLJ6A\n1Akh/O9wxitnUsrNwHXAVcBbgfOklLU4Rw3POSrDmgPKSHMWNa6dKUQMzQ93TPRQ9MrGbzX/jjeI\nj1GSGodRD31S88as35IMo4nAxBpOqBy+wRo5mwheEClTtNTEW0xjGXE8L6ogoiEdQxf0ueRsoPVy\nQE0UEUP3wy7tddXDmv1Zlcs1mDN9s1jPZiBq6Ay4n1dTMjzlbHFzgjZ3/1FfObOxGpaSEjnVq9HF\nhcI1Rg1UQYcNDSEEyaiBoQlakhFfreh0SYBXOechNYGaob6j4TdM5/K74Pw7+F1G3atXuiHNxS0J\nDPc8FUsOxFvI9B+jrXiovKOAchYNaSxwydlhlxwM50vkSzYdDVXImXvui4YiZymRYVvXMDd+5gFs\n13D2cm0HmrQ4KOeQFkl3vbJyBkCLynnzSIcm4LaLOnnPTSqvylORvCKPDq8gIlQ+xwcdldvX5Fa0\nhg3N319IF4R0UaGoemhKKJLiKZned1rYlPDNuj3rj3p3f0O5kh+e9BAN6X4/1IZ4iL+6aeUY4gdl\nE9rRIfMgFjTHOTKYw3YkliM5IpX6tsuZTyoWGpNPFgvrtNdHJowKQOXvwgubvm3jsqr5aUFE3HMy\n25WzSWcyIcRrRy26WAiBlPLuUz2oEOKdwJtRz7UtwBuADuBbQDPwBPAaKaU57k5qOOdR0SEgP6i8\njM4BqAoonZGCNaWw5gHZQS4UYbHtcNCZw4XanqphTUPXaK2LlMOaoNSzgYPT/A3OLjgBL7i9JzJc\nYqYx9epv/ZGQTkjX2CKXcLe4jXmLb4fHD/hv8cmowUDWrAhrBhWCfndCL9nS/9ubGGNhnRNuIr7n\nvh/EbRfNJazrpAI2GLFAWNNsWEwEWKvtoxBpJlrs5wJnt1qxCpmvj4boaIiia4JULMTRwTzzGlX4\nMVh4AOXk//GQCOs+WSmuez3mBa9l7y93+6HJynOokS1aEG9iYe8WwsJmP/NYwlFoW0VLMsxbr13C\n81e301YXIWxoHB3IMVIo8ds9qoCgMzW2XY93Hs2QS87IsvnwII3Z/eiRnQBcKNSLymGn3S/GSJGl\no4KcrfDPD5TJrHcOhvLqe/Zl1LXyFOtuvZOS1BG6QTdNFeetkpxphAytqmrelFDrtyQjnEgX/fvq\nQ7esZsvRYd77/Wf80LdHqAdzJqPf8WIhnRPu+IwqNj0eQpogFtIrev+OxsKmBCVb0j2cR0o45Ha9\n2CnnVw1BvvTiufRlWscsH414qPzse/eNKzg2mOfWizon2EIhbGhQnP0FAVORGS4L/B0FngdsRoU3\nTxpCiLnAO4A1Usq8EOI7wJ3AC4HPSCm/JYT4f8CbgC9NsKsaznFUVGvmBs6JYgAPyYjhkrPJw5qg\n1BXbkex32pVePo4f3Jz6aDmsCcra4OCD0zXssxJBn97tXcNktx5kmRw7+UM5JGUS4t8ib+ATiRbg\nAIarXNT55Kwc1gxOQkHT126XRHukIhrSfDXZSw4P4vLFTVy+uPI34iln+ZJNoW4xXmr/kbaNLD/y\nfdY4br/HKmT+Hc9bzqA30btEJBExaKuLVNpXMAVyFjE45Kpbn75vN7/c0cOCpjiLWxJjJv6IoTGQ\ndaC+lRZb9Yj9oPkGXr0kz4vaz0cIwQdeuNpff15jjEP9OT59326+9vuDAFWVM4/IFHR1FupFloGs\nyQeMn2DrMY42X8nCXuVTd0i2MeQo5axZjNDCMFkZISGKPjnzyJSnbHr5Y75y5hLpdpcoZkuCQ7Kd\nOXVJZE6NxSPZIV34VhohXSOkaxMqZx2pqCJnbueQ1R31/ni843vXbDBXom6UchYJab4/3Og8ttHn\nbKJnEFChXnakYhyUShXcIReSrPIdbl87d8L9eQi+tJzfmeJVV0zNgPxsCmv+ReC/u4CLgeRk200C\nA4gJIQwgDnQDNwBev5ivAy8+zWPUcJbDmxT9nLNzIN/MQyJiEHYf0uMhGGoIGxqmLdnqLEQioHlZ\n1W3a66MV+UI0LYaRLigVqq5fQzn3EeAnT3cjCyOcMMOE3Ykr+IYedZUzUNfE+8xXzty8orZxqjWD\n6B7OY2jCzzsKJoq3JMbmu1WDl69WKNnk43MpuU71+5uuBWCxtV/9riJjH/mrO+q5aqmqMK2PlZPw\nRzebVp9PppwZSg1DFVbsP5HliUODLGkdmz8UMXRly3H5Xf6yJ5zlbOm8o2pf3WWtSXYcH+HJgMdb\nNeXMm7Tzelk5W85hbtceYv/Cl9OTVF5wUo8wHGpm0K3GXSq60IXkfkcZqdKhOil4ZMjbr6dY3r+r\nl+f98yYO9GWpixokXQUsZ9p8wXox+Sve4Y+pwVXCIgHlLBrSCWmi6n3h2Wl4alzw+eCppF6uWyqg\nnI3JOQuENScK/4UMrWrfyyAWukayh/tz2I7Dd+zr+Lu6v+awbJ+wsnIyBL//RNWio+F9n9ke1jyV\n0WWBxad6QCnlMeCfgMMoUjaMCmMOuTYdAEeBqdHnGs5Z+B0CNFTOWfzcUc4SEWPSB1KkQjnTKJg2\nv3Iu5puXf2/c9iaLWhIc7A8kQjcuBmTZ5LeGMfC42dyGGI8fGiAhCmRklEREpzEe9pPkATeJ2+19\nqmvlicKdROuiBtGQ5ucDwfgTT/dwoeIaByfJaspZNQRzzkw0Dss2LKlxIHkJJUIY2FVDmqPhTfSx\nsObnUAXzzBomyzmL6KrNEuW8unTBqqjo9BAxNGWNseIm3mx/gI+WXkMJw688HY1LFzVyqD/Htq4R\nbljVxl/csKzimngokzNFCC/W9vCt8CcYpI4n5r2awbCbr9m4iHg4zKAVxkFnpTgCwP/aG3hL01eh\n/TwA6qJlYhU8H/dt62HfiSwP7u2jNRnxw4b5kqq+TVxaNmT1c850nUTE4POvXMfLLp5LyNCqdgrx\n8sI8ghx8MfBSIHzlzCXUUkJ4dN5XSPd96SYKa75m/UL+6qYV434OSsUzNMGhgRyWI8kQ5+nEBmBi\nw9jJEMyrjFZp7zQeyi9EE+emPdeYSs7ZTyjnvGrAGuA7p3pAIUQjcDuK4A0B3wWqt5Cvvv1bgLcA\ntLe3s2nTplMdypSRyWSelePUcHLYO6Qe5lu3bOGakRP0RnPsCVyns/m6lXJ5dCkn/H4HD5V7ABZz\nGYaLEhA80yPpHGc7Y8TCtBy+cc/9LEnp1I0Mcwmw49ffoGfODRXrWo6k5MC8ocdYveOzPHzlV7CN\niSuspoIz7bodOKhCew16kWMSEuTppx5dWrSEHAwNjnnr7t1NPutaKeSzbHn6SQBGhgbZtGkTpWyB\nVEjywAMP+Ps/dKxENRwbyBLR8c9V/3EvRwge//2DE+YBeejKqAl489Nb6U4KGuUiRkiw9UA3fTTQ\nwQn6SnG2TnI9hvvUsXdu24o1or5fQrN8z6VdW55keP/4k3zfcZNM0eL+++/nWF+5mKBw4jCbNnVV\nrNt/okg6a3PvZd+19gAAIABJREFUr+7nV6ULANWGrOvIwTHrAmiD6jlhOZJVkWEuCWd54IHuMesd\nGnF953Ye5hrgFfomoqLEdcVPs27/EPOLgpuAflmP5pTYf6SbrIizSlPk7LhsQhZi/vU40u0ar5oF\nf1lExy98OJEu0miU2LZF1dd19Sgj7d//rpxG0HNE9Rl9+skn6N+rUQ9sHwTHLFBIF8f8TvrceyXX\np85D19EjbNqkeqNK92X2QJf690D3kfI5klbFvgbd6wmwa8c2EgO7xpwvD43Apk17x/0coDkKT+w8\nyBxT/RJyaXVnZIf6T+u3HtbAdGDzHx5hf2RqWpNZUPfXoQP72GTP3pfOqdDWYPMpCzgkpTw63spT\nwPOBA1LKEwBCiP8FrgYahBCGq57No/w8q4CU8t+Bfwe49NJL5caNG09jKFPDpk2beDaOU8PJIXlw\nAB55mLUXnE9oW4a5yy5gbuA6nc3X7Xtdm7F7M2zceO246xx/7DDs2AJAa1MjQ70ZoMjqlcvZeNWi\nqtssH8rzxad+g966VK3jXAtH/pPV/fex+uUfqWgJ9On7dnHPlm5+bX0J7BzXXLhY9Wg8TZxp121z\naTfs3cPFy+ezrf8QSQpkiNKSSvK/77iGTNHioo/eB8DaC87jmfQh9g8P0NxQz/rLLoCHH6S9rYWN\nGy+lfeUIw/kS65c0+/svbD3Of2x5AiEq89tMB5rrov65ery4k3sP7aO1Lsr1118/pbEfHczB7+5n\nyfKVLG9P8prfvwkdh5d1zGOwp4UO+wQty9ZNej222Hu49+Bu1l92MeFDg9x7aAcL25vo2q889m7c\nuKFqtZ+HHezjJ/t2cuWGa8lt+hVqqoEXXXspF86rLPTZNLKNp/qPcd4lV8Cv7veXr1mxnI0bxgZ1\nrrRsPvXEfZiWw503XuX3axyNvb1p+P1vWbr6QrI7VP7YMdnMITmHG9rnEpJJOAEtyy+jeWeSZEOc\nfKaBNrNMzta2tbBxo0rTFrtP8MWnH6Oxvo6NG68BoPnhX1fk4y2d28ZllyyGxx8mmkxB/yDPu34j\n3PczAO66dQND4V3c8YILKpTRLy0fJhkx/L6gHvJburl7+2auXLuG3x7fyVVrV7Dx8nJ+aew3v0BE\nEsAIN1+1lm/vegxHQjxiVFzj+4e38uAxVQW77qIL2TjK3+xksebAYxwayLF23Vr4/UO0tTZDfy9L\nFnSyceOFp7zf5IO/ZCBrcsN110zYUzOI5u0PcWhkiPNWraw4N7MNU8k5eyDw30OnScxAhTPXCyHi\nQr3aPQ/YDtwP3OGu8zrgR6d5nBrOcnjhpIidAeQ5lXP2vhes4rN3rp1wnfConLO8OXkOSWcqSmtd\nhKeOuB0XNA2u/Ss4sQP2/rJi3UMDOWW86nnMWedmXpqUEk3gT5RJkScrYyQiBvqo3KCooftJ2mFj\nbFhzdUd9BTGDcm5Nc5U8smDo0AvzTESCRsOv1rRUu6YMcYZJki/Z9An39zSFsKaXUxbMOQuGDusn\nCV95hrYDWaWgeaLfaPIB5bBm0NgVGDf3KWLoXDQvRSoWGuOWH4RnPZM3LYZRxz3kqMrC4VyJIVJ8\nWb4YLnwFUTfsl9Nc7zKSDFBXYYY6OucMIDWqirYlGfFzBnOmjaEJhBC88/krmFMfpSMV49MvXzvm\nu50/N1X13DS7fl/1sRAPvu96XnFpZSFHPKz7Yc26qMFC1xMsMirE1xS416YjcX7jyjb2n8iyuycN\nlJvEVytqOBl49+9EJrijccbnnAkh0kKIkSr/pYUQI6d6QCnlo6jE/80oGw0NpYS9D3iXEGIvyk7j\nK6d6jBrODXjVmiHTJQfnUM7Z/KZ4RU/DagiPyjnLub5YEz1shRCsm99QkTzN8hvV/09UhjYyBYt6\nMuUFZnaKoz+74EiJJgSLXdPMpCiQIebnBIX0si9dJKT5OTxhQ/fzkYwJ8l88ctZWJU/q5vM7/L+j\np0DO/GpN0/Ybe4PKQet17RyqVWqOxoLmOLqA5mSYjlHkrC5iVJilVoOXD+WZlb55w2I+8eLzq6oh\nipw5qgdsxXcZ/xjvfcEq/v6lF0wY6vVIc860GZaKtBx0bR+G8yVMx+FLxquhc61PEL1Q4X3GdYCo\nIFH1frVmeVyjc+9akhHfvb9Qsv3f5l8+fzmPfPB54451PKxb0MB7blrJhmUtRAy9qoeYVxAQNjS/\nO8LotMYgsZ6O3Kwbz1Pn8WdbVDi54BooV8ubOxnEwzq6Jk6KQIbd/LTZXq057pmRUtaN99npQkr5\nYeDDoxbvBy6fqWPWcPbBq5ILm+67wjmknE0FwWTgSEj3Q2KTvTGuXdDAfdt7GMyayqE8UgeaoYou\nAkgXLC7VdpcXnLPkTFUMX764mVdd0k5om0VGRv0qPICooZE17cpqzUC17UQThVcQ0FYfYfuoVKk/\nvrSsannEoPkUyFnOtCv6SOZNm17phhOrdJMYjY0rWvnMxjhtdVHf46wxHlIeaJPYaAD+ufLMYi9d\n1MRN582puq53L/eOVCq1E1UNXrZo8he3cEDBGvGUM9f2YThfojkZ9n87kZBOulBicVH5n/0yciNk\nKhWc0QUBULYUqY8qK5yWuvI+c6Y1IUmfCkK6xtuvr16JDWp8R4t5d1w6K9qT/HJ7D/oo0hp8EZiM\nWE8FHakYF81Lcf8ulVfnta6aqEn5VBAP6yelmkH5Op+xytloCCHahBALvP9mclA11DAVeGHNcOnc\naXp+MhitnPnLJ5kAvP6JTx11z6sQEG8u9y91kS5aXKjtLy8opk9zxGcmHClBKBuMv3vhIgCyxCpC\nNh5xiBo6YVehiQTCmhORs8UtCa5d0co1y5UxZyyk8ydXLODaFa10Bvy6vEnKC21NBbomaEmG6Rkp\n+OQsYmjkSzabWUFfeB40L590P0II6iPqe82pj3L72k6uXtZCPKxP2h0AAsqZ22apZYJqU+9e9nze\nPHFoIuVsKgiSpLJypsjZUF712fTJmaFRLDl8oeH9/Cr2ArqjihBVkrMqyplLzq5epixImhNl5Sxv\n2jOu5gRD7BFD8/tXDhWdivWC7cOmy6z1ovnl3EG/W8Ukzc0nQyysn/R1j4xKJZitmHR0QojbhBB7\ngAPAA8BB4OczPK4aapgUnpWGUXJJQXTiMN+5hkigvDxI1CabAC6c14AQ8NThofLCWJNqMh1AulCi\nnUD48xxVzpBlguDl3w3LREXIxiNnkZBW6XPmk7OJwpoGd7/xclZ3qGBGIqLzyZdcwN1vrAw0nEpY\nE5QFyLGhvB/WTMVC5Es2j9mr+Jfzv3PSvytdE3zuznWsW9BIPKxPakAL5ZwzL6zZNIFPm0/OhgoY\nmvBDcCdjp1ANoYByVjWsaTv+hB4xNAqWzf3ha/la87sCRsAB762QCrlV5Jy5PUZfdGEnhiZY1pb0\nj5sv2RUNymcCQVuWxkSYeY0qFN+Xr+zo0FqhnE3PmIIh3bdcu4RvvOkKnre6/bT2GQ8bk/qsjcZZ\nY0ILfBxYD+yWUi5GJfA/MqOjqqGGKcDxyZlLCsKn6418dsF7CGlCtVkZvXw8JCMGK9rqykUBoPL5\n8oMV62WKFnPEAIMR15LwHCVnXs4ZAOnjAPTQWGGwGXHf7qOGXs450zWflE1lovDUpfHydGJhtY+T\nCWsCzG1U5MzztUrFQn4O2umGfhrjYb+P50TwvpMX1myeUDlTk3H3SIHGRNhX5sbzOZsqPOKVN22/\nIOCw2wdyeIxypvp7mrZDJGDEGiQ/Qqhm9sGXpNUddcypj/JHa9rZ+tGbWNaW9MlPyZYzThg8ZW9u\nQ4xkxGDdggauW9HKq1aPLVTwMF1jChZDRAydDctbTnufy9qSJ62+nSlhzakEfEtSyn4hhCaE0KSU\n9wshPjvjI6uhhkngJeMalksKqriYn8vw3ub1gIs8TO1hu3Z+A/duP46UUiVRxxqhf5//uZSSdMGi\n3Rii25hLY/HYOUzOGEPOXnT1Oi4N9PnzJsVoSPPDmtU6BEwEbx/j9VP1lKNTUc5+s7O3gpwN5Usu\nWTg91eSLr7p4Si7wXgj48ECOkC6om2Abj+geH87TGA/5uV2nG9bUNNVQPGvafN++li7ZQp4odRGD\ndNFiJG8Fcs5UUUKx5BAJaX516WgV59rlraxbUA7n3b527pj2RKGK3+bMKmfevbO8XT0royGdr7/x\n8jFeYzMxpmB4W58mhfCDLzx5656pqNWzAVO5m4eEEEngQeC/hRCfQ3UJqKGG5xRecZluqbftmnJW\niXCAnAVzYabyxnj+3HqGciV6RlwzynhzRUFAoeRgO5I2McgxpwX0CJiZcfZ2dsORstw1KK0y9l/1\nvCtYOadcU+WHNY3K9k1CCG69qJMrFk+eL+ldw2SVhtcAF8xL8ZJ1c8f0z5wMnQ0xCiWHHjeHKxUL\nkS1a2I707SVOFUtakxWtqMaDlwt1Il2kKRGesKrSe+noTRdpiIUr2hqdLsK6spzZIRfyLf1FgFIW\nAU5kihVhzaJlU7QcIobuq3ajk9M//8p1vPbKRRMeMxTwDpyO5PuJ4P32V7RPvd5vupSzYFhzpsO3\nE+FssNL4VyHEBpSbfw74P8AvgH3Arc/O8Go4l1CyHb+KZyrwwpq6lQUjBtrpP5zPJngTiS4ES9sS\nY5ZPBC/nxPeSirs5Z+45TxdKhLBoESMctlJKtTxHyZlbD6CQPg6hhKpwDcBTdYJWGt6k94VXruP6\nKZh8Rt2w5XjKWV00xGdesZaG+MkrZwAH+tQ7dyoe8u0WPHuJmUYwVFvNzy0IL0w4lCtRFzV8u43p\nIGchQyPrtpHyCKOXvN47UqgMa1oORcsmYmg+YfRCyyeDYE7XTJOWE26z9eVtU3+RnTZyFp9+5exU\nMNpbcLZiIr15N/B/gQ5Uu6ZvSim//qyMqoZzEp/82Q62d43w7bdeOaX1PSsNvZSthTSrIKicBd+U\np/KwbXQn+MGcS85iTeBYqiIzWk+6aNHmFgPsL9QhEwnEORrWlFKW/aTS3VA3Z0wDbi/kGDG0ChPa\nk4FHyk6nWXQ1eMrQfpectSQj5ExFUJ6tCSxiaH4HhPPnTlyAEKx+rI+FfBIVnQYlJKyX/QDV+Tb9\npPmsaVcoZ6blUCipnDPv+p9KUUKQnM20mnNsSFXDnpxyNk0FAfGgcvbcEaMzJeds3NFJKT8npbwS\nuA7oB/5TCLFTCPG3QoiJO53WUMMp4NhgnqOD+clXdOFZaeilTC2kWQVBcrY00EB6Kg8lL2+pQjkD\nP7SZLli0C0XOjtkpZChxzipnY3LO6jrGrBMN6S4BERUT/MnAIx/xSRrenyzmNSjycbAviyYqJ9Fn\nawITQvg+fFctnThRPBLILauPGn53gmkJawY6aXhq3vymeMXnwTGkCyUiId0nZdFTuDYVYc0ZVpS8\n58CyKShn3limS+XyKlUB9Ocw3+usqdaUUh6SUv6jlHId8ErgJcCOGR9ZDecczFMOa+ZqylkVlMmZ\nVjFxTeVNuDExSjmLuy2FXDuNTMGiTahqzh7Z5JKzc1M5c9z2TUBZORuFSKh8DYImtCcDQ1fWG6fr\nqj4a9TGDZMQgX7IJG5qfYH8qY5wOXLm0ecLPg9WPddEQ53emWNGePGkz0moI62PDmktbAykBgbAm\nKGKuqjXdsOYpjEHThE+AZjrn7NOvuIgf//nVU7qHvvL6y7h2Retpt1jykJolOWeRMyTnbNKzLoQw\ngJuBO1E2GpuAj8zoqGo4J2FaDvlTIGdaKQPhGWtoccaiXK1ZuXwqDyUveXcwq3KPfIPf9HGQUnmc\nucpZj2zECSXQz1lyppQfpHSVs7HkbNWcOrqHVMK9F8Y6lcnhY7edx9oFDZOveBIQQtDZEGV3T4aw\nrlX0wXwu1IX2SQoIKsOaBrdc2MEtF45VK08FYUNjyM2388jZwuYEuibcAomxqmfE0PzipFMliGFd\nI+/YM15BWB8NjWkkPx6uW9HKdStap+3Ywfv9ucw5u2ppCy+9eK6fujFbMVFBwB8JIf4TOArcBdwD\nLJVS3imlrDUln0Z87aED/PSZrud6GM85SrYiZ55FxmTwyZmZhfDpOU2fjQgWBAAscRWA0BTyPQxd\nIxULBZQzl5x960/gx39OuqjCmrYwGCSJHUpA8dwMa0opVUFAYRisfNWw5luuXco337IeOL2clzsv\nXzBpT9VTgVcUEDb0in6WoWdRXfjIrWv43J1rJ10vqJxV6715OggbGjk3rNmUCKMJ1YbKa2fkXbPo\nqOpnTzk71dDqeZ3qms72UNt04blUztZ01vPpl699TgniVDCRcvYB4H+Ad0spBydYr4bTxEd+sh1Q\nrtHnMkzLQUpcY8fJH3Le26pWKwioCi+/ycvv+OZd67l323E/ZDkZmhJhBrIm27tGWJ1qLFckPvkN\nosaNzBED5CKtyLyGbcTP2Zwz6eWcuR5n1ZSzIE41rDmT8IoCwrqgPlaeFp7NMb7+6sVTWq8i52wK\nraFOBiFd85ty33HJPF6zfiEN8TBt9VG6h4PVmkHlrLIrwKlgw/IW/nBokFxx6pGDMxmznRjNBkxU\nEHCDlPLLNWJ28njf957h1zt6nuthnHHwTDALpjPJmgrlsGa2VhAwDsKG5itn7fXRST2XgmiMh/jx\n01288PMP8oOdKmQp51wIiTbW7P8qnaKfYlypRJYRR5pZvvuHIyeVN3g2wM85KwyrBbGJw0ahWVgt\nNtctChiTc/YsWWmcDILE6HQbZ49GkIwmIwaXug3TRytno8Oa58+tZ01HfUXbo5PBBrfX5uOHBiZZ\n8+zAc1mteaagdoZmAP/75FEe2ts/+YqjMLLnYXj62zMwojMDXm+/gjW1yd0Lf4pSZoyvVA0KYUM7\n5bfUoNN8b8biReEv8+11d8OCK0hlDzBX9GMmFDmz9TjSzPCe7z3Dpl290zL2MwV+zpnthoD1iSfo\n08k5myn4ypmhVYQKT9eEdiYwk2HNYKJ8MMTokbOIl3MWUMgiIY1LFjbxs7+8pqJ908kg2BT8XEBN\nOZscs+fpcJbAdiQlW1Kyp6b+VGz70Ofgp+8E5+S3PRvgnbO867FEbgC+8zrI9lVdX60ulb9WLees\nKsL6qZOzYMJsLKSzdSTOnhN5aFxEQ7GLdjGAGVeh+JKRQLMKaDi+R9a5AuVzRoCcTRw2Ds/GsGaD\nSsJXylmQoMy+STRszFxYM1gMEfQfa3Z7TXrZsOOFNU8VIV3jP19/KT/9iw2nva8zAc9lztmZgtnz\ndDhL4IV0ToWcOUNHoZSFoUPTPawzAqYb1vQrNg/8Frb/EPZvqrq+IyUxighkLaw5DpRydmo/86By\n1u/6nY3kS9C4iJA0CWNRSirlzNSV8pKgwMI9d8PIuVPg4jc+t93KVn1iwjCrw5q6Rjys+4R+No3R\ng+72wITpD2sG9xckEI2u99tQTl3j0WHN6cANq9o5rzM1LfuarfDIr1YjZ5Ni9v3yznB4eVPmFMlZ\nsDIxknUntN7tp3z8ku1MudrxuYLtSD7/6z1+ixgPHjnzc5YGD6j/9+2puh9HSpIoe4JaQUB1KHJ2\natsGCwf6M6rty0hBkTMPVp2rnGlqcl8qurhkxz/Clu+e2kHPQDhe+6YpKmehWRjWbKuLENKF3+/T\nIymztXrQU6umn5xVd7H3VGTPZiOolk2Hcnau4J53XDOlitwaauRs2lFWziRSykmJkuXa3EcwSZbc\nPLWeUyNnQzmT5R/6OV/53YFT2v7Zwm93n+DTv9zNR3+yrWL5GOVswCNnu6vux3EkceGSs5rPWVVE\nTkc5C4Q1B3zlzILGclWdTCpy5ilni4RbsZg7+ZzLMxUSt1pziuRsYXOCRFj37StmAzRN0JGKEXaJ\nhpfLNZsIZBCe8et0E6NgpWowrJnylTN1jYMVo8G/a5gY85vi3L527nM9jDMCtbtqmuEpZyXL4d3f\nfZp3fefpCdf3CMkcEajS6d02ztoTw+uN9+OnpxBSsi34+m0qdPgsw3vgdw1VtmryCwKmrJxRVs5q\nOWdVoao1T23b+U1xv0Vkf8YlZ4USpObjuMYaMqUetEWhiMZi7dwjZ46U6jxNMay5ck4d2z72Ajpn\nETkDuOuaxbzsYnU9PUVqNuXFBREZVVU6XRhPOVu/uJlrlrfwoVtW+8cPjqWGGqYbtbtqmhHMOTvY\nl/UJ03jwyFyncCezaGpKytmvd/Twf+/dWbFs2M2HSE2QJCulpHs4D5keOPAAHPr9pMeabngTvpe/\n4Y2rZCsV0fMZYuCg+n//3qpFEo6UJHAJXi2sWRV10dApt/tZv6SJB997Pc2JMP3ZQFjTCNNDMyUR\nRksoB/FcWFkOrBEH1cY592Vjy/dg2w9O6zvMdkg/52xqytlsxWuuXOSrGp5y9mya0J4MIiG9Inl/\nulA3TkFALKzzX2+6wjcAroU1a5hpzM5f3hkMj5y15fdRb57wm+iOB085myvcisRlz1dkxCpOuN19\n23r4n0cPVyzzQk+XsHPcCsctx4a58u9/wzc3bVYL8kMTHmcm4BHSdKF8boI5ennTBsuEkaOQnKNc\n10eOjtmPIyWJWlhzQnz89vP4+O3nn9K2QgjmNcaJhnS/IMB7ATgi20mHWwm5E9NwVIU3L9ZcldNT\nzh78NDzypdP4BrMfjnNyYc0zAWeCcjbdlZpQqZxN1EmjIqw5SwlsDWc2anfVNMMjHu/o+xivyX51\n0l6RRdfTa0nY9fpd9nyQNpzYNel2ntLkoTddRODw9qN/Bb//fNXtvEn2Z49uVQsKzwE5c89JsCDA\nI6nNDLNgz93wi/eBdGD5H6kVquSd2Y6qDgRqytk4WNicYFHL6YV842HdVznTRQvLdvgn86U8uPid\n/uSd1RooaRGaRVpt5JGzkWNlFe0sxcmGNc8EeMRntpKzhniI9rqJe3CeCoLKmT5BPkBFWLOWc1bD\nDGD6deFzHIWSjYZDm91Nj2wkLycmZx4pWagP0FtqoLVjrcrm6d0OHReOu13RcsZUhPamCzSQISRN\nGKxux+G4BQhNjLgDHp7aF5tGeAQ2UwwoZ+6yPzV+wmU7f1ZeecVN8OR/qbyzZc+v2E+lclbLOZsp\nxAPGmlJCT7rIY3I1N85dTch1kDcdyUikk+a8myeY6wczq8i/dnaHfSSjTWjPIuVslqpCn3nFzPRG\nrK/IORt//2Fdw+t1Xwtr1jATmJ2/vNkGKWH3veOGCskPwi8+AGaWQsmhnUF0HFJyaFJDTj/nTBuk\nWzaRr18MWgh6Ji4KKFoO1mhyNlKkyVMuRo5V3c7zX/MVjmkIaxZKNl/53QFsZ2oWHsVSedzyyGOQ\n7fdVwFYxxHB0Lvad32Jg2csUIYumqhYFSCnpFH1IoUGs6bS/Rw3VMbqZ87FBledXFzV8ZaVkOwyG\nAz0l80MwdMT9e/CsNlaWXvsmXzk788lZcyJMSBez0oQWoCMVo20GlLP6aPUOAaMhhPDVs1pYs4aZ\nQO2umgA9IwW+uGkvc3f8O/zPy+HXH62+4pP/DY98EQ49TNGy6XTzxxrkCPmSPaGdhkfOUiLLkEyS\nsQS0roTeHROOrWjZOJIKQtSbLtDiKWIjXfD7L8Cj/1axnUeCmoSnnFUnZ11Def7im0+SG5Uz99lf\n7R6T6/bgnj4+/tPtbD02NRXOa88UwYSvvQh++ylfOWsiTdZo5BfmWi7e+jIOj0hoWTFuWPNisQfa\nz4dwfErHruHkER/Vksarsk1GQn7CuGk59Ic6AmtJ6HFD59KB4sizMdTnBI4M5pyJs0IpfPX6hfzX\nm67AmKVhzZlCMOdsMmHOU8xq5KyGmUDtrpoAw/kS//2L37G81w2z9e6svqJbjXb/E1voy5h+cn+K\nNO2yH7N7fBXMyzmrk1lGiJMt2tC2ZlIjWk99CnYi6Bkp0ixcgpTuhof/FX7/LxXbWY5HgtzJchzl\n7JH9/fzk6S52dFdOqj/b0s1vdlY2dfeKIMZTCY8PF3ji0OCYsS8TxxB2EbqexLTVto0iTUav59CA\nqnLtHs675KyKcuZYrNP2wvwrqh63hunB6H6Bx4aqKWeSPr0dgH5dVXDK41vKG+XP3rwzv/G5bSrV\nTMxOtelk0BAPs35J83M9jGcd0UD+mJjkOkbcvrXnGoGt4dlB7a6aAPMb42XfpvYLlBLgjCIgg4fg\n2B8AeHzLDu55pot5LjnTkHwt/Cki/341dD1V9RieYhR3MozIBNmiBe1rJk2kLloON2uPEvryRnBU\nV4DedKEc1pSOImjDh8utdHIDdBz8MSDLYU1POTu+BbrLnmxZNx+sZ7igyGcxAw99jjXmFsxRhQil\n0f5ko/D/HtjHW//rCf/f3nprNDcv7vhWiqYKCTWKDBmtXh0XGMyZ0LIcMscr8+Oe+iYv3v6XJEUB\nMf/ycc9TDaePWKgyNdUjZ8mo4Yd+SrZDj0vODoeUSe3Tf3iwvFFukLMV5cbnpbMipHkuYzJCFkQk\npNVUsxpmDLU7awLEwjoXRN08s/NfAqXcWAVn+w8BkMKgVQwRGjnMPNHrf7xKc/NuvvfGqsdQYU1J\n1M64ypkFcy9RHx79w7hjMy2Htdpe9J5noDBEumhRKDm0iCqhxSOPQaYXPrWY9U9/gMXieDmsWcop\n24rvvxl+8Kf+JmmXnDlHHoPvvh42fx1++bd8Nv+hMbluY5z9RyFTtJQ/VsV3hjXCJWelLNrgfgAa\nSTMi6jk+oshZf9aE5uVqvb695Z0++E8sGnpU/V0jZzOK0WFNL+esPmqgawJdE5iWQ5dQ5Gy/rsjZ\nvELgeuXPXnIm/WpN86yo1KxhaogY+qwtmKjhzEftzpoE50X7KBCGFS9QC7pHOf5v+wF0rqNQt4Cl\nootvF/6UPzHuH7ujgX1VvctMyyFCCV2WlHJmuuRM6HDk0XHHVbRsGnANbvOD9I6ofTczKrdHaIqc\nPfF1f1EjaZpIl9c5/gyc2Kny3Fx1ylPOmo7+Wq2z/Uf+6qObunv/zo8T1jQtB9Ny/Pw4L5S7WjtM\nwVCmjqG4raHVAAAgAElEQVTerUQwSYgiw6Ke4+73GciYKqwJft7Zdx4/wkheff4L53JoWDjeaaph\nGuCFNb1k6S4/rOkaleqCku2wW1vKW8138vOQsj9pEcMUhJu0fRaHNWUw56ymnJ0ziBg15ayGmUPt\nzpoEi7XjHKEdWlaCEYPuQHhy4AB0PQnnvYRitIXLtLI3WUaWW7MUGl1yUaXas2g51LskK01M5ZyF\nEzDngknImUODyKh/5Ad9A9pmMcKApioXsyKp8rGOPgYD+/1t60WWZjFCTneNW5/+lvuJ9NW6jGsQ\nu6Tfbe/kjqWH5jFhzeJ4ytmun8O2H/rKmldcUCg51Ed11ohD7G2+HvQI0b5naHQJ44CsozeonDUt\nhmgD7P45AN9+dD/xXBe/aX0Nfxt531mR4zObEXOrNdvrFdHyw5qRcnNs03YoWA73OpfR7TT42x42\n3D6cZ7HXmROs1qyRs3MGipyd+cUfNcxO1MjZJOiwu9lrz6HgCGheCv37yh/uvAeA925fQibcQkyY\n/kdbnHJz6JGWi9Uf2RNj9m9aDvUip9bzcs4AFqyHY0/Aid3q1XwUKshZbsAnZx1GhmNaJxkZ5aCx\nCDouwu7ZzvGDO8BttdNMmgaR5UR4vtr+me9Aaj4g4OjjAGSKNvNFD3PMgxXu+ydoGhvWrJZzVirA\nD94K330dt/R9BSgra0XLZm4oS73IcSyyBBZdTeuBH/strPpkkt60UsYGc26o6OLXwo6fwvBRQplj\nGNgcdNpprYuMOTc1TC885awuapCMGORMG02Uw51hXaNkO765cMY2SDdfxFHZws+jNwPirA5rKhNa\nUQtrnmOIGHpNOathxlC7syaCY5MqHuOgnMPRwZwiMMNHyp8ffZxurZ3v7NM4aioCU5QGtxU/zttL\n78CS6vT2N12k1q+qnNnU45Iz4mVj1oVXq3ywf72sav/LYsmmAU85G1AkBmjV0vTLen5gb+A+/Vpo\nWYFeytI4tBWz9QIAFmiq2rI3NNfd2TCsukVViR55DIBMscQyoQoJnFUv8o+rY40Na1qKPFaENXf9\nTIVI6+dyRUaFRr1qzkLJodVQ33lQ1sOGdxEpnOBPjZ8AcCAb8UOgHunk8rsACY98ifq8ugbbi801\ncvYswCNh8bBBm3u+kxHDT54O6Rqm5fg9UYslh19v+CYbip/n5/r1yqfuLA5rKisNamHNswS3r+2k\nKTH5dUzFQjPSQqqGGqBGzibG8BF0p8RBOYfDAzlomK+MNT0l69hmtsilAIwYquz8kGznGbmUAeoZ\npA5bCvrq3d6GubHkrFI5i5ftKFbdAnd8Vf09eGDMdqPDmh45a5DD9Nh1/I31Rr7tPB9aVwEQESX2\nh5YBsFR0A9Ctzy3vcMGVMP8yFdZ0HLJFmzahKjlz86/zV4uTH9M2yrPBqAhrPvU/UD8PznsJDXY/\nq8UhEr/7JEhJ0bJp0lRorN+Jw6INDDZeyI26qujcnVYPRkMT9GdcctawAC54OfKx/2CtrfyzHhlM\n0ZKskbOZhhfWjIV1rnDtFeLhcgVn2NAo2dL3rzNth960CksXSjbEGpUKHOz8cBZBSonAq9asTdZn\nOj535zo2/80fTbre39y6hn/+44uehRHVcC6iRs4mgmViLriGXc58jg7mFUEw01AY4r9/8wQMH+Yx\nU4Uve5wUAPtkp795n6ynS7Yw4Po+VQtrBnPO8npdOayp6bDyZvV3ptJXzLIdLMcpFwTkBhjMmiRC\nkqQzQrelWhllipYytHXxWKaVkhZhqaYUsSP6vPJOF14F8y5XKlrfbtJFi3ZUKOp4y3psqVSSuCxU\nKQhwlTOPnB15HPb+Ei55HdR3EqbE6/R7aX3qX2D4CEXLoUlXxLLfjoMQdLVd6+9vUCoVcllbsqyc\nAdzwIUDyNuPHWFLjqJ2qKWfPAmK+cqZz9TJFzrxqWlAFAabt+GHtYsmmxy3oyJdspZwdewK+9cqz\nslOAlKBp1JSzcwxzG2Kn3be2hhrGQ42cTYTWFWiv+zFPyWWKJKTcHK2hIwzufgSAZ5wlAHTZilAE\nydlTzjIedtYwImPqoT1OzlnKVc7scL2q1vQQikEkpWwwgtvYDlFMIsK1p8gPMJAtsSSm1Kg+qYhi\npmhhx5oZFqoi8jc9cfJ6HYtRytlhLUDOkm1lS4ojj5ItWrRpgwzIJLszUV5d+iA/N57nKmfVrTT8\nnLP7PoRMzsG+4s+gTrX0uVhzLUi6n6FQsmkUiliesFThxLHGsh3GEKqJ+ZqOegZyZrnDQsMCutd/\nGABDOICgtaaczTjiAXJ21dKWMZ+HdI1SMKxpOX7OYN60K4tosr1jtj/ToQoCatWaNdRQw/ShRs4m\ngaFrxAwYypVUWBPg2B+4ov/72FKwVSrlbF9JKQq7nPn+th+w7uK91lvVpBVvGZtz5jgUSxaNuiJV\ndqROVWsGkWytUM5+u/sEv9/bX843A6Wc5UyWRpWNxnFZ7jOZKVo+CduaayKn1RF1Sd1Rx51o464T\nePMyFYI6+hiZgsWCUJoe2ci+3gwPO+cxYLSREEUsq3KMfrWmaavE7yOP8g37j/jnTccgqcjZCs3t\n9Xn8GTckq8jZcVORs57kGn9/NjobV7ayYk4dpuWQDeSy7Vn4Ct5uvoO7zHcB0FJTzmYcXm/NWMjw\nc3GWtpYVg7ChVShnliPpdis6CyUHbvlnSLSplYePTnywx/6DlTu/MM3fYGZRaUJbC2vWUEMNpw9j\n8lVqSIYEQzkTUgvUgp++k7XofMF+CTmUvcC2QhsvK36YJ+XyMdvnTBsSo8hZKQ+fvYDzmt9Mv5YH\nPUwoXC4IyBQt7n74IH+WaENklOImpeS1/6kS9le55Abwc84uDKkcse5R5GynXMhCeZA+6skINama\nIsyQHYE3/YpNvXEajwxx0fwGFdo88jjZ4m10hofoKjWofDugZKj+lYaTr/h+vs9ZyYZ+Zdnxu5EW\nBg8OwmVzKtZVytk1pNyQbG9JkauCUy5Jf89NK3nLtUv44ZOK0A1kTN+2YSBb5B5nvb9uTTmbeXj5\nZYmIukbPfORGjEDjwbBbEFC0HCKGRtFyODKo7hnTdrAufiPGgivhS1fB0GGYd2nV47z3e0/zpgPf\nYln+GRUrPEMsUvzG55YJkbpJ16+hhhpqmAw15WwKSIYFg7mSIlgu/qH0Sj5r3eH/eyhn8oRciVPl\nlOZKlrKxCIY1e7ZD9gTLhh4ipeUgUk8iGvK9wP7unh186he76JEpXznb36cIzXzRw+Waaoxu6zFV\nrZk1masrchZUztKFEp+1Xsob+AggSLshwxG9iaIt2RVaxZu/f4iP/9Tt5Tn/MujbhWYO0SIH6aVR\n5dsBpqbIWcQOEEMI+JjZ/Py3v1NjdTrY05v2w5o+jj9D0bKpI0NeSzJSVCFL03ZYX/gC5lsf4u3X\nLyOkazQnlUrTny2b93oFAiFdTdy1nLOZhxfWLJvRhioKAkK65r9UpNzqtZ6Rot84umA5kHJD6BMo\nZzuPp0nmu9AdE9LHp/trzBjKjc9rPmc11FDD9KBGzqYAXzkLvMl/x97IHZfM47xOlc+VHccdH6Bg\n2i45U8qZ40i2PqHMXRdkt9IgchBNkYgYZNyw5v4TKmxpx1r9nLNH9isfsA8bd/OxkHL8zyYXQE6Z\n0M5hAFuEGKD89j6UK3HMTNCfVEa4IyiClTWaKFo2H/nxNixH8uSRIYbzJaWcAevEHursAXplg6+C\nlAyluoXt6srZ3t4Mu7Y/hYPgsGxjMFei3zRIo0KXfcmVMHKMqDlEncxQDNX5k3rRcjhOM6E55/n7\nbatTqmRPIPl8IGtiaIKFzWosNeVs5uFVa8ZD1Q03Q4ZG2jUtboiXw3qdDeq6f+HXe/jgzw+r/Mmg\nFc0opHNFWh03J61KhfJshSMlAmo+ZzXUUMO0oUbOpoBkCKWcAe8vvZn3lN5CmjivWb+QH7zt6jHr\na6OiMeWwplLO/v3B/Tzz+AMA1NsDrHT2QzRFMqL71Zp9GaUWFaMtqoKyVODhfYqczRdlBS4dX4jM\nDzJSsGiRfeSibcjAZe0eVkSq2SUxQ44iZ5lwE4WSw+MHB7h4QQO2I/n93j6YewlSaDxf24wubfpF\nE91uE/KSribbqMzjOGU7DdNyCFPiDdmvcLHYQ7dspohSEPb2ZuiVjQAcalDEr9nqJulkMEMpSray\n1ijZDmFdq2g8PL9RjfXIQJkMDmRNGhNh2uoihHWN+lgtMj/TaK+Pcv3KVi5d1FT187AuSLu9U1MB\n36dFLoH+1Y4eHtxzQqlnEyhnoUIfYdyCmEBHi9kO6eec1QoCaqihhulBjZxNAYmQ8H3EvmXfwHft\njQDMb4oT0lXj5yC8/CgPuZKrnFl5Rvp7+Mdf7OR87SDZiLLYmC+7IJqiLhJShQdAnxu+y4bcZP1s\nL08eVmHLDlE29EzH5yPMNCEsGq0+8tH2imN3DSli1eKGCAdccpYPNzOcK2E5khtWtVEXMXhg9wmI\nJDGbVnGTrjoFZMMtviGsqanJNikKlAKWCKbtcIm2m7cY93CtvoUDTnkMe09k6HHJ2cH4hQA0WX0k\nnBGssGrzkylYiuCNcttOxUPURQ0/5w1UO6fmRJj5jXHmNcYqyFwNM4OwofHVN1zO+XNTVT8P6Roj\nhcqwJsCCZnWv9YwUVbGI5xMIYFsV+5BSkip2lxcMnFnKWa19Uw011DCdqJGzKSAZFqQLFpbt+InQ\n8bBOYzyEEGJMuMdrCA0qJFQwbVisfLx6HvkWhrRYKY6ws+VG0poKi9K6ksWtCfoyRYbzJRViBNKG\nIjZkeskULRLkfdNagHRE5XQ1kKHO7KUQr8zx8vogematA7ZSvwrhFr/tUmMizNoFDezoVtWe6daL\naRXq70K0nGc3ItU+PmR8A/GLD/jLTcuhjvKYDso5NCXCxMM6u4+n6ZENlKTOgYjyXGt2ThC30ziR\nsuWHaTl+HlkQC5riflgVoD9TpCkR5n03r+Krb7hszPo1PPsIG5qfdxh0TF/Y5Kq0RUuRs9Q8rMHD\n3Pnx/0B+sgN6d/rr5ks2HVIpwo7Qz6iwZmXj81pYs4Yaajh91MjZFJAMKdLQmy5iuSrSyjl1vmoT\nDY8mZ2XlLBULqbBm5zpoW0Pz3u9xodhHRFgciKzhQ82f5S9b/wNu+nuWtapk/V3H0/72w7obSsr0\nqJ6UmjKGLUmdtIyRCanP28QQsfxxzFHkzLM08MKanq9YkHTVR0O0JCMMuOrg8fm3sMOZz/CcKxlM\nlKtPR2yVA3aBdhB9733+ctN2aBRla4/9spN5jTEWNSfY05vhh/YGvmjfxgmnHqmHaZMDRO00TsxV\nzorVlTNQoc0jrnL24R9tZfPhIVa019GUCPt5ZzU8twjp5esWVM4WusoZKPIlGxZimMNcUXgYYZvQ\nu93/PD00yCKhigCG65afecpZzYS2hhpqmEbUyNkU4JGzLpfovOemlXzt9WXTVC9h2vOACoY1G+Ih\nZTEhBKx9FU2Dz/A248eUpM4zkbUcEXMYiC4ETWNZmyJnD+4p55QNGG0gNOTW71O0bFbGlaL1avOD\nXFD8Mmk37LlSHEZzTKyEImeaAF0TvnLW6oU1XeWsFCRnsRCN8TCDWaXWHWu4mJvNf+TIrd8mlGjw\n1xu2yxOvyJXHaFoOjShC+S7zT/mefS1zG2KkYiEGsiYPOBfxGeuPyZYksq6TDtFP1BpBiylVMFNQ\n/TqrkrOmGEcH8zx2YICvP3yIP7liAe+/edV4l6qG5wDVyFk0pNHqFnSAqmgstamw9suNTQD86Heb\n1f0pJQ3fuoV3hb4HwHBs0RmlnDm19k011FDDNKNGzqYAl9eUiU5dhFSgKs2zGvDyuoLKWX0sVG4I\nvu5VFLU4z9OfZKuxhhOlGMWS8oYClcMWNjTu31V2UR8SKbj+g4it3+d28RBLwsMAdNEECIYMRbLW\navsAsJId7pgMkhEjkHOmlLPdch4jWoqRVLmtU33UoCkRIlO0KFq2X5SQjBgV1XdDdnmy1cwMmMpS\no2Q7NIo0eRnm5/r1jJCgsyFGIqJXtF/KmzZ2soOlogtdWoi4ImdZ06JoOxWTvIf5TXGKlsOHf7yN\n5kSYv75ltW+KWsPsQDgQjm6Mq99AW13U/114yLVciIPGXKEKW7qOHuS933sajj5OZGAXAD2ygeFw\nuzIzzg8+S9/g9CBxC7lrylkNNdQwTaiRsynAU848v69EuDLh3yML7fVRIoZGh2shANAYD/l2EcQa\neaTxVgCeil1BumBhBhQjXRMsaUmw9diIv33etGHDu5GRetZpe5hvqAnLq4Ac1pRydpmmJjc7tcgf\nU13U8I/thTUPyg7ePve7mO564Cpnruo3lCv52yQiBg2BMNWQNaoy0rX4MC2HJtIMUMe8xhifuuNC\nXnvlQuJhwy9wAFW1aiU7WCUOAxBKqJBs2isIqEbO3IrNHd0j3HXtkgp/rRpmB4Kkeqkbmm+vj/iK\nsoe8FqMrvMj/d5sYoj9jMvToN7D0KC8rfpjXme9nMOSG5s+Q0KaU7oPUqRUE1FBDDdODGjmbAhIu\nOfOUs3ikctIJhjV/+c7ruPOycgun9vqo8khz8cP4Hdwfvo4nUjeSLpQoWjYRo7w/T3W7amkz8bCu\nQqKahl03l04xwFxtkD5Z71tVmOgUwo2sFKoKTjb+//buPEyuq7zz+Pfce2vpql6lbrX2zZIly8ir\nvIBtLLMbSAxjwhqWBEIIAUKYCQMhE4YhhCXJAIE8IR6WkBlCQkiCIeybMASMwTbYliVvwlqtpTep\n19rumT/uUktXSy2ppKru/n2ep5+u5Vb1bZ1W1Vvve8571gTnmHSryqtRQ1cAzzFxtg6COWeLwozH\n0HiegbE8xgSBZWXmbLJYM2E/DM4KJUuPGWXYdtCTTfLibatYszhLNuXGiw4gWLWazywN98WERE/Q\nmDSac5aqU9ZcH24TdOmqbn7nhvXT7pfmiz5cZJMuy7uD7OqSjnTctDYykS+x2yuXpPsYoW1sH+4D\nX+C7/pXcbTex265myAtX+86R0qZvLQkTfgBTWVNEGkDB2Sy0J8PgbIbMWfQmlPZcVi/OVJVz+tpT\njOdL5ML9KPdMZfl0/7uw2T5Gc9MzRi+8fCUdaY8Pv+SycnBGUK5cagbpswNV2zPlSz7jyT4cY/Hb\nFuGFk+zbEi6rwtVyxlSfs+c6VYFQR7q8Z+LQeJ5jo1MszibxXIeuTDmoizc2j4SbWOeKPovMGEO2\ng56qcm/1v9NkvshUJii7ltw0iQufBgRzzibyxbpzztYszvIfb76eL77hydNalkhriDJnqxdn4yzy\nks7UtPLzZL7Ez+1F+NZwJLWWZWaID+TfT9G6vG+qvNvGUW9uZc58a0lE/dmUORORBlBwNgtpN9gu\n6EDY0qF2Lk0cnCWCf87ozSrpOlXlQgj2huxtT9GZ9hidCloMpBLlYXj5Nau5793Por8zTTpqwwHk\ns8tZaoZYXHiCQzaYZ5b0HApFy2ginNzfsy4+h7aky+uuDzZlt5aqwCfpOnG2LuU5pBNuVXB29EQu\nnsxdWdaMNjiPDT8OA4+SL5bodUYZpiN+HggyKZHOtMdkoUTODcpeBy94KZlUCmPgY997lJ89PhyX\nxGo9aUVX3flo0hqiv60V3emqEv+0smahxL8VruWZ+Q/xcPoSNjoH2eQc4M+LL2efLffGG7cpaO+f\nO5kzHzwFZyLSQJrAMwvGGHrbU+yPMmc1TWajN6FU+D0OzjwnniA9PJGnvzPN4FjQRNVxgi2hCiU7\nbQuiqEVHW6KcOctl+ukzJ/Anx3nYXgYEQWKh5HMiXBTgLFpH0nXjx16zfjGOCc6nMlPmuSYO4qKe\nbFEQOTyR5+hojiXhnpWVZc1c0eduZyMDtotnuXdjvv/n8L33kSj9LT3uaJg5K785ZapWrSaZyBc5\nsupmPlO4h2dc8XZWO4bXXreOfUMT3LCxl5dctXp2AyItxQn/Xpd1tbEom+R9L3wSz9zSHzdojpoY\nT+RLDE0UOWpXcNSWVwHf6V9U9XxTRQs962Do8fP2O5ythFVZU0QaR8HZLPW2p+JtjLK1mbNEVNas\nyZx5TlzmGx4vMJkvMZEvsag9SalkKZSCN63lFQsIqp63oqw5mQ7KgY4t8YhdSdJzSLoOhZLPsBfu\nItCzNs7CRdm9X777WeRqeoh5TjlzFm1/FGXIhsbzHB2dYvPSjvD26kzArfn3APBA6o20F4IdCy73\nd9LhjjNsZ86cdWcSDIzlmPQ9PlO6meemg9/5T56/pe7vLnPHYLjVWPR3/Ipr1sT3pT0n3nf26Imp\nuE/gE34QnA3YTvbbJQBxIJcrAYvWwZ4fzPgzv/LLQ4zlirzs6uYH9EFZMyz5K3MmIg2gWtEs9bbX\nzwhBORCKMmfJirJmdyYqa+YZHA/exHqzqap2G8u609STTrhM5Et87LuPcChcnQmwP7GOlOeQcB3y\nJZ+hcMUmi9bFGbKoMW5H2GDWc0y8b3vSM3EQ1xlmzjzXiQOogbE8SzqDzFl/Z2raXqEATxQ748vP\nNj8FYIiazFmyuhnvZKFUXgmqVZfzxqFw/9bldf6OKxcFRAtqAA4Vg+D/Xn8DBNuG0x9ma6dKYeZs\n9BDkyg2ZK33h5/v5f3fubcj5ny3NORORRlNwNku9FaXH2rk00Tyb6HvCM/H3RXG5sMBguF/m4vZk\n1RZPK2bKnCVcHj4yyl99+2G+tjd4bt9JMJhaTcpzSXoOxZLlqBNkHli8Mc6Q1W4pZYyJg8YgcxYG\nZxVzyhZlkjx2dJySb1kSzjlb0pnmm299Ks/dWr3zwBE/CM5sqpPnRPtwul1sCjNuANmKVa2Lskms\nhSMnguxjZXAqc9v2C4O/vyvX9Ey7r3JRQLSgBmBvvhycPWlF8Le0pDP4m8sVgQtuCg78xefr/sxi\nyVIMM8/N5tvKOWcqa4rI2VNwNku94af6toQ7bdVglB1I1ZY1w2wUBHO5oszZ4vbqzNnSrvqZs7aE\nGy8k+FU+KAPlui4g05YOM2eGQsnnF4kreGfmPbDq6jgAq21jUHl+nmvKZc2K8+jJJtl9OOixFs05\nA9jY31HV7gPgiO1h3KYY3vxyOkzwpvvh1zytanPsyszZ4mzwfFFpWMHZ/PEb21ay+73PYWVPZtp9\nbQk3Lu1XZs7unVrO54s3cXvpOq5au4i2hEt3JkEm6ZIrWVh1Nay8Cu78G/BL05636PsUfH/a7c1g\nlTkTkQZTcDZLUeYsm5oe9LTVZM6izdGTnks64dKWcBkez/Ofjw6ScA1rF2fizFlve3Ja4BM/b0WA\ndXjSYcB2ku/dQnvKI5Vw8JxgztlkybIzsw2Midtk1At+kl657Fovc9aTSTIcBoNRWTNSG5B+rPgC\nXlf4b+xe9yp+XNrCVKIHei+sOqby36q3I3jTirbAql1UIXOXMWbGXRvaki5Lu4LMcGVwNuF7vLP4\nO6xev5mnb+7nug29bF3RRSbpMRXFYte9NVgRvOP9054332KZM9eGzZYVnIlIA+gdcpaiOWf1OtTX\nttIwxpBwTVxi7MkkODaW40ePDPD0zf10Z5Jx8DTTYoDg+cpveMMTBX43/4d85MnPo/uHo+SKPo5j\nyJcsuUKp6thPvfoqLuyf3paiKnNWM+cM4KJlHXxn1xGAuKwZSbjVwdnjdhmP22Xcku/gHYU/4QO/\ntpWXdi6rOqby3yoKbg+NTNKWcNUaY4G4eu0iPNfh4SOjPBFuJZbynHiRyudffy0A128MVhx/+ZeH\nyBXDLNTm58Hlr4Q7/gI23Qwrroyft1jyKZZaMXOmsqaInD29Q85S1O6itscZVK7WLN+XcJ14z8Ge\nbJLv7jrK4HieF10ZdMWPgrNlM5Q0K58XggUFd9tNuItW846bN/HnL9xK0jUUij5TNcHZ9Rt74/k7\nleLgzHHi545WawK8NuyLBsH+oZVmagAblSnrNZCtnPTfFwdnU7SrpLlg/Mnzt/COmzfTlgh2i+hI\nefGikXSdv5mqzJkx8Kz3AgYe/W7VccWSJd9CmTOVNUWkkRSczVI056xeOa7c56z8z5lwnYrMWZKx\nXJHe9iQ3buoDyv3FlnXNnDlrS5afL2pBkPIcNizpYOvKoDFr0feZKvi0JU49lNH5JD2HjnSCD966\nlVuvWBnf351J8sFbt/KMi5ZMK1N5Tv3nPxwGZ/UyYZXbXEXbRx0ZndJ8swUobk7blY7/n6TqlELj\nOWeRth7ofxLs/c+q4woln2KLzDnzrcW1Cs5EpHEUnM1S70kyZ2t7MyRdJ96kG6LMWfDPGy0KeOHl\nK+IgpjPtsXlpB9esWzTt+SK1q0Kh+g0taKVhmSyU6h5bKxlnzoIs2EuuWk1/TYbtJVet5pOvvmra\nY70ZMmdRG4VTZc6ijdethQ7NN1twov83/Z2pcruXOh8oMkmXqTDOsdby8JFRWHsd7L8LSoX4uILv\nt8ycM1uVOVNZU0TOnoKzWepuS+A6pm5/rg1LOtj93uewtjcb35Z0TRyIRe00br2ynKXyXIdvvPWp\n3Ly1ep5WpXqTrCs7/SdmKGvOpDzn7PSHfabHHD5JWTOdcOLeaosrmtOqrLnwRB8e+jvTFVuHTf+b\nzSa9OHP2jQcO86wP38GRniugMAGH7o2PKxQthRaZc+Zbi+tHCwIUnInI2dO75Cw5jmF5dzre5qje\n/ZVSCTcOmF54+Qr62lNsXtpZ76Ezqm2H4ZjqDFYi3CFgcpbBWVzWdOtnwU5mpsxZHJzVCd6MCYLZ\nfMknFe5oEMw70hvYQhM1RV7amWbvYLBHbb3MWXvaI1wwzF2PDwHwSOZS+t0U3HVb0GKDsJVGiwRn\n1oJnwolyjv62ReTsNSU4M8Z0A58EngRY4LeBh4B/BtYCjwMvttYON+P8ZvKpV19Vtdfkybz3lifF\n7SMuX93D5aunN+g8ldpSZcpz4303oRyc5Qr+7IIz92wyZ/WDs9Gw43+9zBkEZSqTDwK1jrTH4Hhe\nmedVF7gAAB/ySURBVLMFKGqKvLQrHWdw62XO+jpSnMhbfN/yi/3B9mAHpjJw3R/AHR+Cq14Hq6+l\nULL4FnzfTvtgdL5VzznT37aInL1mlTU/CnzDWrsZuBTYBbwD+K61diPw3fB6S7mwv2Nai4mZXL+x\n97QzZbVqg7PaACjhOkwVfPIlf1ZzzqI3w5myYCdT7zG1Wbx6sikvPu9oIUC75pwtOG3JyrLmzHPO\n+tpTlCwMjOXYeShoiHzkRA6ufyskMvDg7QBx1mw2jWgLJZ9ccXoj20axFjyUORORxjnvwZkxpgt4\nKvApAGtt3lo7AtwCfDY87LPAC873ubWadLI2c1Y9XEnPMDoV1IAqV3bOJFmzg8HpqJdtq+zRVq+s\nCUEj2mRNw9tOZc4WnOjDw9JTzDmLWrjc8cgA+WIQeB0ZnYJkFvo2w5GdAPFigNksCnjPV3byus/+\n/Ox/iRlUZ84UnInI2WtG5mwdcAz4jDHmXmPMJ40xWaDfWvtEeMxhoL8J59ZSoje0aPubVE2mwXMc\nxvPBJ/bTmXN2RsFZnczZtevLK02TXv1sXCbpxUFlnDlTcLbgRJmzpRWtNOpmzsLg7Hu7g2bIPZkE\nR8J5jfRvgSM7sdbGGbPZzDs7NDIV9+M7F3xrK/bWVCsNETl7zXiX9IArgDdba39qjPkoNSVMa601\nxtT9SGyMeT3weoD+/n527Nhxjk8XxsbGzsvPqXV43McAy9pKDE9AKTdVdR5HnsjFl/c+9gg7co+f\n9PkGjwbH7961k+zQQ6d1Lr96vNzGIOlA3oe1ZiC+7Z6f/4wDmelvtlNjUxRyPjt27GBqNHiDPLR3\nDzt27D+tn38mmjVuMt3QsRyOgZ13/4ShY3kAhgePTRufJ8aCYOuHuw+TcmFVxufRQwPs2LGDlSdS\nbJgY4Eff/BLWBkHQD374n3SlTl6mP3JsktFJe87+FnwLxwePBef94zspedP3GF0I9P9t7tLYtZ5m\nBGcHgAPW2p+G179IEJwdMcYss9Y+YYxZBhyt92Br7W3AbQDbtm2z27dvP+cnvGPHDs7Hz6nnphum\n+NK9B3nw67vp6epg+/Yb4vt+MrkL9u4B4NKtF7P90uUnfa4fjO6E/Y9z+aVb2b759BKT++/cC7sf\nACCbTpCfKPC0667itp13MjJR4Ibrnly3oW5xyRGGJvJs37aKrw38kruPHODKS059ro3QzHGTam2r\nB7l0zxBPu2kj3z/+AD88uJe1K5ezffslVcedmCrwzh99i9ECXLy8ky0ruvjOrqPBOO4x8NinuGZ9\nJ+yY4gJzkBuWrmDRpc876c/+xMM/YaQ0eU7+Fqy18I2v0dfTASfghhtvgsTMjaXnM/1/m7s0dq3n\nvAdn1trDxpj9xphN1tqHgKcDD4ZfrwY+EH6//XyfWyvq70zHDTynzTmrKE+eThPasy1rtiVchimQ\nTXp89S038MWfH2Bpne2iAJ6xpRwERrsiqKy58FyzfjHXrF8McNLVmh0pj4QDBR/W9WZZ0plmcDxH\noeST6L8YAP/wTuAC3uB+ha5vPAinCM4KJUvJPzcNa234tK7VggARaZxmvUu+GficMSYJ7AF+i2D+\n2xeMMa8F9gIvbtK5tZxoA/Ha1ZqVW0md3mrNMw/OjCmfRybpsrg9xR88Y+OsniPaZF0LAha28vZN\n9XvjdaUMA5OW9b1ZlnamsRaOjeZY3t0L2SWYo0Fw1mNGcaaGwPfhJH/T53KrJz+MzuIFAc6p/x+K\niJxKU94lrbW/ALbVuevp5/tc5oJsqv7qtm1ryr3T6k2urpWKM2dn0EojfIznlHc+yNTZLeFkyq00\nlF1YyE62WhOgKxkEZ+v6snFAf/jEVLA6uP9inGO7gF+ny4xjrA+548EenDMolCyFc7TVU5SQcykG\nWTPT3J5rIjI/aPumOaAtDIJqy5qXruqOL59OE9ozK2sGj3Edg+cG2zLNJiCstL4vS1vCpb8zddo/\nX+aPk/U5A+IJ/ut629m0tAPHwDd3Hg7u7L8Yb+AhHHy6GQ9umxiqevxUoRTMBQsVSv45K2uWM2cF\nrdQUkYZRcDYHZKM5ZzUBWGWQNau9NRPRDgFn3oTWcxySbrAtkznNLMGNF/Zx758+k+6M3sQWspPN\nOYOK4GxxlpU9GX7t0uX835/sZWg8D0u2YEpTrDFH6DLTg7OxXJFtf/YdvrOrvJ6oUDr3Wz05tqTd\nAUSkYRSczQFtMywIAHjd9esA6Gw79RvDWWXO3HLmLOE68SKF02GMmVUQKfNb9CFjpszZ5UtcXrJt\nFV1hf7/XP3U9E/kS39l1BMJFAZvNProYCx4wMRg/dmgsz1iuyP6hifi2YslSPOeZs6IWA4hIwyg4\nmwOyM5Q1Ad71vIv44dtvmtW2Ut2ZJMaU536djnLmzOC55oyCMxGoKGvOkDm7pM/jgy8qt9hY15sF\nYHAsD32bsMbhMudRUiachD85xL7BCW75+I84MBIEZbliOVOWD8ualaXORonnnNmidgcQkYZRcDYH\nZMIFAfU2FzfGsGrR7JpePnNLP1/+/evr9iM7lagUWs6cqYQjZyZeEDDLOYttiWALsJGJPCTayHWu\n42qnoonyxCAPHDrOLw8c5/4Dx4PbpkagFARvUUnzXGTPosyZo8yZiDSQgrM5IBNnzs4uW+U6hq0r\nu874sRCURF97/Tre/LQNZ3UusnCdKnNWyxhDTybB8ESws8BUxxq2mL3lAyaGmAi3MTs2msPg86q7\nb4WffgIIypqLOU7p0P0N/C0CNkzQBZkzfWARkcZQcDYHZBIuHSmP3vbmTaRPVMw5275pCTdvXda0\nc5G57WR9zmbSk0kyMhFsITaVXUHKlLcTY2KQyXwRg8+GA/9KL8fJFobhSLCjRb7k8/ve7ST/6UWN\n+yVCypyJyLmgj3pzgOMYvvGHT2VxtnnBmVsx50zkbFy8vIubNvVx8fLZZ3G72hJxcDaZWRHfbjGY\nySBzdrl5lJce/kv2uWH/6pFg/9ZCyafPG8GMHztlw9rTFRVKg8yZViGLSGMoczZHrOhua+pKx0RF\nnzORs7Eom+Qzv3U1i07jw0ZPJhmXNccz5X1ZJ9uWxWXNZSZoqbHF2RfceXxfuBAAuhjHYIOGtafp\nVwPjM95XtVpTZU0RaRAFZzIrUVCm4EyaoSebYDjMnI22lTNno9nVMDHEZKHE0jA422SCjBknDlEo\nBI/pNGFrjcmRk/6cj37nEd74ubvj6w8eOsFNf7mDBw7WD+pU1hSRc0HBmcxKtOXTmTSwFTlb3Zkk\nIxN5rLWMpYPMWdE6QaA2MchEvki/GQZgvTkUPMgvUjgeXO6MdhOYHD7pz7nvwAgPHDwRXx8cz4Xf\n83WPj7pzOGqlISINpDy8zEo5c6Z4Xs6/nkyCom8ZyxWZcDsZs2lyJJhM9MD4MZ6790MMmaAZrWvK\nLTPscJBFi3cTmDp55mw0V6zaTSC6XJph4/TqzFn2zH45EZEaCs5kVqLVmloQIM0Qbfk1MlGg4MN+\n20eSIjuX38rW1BGesuvLHHem9/uzI/uALrrizNnJg7OxqergLB82s51p4/Q4c+YrcyYijaM0iMyK\n5pxJM3W3BYHPyESBQsnnHv9CdtnVHE/0wzPeA0CXKW/ZNOT0AJC+91NcZh7DM2HAdYrM2ViuWBWI\n5cPLxRmCs3LmTBufi0jjKHMmsxLNNVPmTJqhJ1zZOTyRp1jy+R/F1wLwR76FnvVMmAwZWw7Ojpgl\nLHInSB2+m79O7Cs/0akyZ7VlzWK0u0D9smZV5szRy6mINIYyZzIrnlppSBP1hJugD0/kqzJbhVLQ\nt+wx9wIA9vpLguPohFf+G8X0IlY7x8pPdKrMWW1ZM9r66ZSZM5U1RaRxFJzJrChzJs1UNeesIniK\ngqaHzFoA7rfrABiiE9Zez9Dml1c/0UkyZ1OFEvmST6FU3iS9vC/nTAsCgu9qpSEijaTgTGYlCso8\nV38ycv51tyXoSHv8+70H4300jSkHTztZD8D9fvB90HYAMJVdWf1EJ2mlMZYrxpejTdJPvSAgzJz5\nakIrIo2jd1qZlaisqcyZNIPnOnzw1kv4xf4R/nbHY0Cw52wUNH21eA1/VHg93/K3AXDMD4KzyUx5\nD9hc25JyWbOYhx99pCqTNjZVDs6ioC8ft9KYqawZfFfmTEQaScGZzIqn1ZrSZM/duozVizLkSz6u\nY0h4TlxuPF5w+JfSdh63/Xyi+Hy+XgyCtPGK3QQms6tgYhieuA9++gn4zrvh55+O76/MnEVBX6FY\nXd6sFWXOjFppiEgDKQ8vs+I4BscocybN1ZNJsG8o2LHCcxwKJUvJt+SKPp5jKPoOHygG88ystYy1\nBZkz3xomMsvp3vcV+LsbwGsLntCUP5+O1smcleecnSJz5quVhog0jjJnMmue42iHAGmqaGFAwnFI\nuIZCyWeyEMxB621PARB9fvje7qPsPpbjqO3mBBkKTrr8RMXJ4Pt4eSVnlDl7jfsNuv7+RqByh4BZ\n9DlTKw0RaRC9msisea5R5kyaKmqp4bmGhOtQLPlM5IOgqrcjyeETU3S1BZukv+kf78VzDNtsL70c\nxyuMBk9yy9/AgZ/Bff8C4wPxc4/lgk3SL3MeJTGwCyaGyBWrM2i1fJU1ReQcUHAms+Y6Blcbn0sT\nxZkz18FzDQXfMpUPAqe+MHPWk00yPFGIM2rfcy9nuRmke/MfsuLSZ8Blr4DLfzOYezZ+NH7uaEHA\nMjMU3DC0h0IpeM6Z+pxZCw4+BqsFASLSMKpRyayt782yZtH0/QtFzpeeMDgzJihtFks+E4UwcxYF\nZ5nquV8fL72QPy6+jhOp5Yxe8hq+eM/BYCJ/+xIYK5c1R8OyZj9hu43Bx04558xaSBDOVVMrDRFp\nEL2ayKzd/qbrm30KssD1ZIPs1HiuRG+7oVCycd+z3o4oOKufwSr6ln/4yV7+4psPsXlpB0/K9sGh\ne+P7g8yZrcqc5YsXBo89SVnTI/j5ypyJSKMocyYic0ZU1hzLFUm4DiMTee7ZG2S6LuhrxzHB93qK\nJZ/v7w7KmDsPHQ8yZ+MDELbjGMsV6WGUlAnmnjH0WNxSY+bVmrYic6bVmiLSGArORGTO6G4rZ6cS\nruGefSP82Vd3AbCpv4O7/+SZXHvB4rqPHRzPc8++IJC7/+BxyC4BW4p3DRidKrLUBJctBgYfI1/y\nSZPjZY+8DY49NO05fQuJKHOmsqaINIiCMxGZMyrnk3k1bV3aki492SQpr/7L2vcfOopvoTuT4IGD\nJyDbG9zxs/8DQ3vC4CwoaY73bAnLmj4bzUE2jd7JRz75aV52252MTOQrnlVlTRFpPAVnIjJndFfM\nJ/NqVg5nki4AKc+t+9iHDgetNF5w2Qp2PXGCUqYvuGPH++FLb2RsKs8KJ8icDS+5CqZGSBaO02uO\nA1AcG+Qnewa57Y498XP6FjwTlTUVnIlIYyg4E5E5oydbmTkLgrPnXbKMd9y8mWVdQZPZmTJnhZIl\nnXC4fHU3uaLP3ly2fOe+n7Bh7GesSx6nZA0jXVsAaM8P0GeC/TcXmSC4G54oxA/zfVsuaypzJiIN\nouBMROaMbLKcFRsaD8qL165fzBtuvABjgmAtnah+WfOccvPkbNJjddgOZn+xOzhg3Y3QvpRnTHyd\nVd4wA3Qxml4OQEdxgD6CzFm3GQPAz09CKQjQfEu5rKk5ZyLSIArORGTOiAIwgAPDwRZM63uzVcfU\nljUTroMbBmeZlBv3QzuSS8Ebfwq/+a+w9jouLD3ChfZxHvFXMJ4K5qN1FQbLmTOCzNnvPf4W+Orb\ngGD/Tq3WFJFGU3AmInPSYJg5WzstOKvJnIVbPQFkEh59YT+0Y2M5WLIZ3AT+sstYzgCrC49xt72Q\nUS9Y8dldKpc1u80oSxlk7dQu2LODQyOT3H/wuMqaItJwCs5EZE75zttu5Ef//ab4+rLOdNX9Ueas\nPRWUGZPhVk8QZM7SCZeOlMex0Vz8mKm+SwBwsNzrb2SKNKS76CkN0hcuCFjEKDe49wcPGNnHbV+/\ni/d/fTeedggQkQbTq4mIzCkblgRNZv/xddfw4BMncJzqVZupcM7ZqkUZdj1xgoTrYMJGs9lk8JLX\n25FiYKwcnI10bSFtDY6x3ONv4Gm+Dx3L6Bkcoo8oczbGU5378DE4WLqG7wfWkTDKnIlIYylzJiJz\n0lM29PK6G9ZPuz0ZljBX9bQBQVkz6onWFi4o6G1PVgVnx/00e+wyTmTXcYJ28kUfOpbS65czZ51m\nkhuc+7kr9RQwDivGH6STcS4xYWsNtdIQkQZRcCYi84rjGN7/X7by29evA6rLmtFqz76OFANj5Way\nJyYLvKf4Kh7d9qdA0HaDjuWs5hDtZooDNlgg0G3Gude7FHo3sSb3EL/rfYV3Jj4f/mAFZyLSGArO\nRGTeednVq7lkZRcQrNaMFwSE89B621NVc85OTBX5oX8JzoanAeFG5x1L6WIcgIf8VfGxD5l10L+F\nlcX9bDCHyj9Uc85EpEEUnInIvNSWcHEMJDxTbqWRiMqaKY5PFoLyJUHmDKAn3IGgUArmnEUetGsA\nKOHwEGtg0QUstUe5oCo4UysNEWkMBWciMi8ZY8gmPTzHiZvQVmbOAAbHg+zZiakgOOtqS5B0HfIl\nS2nl1ez1l/DXxRfwjdLVABxyVzBaSlDsWYdrLBuciuBMZU0RaRDl4UVk3mpPeyRdh5JvgfKcs972\nIMt1bDTHwGiefUMTwfEpj4RrKJZ8Cku2cmP+IwAsZRCA/akN5As+E9k1dNb+MJU1RaRB9GoiIvNW\nNuWR8Az5Upg5q1gQAPD3P36cL917EN8GgZnnOniuQ6Hkky/58fMM0cmQbWdP+5XkB3xG2lZND86U\nORORBlFZU0TmrVU9bfR3pElETWjDPmcXLevk0pVd/Ns9QWAG0JkO7kuEZc1CsRyc5Unw5NzHua/v\n18gXfUbo4LgN9ugs2bDPmtHLqYg0hl5NRGTe+vjLr+B9L9wa9znLpoLMWTrh8sXfewp/9RuX8tKr\ngpWYXriiM+kaCiU/aKdRIUeS9nSSfNHnxFSJX9mlAGzP/2+OXfdu6Fh6vn4tEZnnFJyJyLyVTXm0\nJd3y9k3J8kyOhOtw65UreeaWfoB43pnnOhRLfrySsy1R3ki9PeVS9C0jk3ke9lex11/CftvPicte\nD6Z6pwIRkTOlOWciMu/FqzWT7rT7Ll/dU3U94RoKJRvPOcumXCYLJVzHkA4fPzCa4yPFl9NhgoDO\nUWAmIg2k4ExE5r2oZFmZOYssygYrN6MMWjDnzA96nVHe8inpOvHWUANjeUboYMR2AOAoNhORBlJw\nJiLzXrQgIJpzVuvhP7s5zq4lvaCsGQdnYVkz6TmkvCg4y1U9XpkzEWkkBWciMu+5NRuf10p65em3\nnhOWNcM5Z1G2Lek58XG1wZmISCNpQYCIzHsJJ9r4/NSfR6OyZjTnLFNZ1gyDs2Nj+apSpqO6pog0\nkIIzEZn3otWalSsvZ1Iua9qqxyQ9h6RbXhCwONwCCjTnTEQaS8GZiMx7nusEG6HPIoqqLWu21cmc\nDYzl6KsKzhSdiUjjaM6ZiMx7Fy/v5ODw5KyOTYTbNxVqy5oVc85yRT/YAuqJ4DGKzUSkkRScici8\n94pr1vCKa9bM6tiEFwRnU4USULMgwC0XG3orMmcGRWci0jgqa4qIVEiEZc3xXBGAnkzQB62yrAmw\nKFve6FxzzkSkkRSciYhUiMqaY7kgc9adCYKwyj5nAJ3pyuBM0ZmINI6CMxGRCkFZ0zKWK+A6hvbU\n9D5nAJ1tCs5E5NxQcCYiUiEoa/qMTRVpT3lxG47aOWedbeUpu0avpCLSQHpJERGpkEq4TBVKjOVK\ntKc8EmFAlqqZc6aypoicK00LzowxrjHmXmPMf4TX1xljfmqMedQY88/GmGSzzk1EFq6utgS5os/A\nWI72lIdbsefmTGVNhWYi0kjNzJz9AbCr4voHgQ9bazcAw8Brm3JWIrKgRQsADo5M0p724k3TpwVn\nypyJyDnSlODMGLMSeB7wyfC6AZ4GfDE85LPAC5pxbiKysHW3BUn7A8MTZFMeXrhpetI9yZwzxWYi\n0kDNypx9BHg74IfXFwMj1tpieP0AsKIZJyYiC1uUOZsq+HSkPLywrJmoXRCgzJmInCPnfYcAY8zz\ngaPW2ruNMdvP4PGvB14P0N/fz44dOxp7gnWMjY2dl58jjaVxm5uaPW57T5Tiy6PDx7j/vmEADu3f\nxx13HMYzwafKu378w/i4H97xg3hu2kLV7HGTM6exaz3N2L7pOuDXjTHPBdJAJ/BRoNsY44XZs5XA\nwXoPttbeBtwGsG3bNrt9+/ZzfsI7duzgfPwcaSyN29zU7HE7MDzBu3/8fQA2rFnFVZcug7t+zIUb\n1rN9+wbS3/8mCddw0003wTe/CsD27dsXfHDW7HGTM6exaz3nvaxprX2ntXaltXYt8FLge9baVwDf\nB14UHvZq4PbzfW4iIt2Z8kLx9nS5rBntDpD0nKqVmqDtm0SksVqpz9l/B95mjHmUYA7ap5p8PiKy\nAGWTbhyQdVQuCPDKCwMq55sBGM05E5EGakZZM2at3QHsCC/vAa5u5vmIiBhj6M4kGRjLkU1VtNJw\nKzNnTX3pFJF5rpUyZyIiLSFasdme9siEe2t2hNmyxe1JlnW1Ne3cRGT+08c/EZEa3eGcso6Ux4ru\nNv7xd65h25pFAPzdK68k5boAPG/rMr56/xNNO08RmZ8UnImI1IgyZ9kwa/aUC3rj+5Z0pOPLH33p\nZbz/1q3n9+REZN5TcCYiUqMr3CWgPXXyl0jPdeh0NTtERBpLryoiIjWizFlHWp9fReT8U3AmIlIj\nmnOWPUXmTETkXNArj4hIjec8aSmjuSI9mcSpDxYRaTAFZyIiNTb2d/DHz72o2achIguUypoiIiIi\nLUTBmYiIiEgLUXAmIiIi0kIUnImIiIi0EAVnIiIiIi1EwZmIiIhIC1FwJiIiItJCFJyJiIiItBAF\nZyIiIiItRMGZiIiISAtRcCYiIiLSQhSciYiIiLQQBWciIiIiLcRYa5t9DmfMGHMM2HseflQvMHAe\nfo40lsZtbtK4zU0at7lLY3f+rLHW9p3qoDkdnJ0vxpifW2u3Nfs85PRo3OYmjdvcpHGbuzR2rUdl\nTREREZEWouBMREREpIUoOJud25p9AnJGNG5zk8ZtbtK4zV0auxajOWciIiIiLUSZMxEREZEWsiCD\nM2PMp40xR40xD1TctsgY821jzCPh957wdmOM+WtjzKPGmPuMMVdUPObV4fGPGGNe3YzfZSGZYdx+\nwxiz0xjjG2O21Rz/znDcHjLGPLvi9ueEtz1qjHnH+fwdFqoZxu4vjDG7w/9X/26M6a64T2PXAmYY\nt/eGY/YLY8y3jDHLw9v1Wtki6o1bxX3/1RhjjTG94XWNWyuy1i64L+CpwBXAAxW3fQh4R3j5HcAH\nw8vPBb4OGOBa4Kfh7YuAPeH3nvByT7N/t/n8NcO4XQRsAnYA2ypu3wL8EkgB64DHADf8egxYDyTD\nY7Y0+3eb718zjN2zAC+8/MGK/3Mauxb5mmHcOisuvwX4RHhZr5Ut8lVv3MLbVwHfJOgP2qtxa92v\nBZk5s9beAQzV3HwL8Nnw8meBF1Tc/g82cCfQbYxZBjwb+La1dshaOwx8G3jOuT/7haveuFlrd1lr\nH6pz+C3AP1lrc9baXwGPAleHX49aa/dYa/PAP4XHyjk0w9h9y1pbDK/eCawML2vsWsQM43ai4moW\niCYu67WyRczwHgfwYeDtlMcMNG4tyWv2CbSQfmvtE+Hlw0B/eHkFsL/iuAPhbTPdLq1hBcEbfqRy\nfGrH7ZrzdVIyo98G/jm8rLFrccaY9wGvAo4DN4U367WyhRljbgEOWmt/aYypvEvj1oIWZObsVKy1\nlupPFiJyjhhj3gUUgc81+1xkdqy177LWriIYszc1+3zk5IwxGeCPgT9t9rnI7Cg4KzsSpnIJvx8N\nbz9IUKePrAxvm+l2aQ0atznAGPMa4PnAK8IPRaCxm0s+B9waXta4ta4LCOZv/tIY8zjBGNxjjFmK\nxq0lKTgr+zIQrUZ5NXB7xe2vCle0XAscD8uf3wSeZYzpCVd2Piu8TVrDl4GXGmNSxph1wEbgLuBn\nwEZjzDpjTBJ4aXisnGfGmOcQzH/5dWvtRMVdGrsWZozZWHH1FmB3eFmvlS3KWnu/tXaJtXattXYt\nQYnyCmvtYTRuLWlBzjkzxnwe2A70GmMOAO8GPgB8wRjzWoKVLC8OD/8awWqWR4EJ4LcArLVDxpj3\nErxhAPwva229CZjSIDOM2xDwMaAP+Kox5hfW2mdba3caY74APEhQMvt9a20pfJ43EbzIuMCnrbU7\nz/9vs7DMMHbvJFiR+e1wDsyd1to3aOxaxwzj9lxjzCbAJ3itfEN4uF4rW0S9cbPWfmqGwzVuLUg7\nBIiIiIi0EJU1RURERFqIgjMRERGRFqLgTERERKSFKDgTERERaSEKzkRERERayIJspSEiC4sxZjHw\n3fDqUqAEHAuvT1hrn9KUExMRqUOtNERkQTHG/E9gzFr7l80+FxGRelTWFJEFzRgzFn7fboz5gTHm\ndmPMHmPMB4wxrzDG3GWMud8Yc0F4XJ8x5l+NMT8Lv65r7m8gIvONgjMRkbJLCTreXwS8ErjQWns1\n8EngzeExHwU+bK29imBfyU8240RFZP7SnDMRkbKfhfsKYox5DPhWePv9wE3h5WcAW8ItpwA6jTHt\n1tqx83qmIjJvKTgTESnLVVz2K677lF8vHeBaa+3U+TwxEVk4VNYUETk936Jc4sQYc1kTz0VE5iEF\nZyIip+ctwDZjzH3GmAcJ5qiJiDSMWmmIiIiItBBlzkRERERaiIIzERERkRai4ExERESkhSg4ExER\nEWkhCs5EREREWoiCMxEREZEWouBMREREpIUoOBMRERFpIf8fj7koqS2nT60AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S8ApDVWMLTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86447eb0-bd5c-4fc1-b7e0-3bc73afed526"
      },
      "source": [
        "tf.keras.metrics.mean_absolute_error(x_valid, results).numpy()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.129704"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKmGTNRwMNv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "1af6e150-6134-491b-aa7f-d8ebcbcd4c5a"
      },
      "source": [
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "mae=history.history['mae']\n",
        "loss=history.history['loss']\n",
        "\n",
        "epochs=range(len(loss)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot MAE and Loss\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, mae, 'r')\n",
        "plt.plot(epochs, loss, 'b')\n",
        "plt.title('MAE and Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"MAE\", \"Loss\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "epochs_zoom = epochs[200:]\n",
        "mae_zoom = mae[200:]\n",
        "loss_zoom = loss[200:]\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot Zoomed MAE and Loss\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs_zoom, mae_zoom, 'r')\n",
        "plt.plot(epochs_zoom, loss_zoom, 'b')\n",
        "plt.title('MAE and Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"MAE\", \"Loss\"])\n",
        "\n",
        "plt.figure()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4yPkEAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n38LCwmKIwBK+hYWFxRDB/wdxVTMx/LXVhwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}